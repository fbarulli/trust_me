{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uvw8bW_N8mSA",
        "outputId": "820cf38f-9907-493c-948a-b1fa543368b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Collecting pytorch-lightning\n",
            "  Using cached pytorch_lightning-2.5.0.post0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Collecting captum\n",
            "  Using cached captum-0.7.0-py3-none-any.whl.metadata (26 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning)\n",
            "  Using cached torchmetrics-1.6.1-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning)\n",
            "  Using cached lightning_utilities-0.12.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.55.7)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.11.11)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (75.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.18.3)\n",
            "Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m94.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.5.0.post0-py3-none-any.whl (819 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.3/819.3 kB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading captum-0.7.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.12.0-py3-none-any.whl (28 kB)\n",
            "Downloading torchmetrics-1.6.1-py3-none-any.whl (927 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m927.3/927.3 kB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics, captum, pytorch-lightning\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed captum-0.7.0 lightning-utilities-0.12.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pytorch-lightning-2.5.0.post0 torchmetrics-1.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy pandas torch transformers pytorch-lightning scikit-learn seaborn matplotlib captum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aq31CxbP8la5",
        "outputId": "ad2f22ad-c155-49ff-8976-51da4d414c48"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "  warnings.warn(Warnings.W111)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting features...\n",
            "Loading embeddings from disk...\n",
            "Embeddings loaded.\n",
            "Preparing data...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-2-20e8fc76ee68>:102: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = GradScaler()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting features...\n",
            "Loading embeddings from disk...\n",
            "Embeddings loaded.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:   0%|          | 0/696 [00:00<?, ?it/s]<ipython-input-2-20e8fc76ee68>:296: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Validating:   0%|          | 0/87 [00:00<?, ?it/s]<ipython-input-2-20e8fc76ee68>:332: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "Train Loss: 1.1962, Acc: 0.5370\n",
            "Val Loss: 0.9994, Acc: 0.5828\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6185    0.6715    0.6439      2426\n",
            "           1     0.4482    0.4440    0.4461      2356\n",
            "           2     0.4525    0.4046    0.4272      2343\n",
            "           3     0.5921    0.5152    0.5510      2527\n",
            "           4     0.7453    0.8605    0.7987      2523\n",
            "\n",
            "    accuracy                         0.5828     12175\n",
            "   macro avg     0.5713    0.5792    0.5734     12175\n",
            "weighted avg     0.5744    0.5828    0.5767     12175\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAApIAAAIjCAYAAACwHvu2AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAgbRJREFUeJzt3XdYU9cbB/BvAiTsvRUQUHHhXrgnuGd/bsU9ilbFvbdY99a6R7VaW1fduBcuFLfUjcoUBGSv/P5AY1NQ4ZYQIN9PnzyP99yTk/eSAi/vOfdEJJPJZCAiIiIiyiWxqgMgIiIiosKJiSQRERERCcJEkoiIiIgEYSJJRERERIIwkSQiIiIiQZhIEhEREZEgTCSJiIiISBAmkkREREQkCBNJIiIiIhKEiSQRfdPTp0/h7u4OIyMjiEQiHDx4ME/Hf/XqFUQiEbZt25an4xZmjRo1QqNGjVQdBhHRdzGRJCoEnj9/jiFDhsDJyQna2towNDRE3bp1sWLFCiQmJir1tT09PXH//n3MmzcPO3fuRPXq1ZX6evmpb9++EIlEMDQ0zPbr+PTpU4hEIohEIixevDjX4wcHB2PmzJkICAjIg2iJiAoeTVUHQETfdvToUfzvf/+DVCpFnz59UKFCBaSkpODy5csYN24cHj58iA0bNijltRMTE+Hn54cpU6Zg+PDhSnkNBwcHJCYmQktLSynjf4+mpiYSEhLw119/oUuXLgrndu3aBW1tbSQlJQkaOzg4GLNmzUKJEiVQuXLlHD/v1KlTgl6PiCi/MZEkKsBevnyJbt26wcHBAWfPnoWNjY38nJeXF549e4ajR48q7fUjIiIAAMbGxkp7DZFIBG1tbaWN/z1SqRR169bFb7/9liWR3L17N1q3bo0///wzX2JJSEiArq4uJBJJvrweEdF/xaltogJs4cKFiIuLw+bNmxWSyM9KliyJkSNHyo/T0tIwZ84cODs7QyqVokSJEpg8eTKSk5MVnleiRAm0adMGly9fRs2aNaGtrQ0nJyfs2LFD3mfmzJlwcHAAAIwbNw4ikQglSpQAkDkl/Pnf/zRz5kyIRCKFNl9fX9SrVw/GxsbQ19eHi4sLJk+eLD//tTWSZ8+eRf369aGnpwdjY2O0b98ejx8/zvb1nj17hr59+8LY2BhGRkbo168fEhISvv6F/ZcePXrg+PHjiI6OlrfdvHkTT58+RY8ePbL0j4qKwtixY+Hq6gp9fX0YGhqiZcuWuHv3rrzP+fPnUaNGDQBAv3795FPkn6+zUaNGqFChAvz9/dGgQQPo6urKvy7/XiPp6ekJbW3tLNfv4eEBExMTBAcH5/haiYjyEhNJogLsr7/+gpOTE+rUqZOj/gMHDsT06dNRtWpVLFu2DA0bNoSPjw+6deuWpe+zZ8/www8/oHnz5liyZAlMTEzQt29fPHz4EADQqVMnLFu2DADQvXt37Ny5E8uXL89V/A8fPkSbNm2QnJyM2bNnY8mSJWjXrh2uXLnyzeedPn0aHh4eCA8Px8yZM+Ht7Y2rV6+ibt26ePXqVZb+Xbp0wcePH+Hj44MuXbpg27ZtmDVrVo7j7NSpE0QiEfbv3y9v2717N8qUKYOqVatm6f/ixQscPHgQbdq0wdKlSzFu3Djcv38fDRs2lCd1ZcuWxezZswEAgwcPxs6dO7Fz5040aNBAPk5kZCRatmyJypUrY/ny5WjcuHG28a1YsQIWFhbw9PREeno6AOCXX37BqVOnsGrVKtja2ub4WomI8pSMiAqkmJgYGQBZ+/btc9Q/ICBABkA2cOBAhfaxY8fKAMjOnj0rb3NwcJABkF28eFHeFh4eLpNKpbIxY8bI216+fCkDIFu0aJHCmJ6enjIHB4csMcyYMUP2zx8ry5YtkwGQRUREfDXuz6+xdetWeVvlypVllpaWssjISHnb3bt3ZWKxWNanT58sr9e/f3+FMTt27CgzMzP76mv+8zr09PRkMplM9sMPP8iaNm0qk8lksvT0dJm1tbVs1qxZ2X4NkpKSZOnp6VmuQyqVymbPni1vu3nzZpZr+6xhw4YyALL169dne65hw4YKbSdPnpQBkM2dO1f24sULmb6+vqxDhw7fvUYiImViRZKogIqNjQUAGBgY5Kj/sWPHAADe3t4K7WPGjAGALGspy5Urh/r168uPLSws4OLighcvXgiO+d8+r608dOgQMjIycvSckJAQBAQEoG/fvjA1NZW3V6xYEc2bN5df5z8NHTpU4bh+/fqIjIyUfw1zokePHjh//jxCQ0Nx9uxZhIaGZjutDWSuqxSLM398pqenIzIyUj5tf/v27Ry/plQqRb9+/XLU193dHUOGDMHs2bPRqVMnaGtr45dffsnxaxERKQMTSaICytDQEADw8ePHHPV//fo1xGIxSpYsqdBubW0NY2NjvH79WqHd3t4+yxgmJib48OGDwIiz6tq1K+rWrYuBAwfCysoK3bp1w++///7NpPJznC4uLlnOlS1bFu/fv0d8fLxC+7+vxcTEBABydS2tWrWCgYEB9u7di127dqFGjRpZvpafZWRkYNmyZShVqhSkUinMzc1hYWGBe/fuISYmJsevWaxYsVzdWLN48WKYmpoiICAAK1euhKWlZY6fS0SkDEwkiQooQ0ND2Nra4sGDB7l63r9vdvkaDQ2NbNtlMpng1/i8fu8zHR0dXLx4EadPn0bv3r1x7949dO3aFc2bN8/S97/4L9fymVQqRadOnbB9+3YcOHDgq9VIAJg/fz68vb3RoEED/Prrrzh58iR8fX1Rvnz5HFdegcyvT27cuXMH4eHhAID79+/n6rlERMrARJKoAGvTpg2eP38OPz+/7/Z1cHBARkYGnj59qtAeFhaG6Oho+R3YecHExEThDufP/l31BACxWIymTZti6dKlePToEebNm4ezZ8/i3Llz2Y79Oc7AwMAs5548eQJzc3Po6en9twv4ih49euDOnTv4+PFjtjcoffbHH3+gcePG2Lx5M7p16wZ3d3c0a9Ysy9ckp0l9TsTHx6Nfv34oV64cBg8ejIULF+LmzZt5Nj4RkRBMJIkKsPHjx0NPTw8DBw5EWFhYlvPPnz/HihUrAGROzQLIcmf10qVLAQCtW7fOs7icnZ0RExODe/fuydtCQkJw4MABhX5RUVFZnvt5Y+5/b0n0mY2NDSpXrozt27crJGYPHjzAqVOn5NepDI0bN8acOXOwevVqWFtbf7WfhoZGlmrnvn378O7dO4W2zwlvdkl3bk2YMAFBQUHYvn07li5dihIlSsDT0/OrX0ciovzADcmJCjBnZ2fs3r0bXbt2RdmyZRU+2ebq1avYt28f+vbtCwCoVKkSPD09sWHDBkRHR6Nhw4a4ceMGtm/fjg4dOnx1axkhunXrhgkTJqBjx4746aefkJCQgHXr1qF06dIKN5vMnj0bFy9eROvWreHg4IDw8HCsXbsWxYsXR7169b46/qJFi9CyZUu4ublhwIABSExMxKpVq2BkZISZM2fm2XX8m1gsxtSpU7/br02bNpg9ezb69euHOnXq4P79+9i1axecnJwU+jk7O8PY2Bjr16+HgYEB9PT0UKtWLTg6OuYqrrNnz2Lt2rWYMWOGfDuirVu3olGjRpg2bRoWLlyYq/GIiPIKK5JEBVy7du1w7949/PDDDzh06BC8vLwwceJEvHr1CkuWLMHKlSvlfTdt2oRZs2bh5s2bGDVqFM6ePYtJkyZhz549eRqTmZkZDhw4AF1dXYwfPx7bt2+Hj48P2rZtmyV2e3t7bNmyBV5eXlizZg0aNGiAs2fPwsjI6KvjN2vWDCdOnICZmRmmT5+OxYsXo3bt2rhy5UqukzBlmDx5MsaMGYOTJ09i5MiRuH37No4ePQo7OzuFflpaWti+fTs0NDQwdOhQdO/eHRcuXMjVa338+BH9+/dHlSpVMGXKFHl7/fr1MXLkSCxZsgTXrl3Lk+siIsotkSw3q9GJiIiIiD5hRZKIiIiIBGEiSURERESCMJEkIiIiIkGYSBIRERGRIEwkiYiIiEgQJpJEREREJAgTSSIiIiISpEh+so2T9zFVh0Cf7BjmpuoQ6B/K2hqoOgT6REeioeoQ6DPuplxg6Ery7vPpc0unynCljZ14Z7XSxlY1ViSJiIiISJAiWZEkIiIiyhURa2tCMJEkIiIiEqluWr0wY/pNRERERIKwIklERETEqW1B+FUjIiIiIkFYkSQiIiLiGklBWJEkIiIiIkFYkSQiIiLiGklB+FUjIiIiIkFYkSQiIiLiGklBmEgSERERcWpbEH7ViIiIiEgQViSJiIiIOLUtCCuSRERERCQIK5JEREREXCMpCL9qRERERCQIK5JEREREXCMpCCuSRERERCQIK5JEREREXCMpCBNJIiIiIk5tC8L0m4iIiIgEYUWSiIiIiFPbgvCrRkRERESCsCJJRERExIqkIPyqEREREZEgrEgSERERiXnXthCsSBIRERGRIKxIEhEREXGNpCBMJImIiIi4IbkgTL+JiIiISBAmkkREREQisfIeueDj44MaNWrAwMAAlpaW6NChAwIDAxX6JCUlwcvLC2ZmZtDX10fnzp0RFham0CcoKAitW7eGrq4uLC0tMW7cOKSlpSn0OX/+PKpWrQqpVIqSJUti27Ztuf6yMZEkIiIiKiAuXLgALy8vXLt2Db6+vkhNTYW7uzvi4+PlfUaPHo2//voL+/btw4ULFxAcHIxOnTrJz6enp6N169ZISUnB1atXsX37dmzbtg3Tp0+X93n58iVat26Nxo0bIyAgAKNGjcLAgQNx8uTJXMUrkslksv9+2QWLk/cxVYdAn+wY5qbqEOgfytoaqDoE+kRHoqHqEOizIvdbsPDSlahunaJO85+VNnai7wTBz42IiIClpSUuXLiABg0aICYmBhYWFti9ezd++OEHAMCTJ09QtmxZ+Pn5oXbt2jh+/DjatGmD4OBgWFlZAQDWr1+PCRMmICIiAhKJBBMmTMDRo0fx4MED+Wt169YN0dHROHHiRI7jY0WSiIiISImSk5MRGxur8EhOTs7Rc2NiYgAApqamAAB/f3+kpqaiWbNm8j5lypSBvb09/Pz8AAB+fn5wdXWVJ5EA4OHhgdjYWDx8+FDe559jfO7zeYycYiJJREREpMQ1kj4+PjAyMlJ4+Pj4fDekjIwMjBo1CnXr1kWFChUAAKGhoZBIJDA2Nlboa2VlhdDQUHmffyaRn89/PvetPrGxsUhMTMzxl43b/xAREREp0aRJk+Dt7a3QJpVKv/s8Ly8vPHjwAJcvX1ZWaP8ZE0kiIiIiJe4jKZVKc5Q4/tPw4cNx5MgRXLx4EcWLF5e3W1tbIyUlBdHR0QpVybCwMFhbW8v73LhxQ2G8z3d1/7PPv+/0DgsLg6GhIXR0dHIcJ6e2iYiIiArI9j8ymQzDhw/HgQMHcPbsWTg6Oiqcr1atGrS0tHDmzBl5W2BgIIKCguDmlnmDq5ubG+7fv4/w8HB5H19fXxgaGqJcuXLyPv8c43Ofz2PkFCuSRERERAWEl5cXdu/ejUOHDsHAwEC+ptHIyAg6OjowMjLCgAED4O3tDVNTUxgaGmLEiBFwc3ND7dq1AQDu7u4oV64cevfujYULFyI0NBRTp06Fl5eXvDI6dOhQrF69GuPHj0f//v1x9uxZ/P777zh69Giu4mUiqUQ1nEwwuLETKhQ3gpWRNoZs8YfvA8UysrOlHia0KYNazqbQEIvwLCwOP267jeDoJBjpamGURynUdzGHrYkOouJScOpBGJYd/xsfk75sKlqnlBlGtygNFxsDJKakY/+tt1h87G+kZ3BPi685tGsjDv+2WaHNurgD5q3fi/dhwZgwoFO2zxs6cR5q1GsKABjQpnaW84PHzUGths3zPuAi7o7/LezesQWBjx/h/fsI+CxZiYaNm8rPb1q/BqdPHUd4aCi0tLTgUrYchniNRHnXigCA27duYPjgftmOvWnnHpQr75ov11HUbdm0AauWL0WPXn0wbuJkAJl3oy5d9DNOHj+KlJRUuNWti8lTZ8DM3FzF0RZ9WzZtwKoVn96PCZnvx8B+veF/66ZCv87/64qp02epIsTCpYB8ROK6desAAI0aNVJo37p1K/r27QsAWLZsGcRiMTp37ozk5GR4eHhg7dq18r4aGho4cuQIhg0bBjc3N+jp6cHT0xOzZ8+W93F0dMTRo0cxevRorFixAsWLF8emTZvg4eGRq3iZSCqRrkQTj4M/Yt+Nt1jfr1qW8/Zmuvh9hBt+v/4Gy08+RVxSGkpZ6yM5LQMAYGUohZWRNuYffoJnYXEoZqKDuT9UgJWhFF7b7wAAytgaYPOg6lh7+jnG/nYXVkbamPtDBYhFIvj89SRfr7ewsbV3wth5q+THYnHmvn6m5lZYulPxL7ILJw7ixP5dcK2mWPLvN2qqQpuunr4SIy66kpISUbK0C9q074RJY0dmOW/v4IAxE6bAtlhxJCcnY++uHRjlNQi/HzoOExNTuFaqjL9OnVd4zoZ1q+B/4zrKlquQT1dRtD28fx9/7tuLUqVdFNoX/+yDyxcvYOHSFdDX18eC+XMwZtQIbPv1NxVFqh4ePriPP//I+n4AQKfO/8Ow4T/Jj7W1c77ejVQvJ9t7a2trY82aNVizZs1X+zg4OODYsW/vq92oUSPcuXMn1zH+ExNJJbrwJAIXnkR89fyYVqVx/nEEfj7y5aOPgiIT5P/+OzSzOvnPc4uPB2Jpz0rQEIuQniFDm8o2CAz+iFWnngEAXr9PwIK/nmC1ZxWsPPUU8cnpSriyokFDQwNGJmZZ2sXZtN/2u4Aa9ZpCW0dXoV1XzyDbMSh33OrWh1vd+l89796yjcLxT97j8dfBP/H8779RvVZtaGlJYGZuIT+flpqKS+fP4X/dekBUQKoMhVlCQjwmTxyLaTPnYNMv6+TtHz9+xMH9f2L+wkWoWSuzQj9rjg86tWuFe3cDULFSZRVFXLTJ348Zc7Bpw7os57V1dGD+j+8HyqFcrmWkTCr9qr1//x4LFy5Ex44d4ebmBjc3N3Ts2BGLFi1CRMTXE7CiQCQCGpe1xMuIeGwbXAM3ZjXF/pF10LyC1TefZ6CtibikNPm0tURTLK9gfpacmg5tLQ1UKG6ktPiLgrDgN/Du0wYTBnTChkXTERkemm2/V8+e4M2Lv1HfvW2Wc7vWLcbIHh6YO7o/Lp36K0d/SdJ/k5qagkP790Ff3wAls6nGAMCli+cQGxON1u065nN0RZPP3Nmo36ARarvVUWh//Ogh0tJSUbv2l3ZHJydY29ji3t2AfI5SffjMm4369bO+H58dO/oXGtevjR86tsXK5UtytScgUW6prCJ58+ZNeHh4QFdXF82aNUPp0qUBZN56vnLlSixYsAAnT55E9erVvzlOcnJylt3hZWmpEGlqKS32vGCmL4G+tiaGNnHC0uN/4+cjT9CwjAXW9a2KHuuu48bzqCzPMdHTwojmpbDH74287eKT9+jXwBFtq9jgaEAILAylGOFeCgBgaZi7rQbUiZNLefQfPQ3WxewRExWJw79txoIJQzF7zS7o6Oop9L106jBs7EqgZNmKCu0deg5GmUrVIJFq4+Gd6/h13SIkJyWgWbuu+XkpauPKxfOYPmkskpKSYGZugeXrNsLYxCTbvkcO7kctt7qwtLLO5yiLnhPHjuLJ40f4dc8fWc5Fvo+AlpYWDAwNFdrNzMwQ+f59foWoVk4cP4onj7J/PwCgZas2sLG1hYWFJZ7+/TdWLFuM169eYcnyVdn2p3/g7IUgKkskR4wYgf/9739Yv359lqknmUyGoUOHYsSIEd/9qB4fHx/MmqW4iNi4dg+YuPXM85jzkvjTNZ9+GI4tF18BAB4Hf0TVEibo6WafJZHUl2pi88AaeBr2EStOPpW3X/77PRb89QRzf6iAJT0qISUtA6t9n6Gmsyl4r83XuVb/8pe8nWMpOLmUx/j+HXDr8hnUd28nP5eSnITrF06hbdesN3K07d5f/m8HZxekJCXhxP5dTCSVpGqNmtj+25+Ijo7G4QN/YNqEMdi44zeYmiouLQgPC8V1vyuY8/MSFUVadISGhGDRgvlYt3FLrvfAo7wXGvrp/djw9fej8/++/PwpVdoF5hYWGDKwL968CYKdnX1+hUpqRGVT23fv3sXo0aOzXb8kEokwevRoBAQEfHecSZMmISYmRuFhXKOLEiLOWx/iU5CanoGnoR8V2p+Hx8HGRFuhTU+qga2DayA+OQ1Dt95G2r8yxM0XXqLSFF/Um3MO1aaflt8Z/uYf6y3p23T1DWBVzB7hwW8V2m9dOYeU5CTUadrqu2M4upTHh/fhSE1NUVaYak1HRxfF7R1QoWIlTJ4xJ/OuxIP7s/Q7evgADI2MUb9BYxVEWbQ8fvQQUVGR6NGlE6pXKo/qlcrD/9ZN/LZrJ6pXKg9TM3OkpqbiY2yswvMiIyN517YSPH746f3o2gnVK5dH9cr/eD8ql0d6etY18a6fdjZ4E/Q6v8MtfArIPpKFjcoqkp93XS9Tpky252/cuJHlMyCzk91u8QV9WhsAUtNluBcUAydLxbt8S1joIfhDkvxYX6qJbUNqICUtA4M230LKv9ZD/lN4bOYUf9uqtgj+kIgHb2OUE3wRlJSYgPCQd3Br3EKh/fKpw6hcsz4MjLKfQv2nNy/+hq6+IbS0JMoKk/4hQyZDSopi0i6TyXD08EG0bNMOmloF/+dAQVezdm3sO3BYoW3G1MlwdHRC3wEDYWVtA01NLVy/7odmzTO3DHn18gVCQ4J5o40S1KxdG/v2/+v9mPbp/eg/EBoaGlmeExiYuXuHubllvsRYqBXxhE9ZVJZIjh07FoMHD4a/vz+aNm0qTxrDwsJw5swZbNy4EYsXL1ZVeHlCV6IBB/Mvd/nameqgrK0BYhJSERydhI3nX2Bl7yq48SIK155FokEZCzQtZ4kea68DyEwitw+tAR0tDXjvugt9bU3ofypWRsWlyKeuBzV2xMUn75GRIYNHRWsMbeKMETvucGr7G/ZuXonKNevBzNIa0VHvcWjXRojFYtRq6C7vExb8Bn8/DMDImUuzPD/g+iXERkfByaUCtCQSPAq4gaO/b4dHp4K9pKKgSkiIx9s3QfLjkHdv8XfgYxgaGsHI2BjbN21AvYaNYWZugZjoD/jz99/wPjwMTZor7nfmf+M6gt+9RdsOnfP7EookPT19lCxVWqFNR0cHRsbG8vYOnTpjycKfYWRkBD09ffw8fy4qVqrMRFIJvvd+vHkThONHj6Be/QYwNjbG33//jSULfVC1WnWUdsn+xjSi/0pliaSXlxfMzc2xbNkyrF27Vl6S19DQQLVq1bBt2zZ06VLwp6i/xdXOCL95fdm0emqHzI8l+uPGW4zfcw+n7odh2h8PMKypM2Z0LIcX4fH4cdtt3Hr5AQBQvrghqjhkVsLOT2mkMHb9Oefw7kPmnXgNy1jAq1lJSDTFeBwciyFb/L+57RABH96H45dF0xEfGwMDI2OULFcJU5ZsUqg8XvY9AhNzS5SvUivL8zU0NXH26J/Ys2kFIJPB0qY4ug4ciQYe7fPzMoqMJ48eKmwovnLpQgBAq7btMW7yDLx+9RLHjhxCTPQHGBkZo0z5Cli7eQecnEsqjPPXoT/hWqkySjg65Wv86mzshEkQi8UYO2okUlJTUKdOPUyaNl3VYaklLS0tXL92Fbt/3Y7ExERYWdugaXN3DBw8TNWhFQ682UYQkawA7FeSmpqK95/u8DM3N4fWf5yScvL+9gaclH92DMvdZ3aScpW1NVB1CPSJjiTrNCSpiMp/C9JnuhLVJXM67bLuyZlXEg8X3WS+QGxIrqWlBRsbG1WHQUREROqKayQF4VeNiIiIiAQpEBVJIiIiIpXiGklBWJEkIiIiIkFYkSQiIiLiGklBmEgSERERcWpbEKbfRERERCQIK5JERESk9kSsSArCiiQRERERCcKKJBEREak9ViSFYUWSiIiIiARhRZKIiIiIBUlBWJEkIiIiIkFYkSQiIiK1xzWSwjCRJCIiIrXHRFIYTm0TERERkSCsSBIREZHaY0VSGFYkiYiIiEgQViSJiIhI7bEiKQwrkkREREQkCCuSRERERCxICsKKJBEREREJwookERERqT2ukRSGFUkiIiIiEoQVSSIiIlJ7rEgKw0SSiIiI1B4TSWE4tU1EREREgrAiSURERGqPFUlhWJEkIiIiIkFYkSQiIiJiQVIQViSJiIiISBBWJImIiEjtcY2kMKxIEhEREZEgrEgSERGR2mNFUhhWJImIiEjtiUQipT1y6+LFi2jbti1sbW0hEolw8ODBHMW6aNEieZ8SJUpkOb9gwQKFce7du4f69etDW1sbdnZ2WLhwYa5jZSJJREREVIDEx8ejUqVKWLNmTbbnQ0JCFB5btmyBSCRC586dFfrNnj1bod+IESPk52JjY+Hu7g4HBwf4+/tj0aJFmDlzJjZs2JCrWDm1TURERFSAZrZbtmyJli1bfvW8tbW1wvGhQ4fQuHFjODk5KbQbGBhk6fvZrl27kJKSgi1btkAikaB8+fIICAjA0qVLMXjw4BzHyookERERkRIlJycjNjZW4ZGcnJwnY4eFheHo0aMYMGBAlnMLFiyAmZkZqlSpgkWLFiEtLU1+zs/PDw0aNIBEIpG3eXh4IDAwEB8+fMjx6zORJCIiIrWnzDWSPj4+MDIyUnj4+PjkSdzbt2+HgYEBOnXqpND+008/Yc+ePTh37hyGDBmC+fPnY/z48fLzoaGhsLKyUnjO5+PQ0NAcvz6ntomIiIiUaNKkSfD29lZok0qleTL2li1b0LNnT2hrayu0//P1KlasCIlEgiFDhsDHxyfPXhsooonkL4NqqjoE+uRQYLiqQ6B/kGpwEqKgKGmtr+oQ6BOpJr8vSLnb/0il0jxN3j67dOkSAgMDsXfv3u/2rVWrFtLS0vDq1Su4uLjA2toaYWFhCn0+H39tXWV2+N1DREREVAht3rwZ1apVQ6VKlb7bNyAgAGKxGJaWlgAANzc3XLx4EampqfI+vr6+cHFxgYmJSY5jYCJJREREaq8g7SMZFxeHgIAABAQEAABevnyJgIAABAUFyfvExsZi3759GDhwYJbn+/n5Yfny5bh79y5evHiBXbt2YfTo0ejVq5c8SezRowckEgkGDBiAhw8fYu/evVixYkWWKfjvKZJT20RERES5UZA+2ebWrVto3Lix/Phzcufp6Ylt27YBAPbs2QOZTIbu3btneb5UKsWePXswc+ZMJCcnw9HREaNHj1ZIEo2MjHDq1Cl4eXmhWrVqMDc3x/Tp03O19Q8AiGQymUzANRZovo/fqzoE+uTU80hVh0D/0KVczte9kHJxjWTBwTWSBYeuRHXJnO2Q/UobO/iXTt/vVEixIklERERUcAqShQr/DCMiIiIiQViRJCIiIrVXkNZIFiasSBIRERGRIKxIEhERkdpjRVIYViSJiIiISBBWJImIiEjtsSIpDBNJIiIiIuaRgnBqm4iIiIgEYUWSiIiI1B6ntoVhRZKIiIiIBGFFkoiIiNQeK5LCsCJJRERERIKwIklERERqjxVJYViRJCIiIiJBWJEkIiIitceKpDBMJImIiIiYRwrCqW0iIiIiEoQVSSIiIlJ7nNoWhhVJIiIiIhKEFUkiIiJSe6xICsOKJBEREREJwookERERqT0WJIVhRZKIiIiIBGFFkoiIiNQe10gKw0SSiIiI1B7zSGE4tU1EREREgrAiSURERGqPU9vCsCJJRERERIKwIklERERqjwVJYViRJCIiIiJBWJEkIiIitScWsyQpBCuSRERERCQIK5JERESk9rhGUhgmkkRERKT2uP2PMJzaJiIiIiJBWJHMZ9GRETi0Yy0e3r6G1OQkmFsXR6+fJsOhZFkAwNHfNuP25dP48D4cGppasHd2Qdteg1GidHn5GCf2bcfDW1fx9uVTaGpqYdHuk6q6nEIj8vkDPDt/ANFvnyM5Ngo1+k6GjWtt+XmZTIbAk7vx+toppCbGw9SxLCp2HgZ9C9ssY6WnpeLSirGIDX6Jht7LYVTMSWGc5+cP4vW1k0j8EA6JniFK1G2F0s265Mt1FkZ//roBB3ZtUmizKe6ARRv3AQDOHjuAq+dP4tWzQCQlxuOXfWegp2+g0H/JzDEIevE3YqM/QFffABWq1ES3/sNhYmaRb9dRVNzxv4Vfd2xB4KOHeP8+Aj8vXYmGjZvJz58744sDf+zFk8cPERsTgx17/kRpl7IKY7x9E4RVyxbh7p3bSElNgVudevCeMAVmZub5fTlF2pZNG7BqxVL06NUH4yZMRvC7t2jdolm2fRcuXo7mHi3yOcLChQVJYZhI5qOEuFgsnTgUpVyr4sdpS6BvZIyI4DfQ1fvyS9HS1g7/G+wNcytbpKYk4+zhvVg9czRmrNsLAyMTAJmJTJW6jeHoUgF+p4+o6nIKlbSUZBjaOsK+ZjPc3OaT5fyzc/vx4tIRVOk+ErqmVgg8sQvXNsxA4/FroKElUej76Mg2aBuaIjb4ZZZxHhzciIjAOyjfth8MbByQmhCHlISPSruuoqK4gxMmzl8tP9bQ+PKjKSU5CRWru6FidTf8vnVNts8vV6ka2nftC2NTc0RFRuC3TSuwct5EzFi6WemxFzWJiQkoVdoFbdt3wsQxP2U5n5SYiEqVq6Jp8xbwmTM92+eP/HEQSpZ2weoNWwEAG9auxLiRXti04zeIxZwIywsPH9zHn3/sRanSLvI2K2sb+J67pNDvz32/Y8e2zahbv35+h0hqgolkPvLdvwsm5pbo/dMUeZu5lWLFq0ZDd4XjTv1/gt/pIwh+9RwulaoDAFp3HwgAuHbmqJIjLjqsylaDVdlq2Z6TyWR4cfEwSjfrApsKmVXKKt1H4+TMPgh9cA3FqjSQ9w177I+IwDuo4TkR4U/8Fcb5GPYGr64eR+Nxq6BvWTyz0Uw511PUiDU0YGyafbWqRcfuAIBH9/yzPQ8ALTv2kP/b3MoGbbp4YvnscUhLS4OmJn/M5Uadeg1Qp16Dr55v2aYdACA4+F225+8F3EFI8Dvs+O1P6OnrAwCmz/ZB84a1cevGNdSsXSfvg1YzCQnxmDxxLKbNmINNG9bJ2zU0NGBurliFP3f2NJp7tISurl5+h1nocI2kMPzTMB/dv3EZ9iXLYPPCqZjo2RoLRvfFlVOHv9o/LTUVV04dgo6uPoo5lszHSNVLQlQYkj9+gEXpSvI2LR09mNiXRtTrQHlb0scPuLtvNar2GA0NiTTLOKEPb0DXzBqhj27i9LyB8J07EAF7V7EimQNh795geM9WGN2vA9b+PA3vw0MFjxX3MQZXz51AqbIVmUSqQEpKCkQiEbQkXyr5EqkUYrEYdwNuqzCyosNn3mzUr98Itd2+nZQ/evgAgU8eo0OnzvkUGamjAp1IvnnzBv379/9mn+TkZMTGxio8UlKS8ynC3HkfFoxLJw7CwqY4vGYsQ70WHfHHpmW4dvaYQr/7N6/Au1szjO7SGOcO78XwWcuhb2ismqDVQHLsBwCA1MBYoV1qYCw/J5PJELBnBUq4tYCxXalsx0mICkPih3CE3L2CKt1Ho0q3kYh++wy3ti9QavyFXUmXChg8ZjrGz12BfsMnICIsGHPGDUZiQnyuxtmzeRUGdGiAoV2aIzI8FKNnLFJSxPQtFVwrQVtHB2tWLEFSYiISExOwculCpKenI/J9hKrDK/ROHD+KJ48eYcQo7+/2PXjgTzg6OaNy5ar5EFnhJxKJlPYoygp0IhkVFYXt27d/s4+Pjw+MjIwUHns2rMinCHNHJsuAnVNptOs9FHZOpVHPoz3qNG+HyycPKvQr7VoVk5Ztg/eC9ShXpTa2LJqGj9EfVBM0AQBeXj6CtKRElGr6w9c7yTKQkZaKKj1Gw8ypPMxLuqJy15/w/tl9xIW/zb9gC5lKNeqgVv1msHcshYrV3DB29nIkxH3E9UunczVO6x96Y+7qnZgwbxXEYg2sXzwLMplMSVHT15iYmmL+wmW4fPE8Gtetjmb1ayEu7iNcypaDSFSgf+UUeKGhIVi0YD7mLVgMqTTrrMg/JSUl4fixI6xGktKpdN7n8OGvT+sCwIsXL747xqRJk+DtrfiX2aWXBXMq0dDEDNZ2JRTarIuXQIDfeYU2qbYOLGyKw8KmOBxdKmDWsK64evovePzQJ/+CVSNSw8ybmJI/RkPb0FTenvwxGoaf7sh+//Qeol4H4sgExR/KF5d7o1jVhqjafTSkBqYQiTWgb1FMft7AKnOtZMKHiC/rJumb9PQNYF3MHmHBuUu+DYyMYWBkDJviDrC1K4GRfdri2ZP7KFW2opIipa+p5VYXf/51EtEfPkBDUwMGBoZo1aw+inm0VHVohdrjhw8RFRWJHl07ydvS09Nx2/8W9v62C9f970FDQwMAcNr3JJISk9CmbQcVRVv4FPHCodKoNJHs0KEDRCLRN6sG3ysJS6XSLH+ZSSQpeRJfXnMqUxHh74IU2sKDg2BqYf3N58kyMpCWmqrM0NSarqkVpAYmiHh6V76VT2pSAj4E/Y0SdTJ/8VXoOBhlWvaSPycpNgrXNsxAtd7jYWJfGgBg6lgWsox0xL8PgZ65DQAgLiL402tY5uclFWpJiQkID3kH46bCt4r5/DMlld83KmVskvlH2q0b1/AhKgr1GzZRcUSFW83atbFvv2IBZsa0yXB0dELf/gPlSSQAHNz/Bxo2bgxTU9N/D0NfUZCmoC9evIhFixbB398fISEhOHDgADp06CA/37dv3ywzth4eHjhx4oT8OCoqCiNGjMBff/0FsViMzp07Y8WKFdD/dBMcANy7dw9eXl64efMmLCwsMGLECIwfPz5Xsao0kbSxscHatWvRvn37bM8HBASgWrXs77QtjJq064olE4fg5L7tqFqvKV79/QhXTh1G9x8z37TkpESc3LcdrjXrwcjEHHGx0bh4fD+io96jat3G8nGiIkKR8DEWH96HISMjHW9f/A0AsLApDqmOrkquraBLS05E/PsQ+XFCVBhi3r2Alq4BdE0s4NSgHZ6e/h365rbQNbPCk+O7oG1oCutPd3HrmijeCakp1QYA6JlZQ8c4M+GxKFUJRsWdEbB3JSq0HwiZTIb7+9fDonRlhSolKdq9cQWq1KoPcytrfIh8j/2/boBYLIbbpx0MoqPeI+ZDFMKC3wAA3rx6Bh0dPZhZWkHfwAjPnjzAi78fwaV8ZejpGyAs5C3+2PkLLG2Ko1QZV1VeWqGUkBCPt2++/MEb/O4d/g58DENDI1jb2CImJhphoSF4Hx4OAHj96hUAwMzMHGaf7hg+cmg/Sjg6w9jEBPfvBWDZIh9069kHDiUc8/16ihI9PX2ULFVaoU1HRwdGxsYK7UFBr3Hb/xZWrd2Q3yFSHomPj0elSpXQv39/dOrUKds+LVq0wNatW+XH/y6q9ezZEyEhIfD19UVqair69euHwYMHY/fu3QCA2NhYuLu7o1mzZli/fj3u37+P/v37w9jYGIMHD85xrCpNJKtVqwZ/f/+vJpLfq1YWNg6lymLQRB8c3rkex3/fBjMrG3QeMBI1GnoAAMRiMcLevcb1n48jPjYGugaGcChVFqPnr4WN/ZdNr4/u3oTr547Ljxd49wMA/DRnFUq7clF1dqLfPMPVdV+2XXp4OHN/QbvqTVCl+yiUbNwJ6SlJuPvHmk8bkpdD7cEzs+wh+S0isRi1+k/F/QMbcHntZGhKpLAsUw3l2337hjF1F/U+HGt+noq42BgYGJnApXwlzFy2BYbGmdWsM8f2K2xYPnfcEADAYO/paNC8DaRSbdy6eg77f92A5KQkGJuaoWI1N7Sf1F/hzmHKmcePHsJrUF/58YolPwMAWrXtgOmz5+PShXOYO+PL99K0iWMAAAOG/IhBQ4cDyEwu165ahtiYGNjYFkPfAUPQvZdn/l2Emjt04E9YWVnDrU5dVYdSqBSggiRatmyJli2/vRREKpXC2jr7Gc3Hjx/jxIkTuHnzJqpXz9w6cNWqVWjVqhUWL14MW1tb7Nq1CykpKdiyZQskEgnKly+PgIAALF26NFeJpEimwkzt0qVLiI+PR4sW2e+2Hx8fj1u3bqFhw4a5Gtf38fu8CI/ywKnnkaoOgf6hS7lvL6Og/FPSWv/7nShfSDV5E1BBoStRXTZXdfZZpY3tN6EukpMVd5TJbmledkQiUbZT2wcPHoREIoGJiQmaNGmCuXPnwswsc/PiLVu2YMyYMfjw4cuNumlpadDW1sa+ffvQsWNH9OnTB7GxsTh48KC8z7lz59CkSRNERUXB5NPSlO9R6XdP/fr1v5pEAoCenl6uk0giIiKi3FLm9j/Z7TDj45P1U9ZyqkWLFtixYwfOnDmDn3/+GRcuXEDLli2Rnp4OAAgNDYWlpeLafE1NTZiamiI0NFTex8rKSqHP5+PPfXKCu/USERERKVF2O8zkpBr5Nd26dZP/29XVFRUrVoSzszPOnz+Ppk2bCh5XCCaSREREpPaUuUYyp9PYQjk5OcHc3BzPnj1D06ZNYW1tjfBPN8R9lpaWhqioKPm6Smtra4SFhSn0+Xz8tbWX2eHCECIiIqJC7O3bt4iMjISNTebWc25uboiOjoa/v7+8z9mzZ5GRkYFatWrJ+1y8eFFhmzRfX1+4uLjkeH0kwESSiIiIqEB9RGJcXBwCAgIQEBAAAHj58iUCAgIQFBSEuLg4jBs3DteuXcOrV69w5swZtG/fHiVLloSHR+YuMGXLlkWLFi0waNAg3LhxA1euXMHw4cPRrVs32NraAgB69OgBiUSCAQMG4OHDh9i7dy9WrFiRZQr+e5hIEhERERUgt27dQpUqVVClShUAgLe3N6pUqYLp06dDQ0MD9+7dQ7t27VC6dGkMGDAA1apVw6VLlxSmz3ft2oUyZcqgadOmaNWqFerVq4cNG77sLWpkZIRTp07h5cuXqFatGsaMGYPp06fnausfQMXb/ygLt/8pOLj9T8HC7X8KDm7/U3Bw+5+CQ5Xb/9Scf15pY9+Y3EhpY6sab7YhIiIitVeQPiKxMOGfYUREREQkCCuSREREpPZYkBSGFUkiIiIiEoQVSSIiIlJ7XCMpDCuSRERERCQIK5JERESk9liQFIYVSSIiIiIShBVJIiIiUntcIykME0kiIiJSe8wjheHUNhEREREJwookERERqT1ObQvDiiQRERERCcKKJBEREak9ViSFYUWSiIiIiARhRZKIiIjUHguSwrAiSURERESCsCJJREREao9rJIVhIklERERqj3mkMJzaJiIiIiJBWJEkIiIitcepbWFYkSQiIiIiQViRJCIiIrXHgqQwrEgSERERkSCsSBIREZHaE7MkKQgrkkREREQkCCuSREREpPZYkBSGiSQRERGpPW7/IwyntomIiIhIEFYkiYiISO2JWZAUhBVJIiIiIhKEFUkiIiJSe1wjKQwrkkREREQkCCuSREREpPZYkBSmSCaSpSz1VR0CfaKvVST/Fyu0zrx6r+oQ6BMNDf7WKiic+TujAOH3RWHD3/JERESk9kRMYgVhIklERERqj9v/CMObbYiIiIhIEFYkiYiISO1x+x9hWJEkIiIiIkFYkSQiIiK1x4KkMKxIEhEREZEgTCSJiIhI7YlFIqU9cuvixYto27YtbG1tIRKJcPDgQfm51NRUTJgwAa6urtDT04OtrS369OmD4OBghTFKlCgBkUik8FiwYIFCn3v37qF+/frQ1taGnZ0dFi5cmPuvW26fsH37dhw9elR+PH78eBgbG6NOnTp4/fp1rgMgIiIioi/i4+NRqVIlrFmzJsu5hIQE3L59G9OmTcPt27exf/9+BAYGol27dln6zp49GyEhIfLHiBEj5OdiY2Ph7u4OBwcH+Pv7Y9GiRZg5cyY2bNiQq1hzvUZy/vz5WLduHQDAz88Pa9aswbJly3DkyBGMHj0a+/fvz+2QRERERCpVkNZItmzZEi1btsz2nJGREXx9fRXaVq9ejZo1ayIoKAj29vbydgMDA1hbW2c7zq5du5CSkoItW7ZAIpGgfPnyCAgIwNKlSzF48OAcx5rriuSbN29QsmRJAMDBgwfRuXNnDB48GD4+Prh06VJuhyMiIiJSuX9PA+flIzk5GbGxsQqP5OTkPIs9JiYGIpEIxsbGCu0LFiyAmZkZqlSpgkWLFiEtLU1+zs/PDw0aNIBEIpG3eXh4IDAwEB8+fMjxa+c6kdTX10dkZCQA4NSpU2jevDkAQFtbG4mJibkdjoiIiKhI8/HxgZGRkcLDx8cnT8ZOSkrChAkT0L17dxgaGsrbf/rpJ+zZswfnzp3DkCFDMH/+fIwfP15+PjQ0FFZWVgpjfT4ODQ3N8evnemq7efPmGDhwIKpUqYK///4brVq1AgA8fPgQJUqUyO1wRERERCqnzKntSZMmwdvbW6FNKpX+53FTU1PRpUsXyGQy+bLDz/75ehUrVoREIsGQIUPg4+OTJ6/9Wa4rkmvWrIGbmxsiIiLw559/wszMDADg7++P7t2751lgREREREWBVCqFoaGhwuO/JnOfk8jXr1/D19dXoRqZnVq1aiEtLQ2vXr0CAFhbWyMsLEyhz+fjr62rzE6uK5LGxsZYvXp1lvZZs2bldigiIiKiAkHINj2q8jmJfPr0Kc6dOycv6n1LQEAAxGIxLC0tAQBubm6YMmUKUlNToaWlBQDw9fWFi4sLTExMchxLjhLJe/fu5XjAihUr5rgvERERESmKi4vDs2fP5McvX75EQEAATE1NYWNjgx9++AG3b9/GkSNHkJ6eLl/TaGpqColEAj8/P1y/fh2NGzeGgYEB/Pz8MHr0aPTq1UueJPbo0QOzZs3CgAEDMGHCBDx48AArVqzAsmXLchWrSCaTyb7XSSwWQyQS4WtdP58TiURIT0/PVQDK8CoySdUh0CchH/heFCQXgiJVHQJ94u5soeoQ6BNnS31Vh0CfGOmo7nNSum2/o7Sx93hWyVX/8+fPo3HjxlnaPT09MXPmTDg6Omb7vHPnzqFRo0a4ffs2fvzxRzx58gTJyclwdHRE79694e3trTClfu/ePXh5eeHmzZswNzfHiBEjMGHChFzFmqOK5MuXL3M1KBEREREJ06hRo68W7wB88xwAVK1aFdeuXfvu61SsWPE/b92Yo0TSwcHhP70IERERUUEmKkRrJAsSQTXknTt3om7durC1tZV/LOLy5ctx6NChPA2OiIiIKD+IRcp7FGW5TiTXrVsHb29vtGrVCtHR0fI1kcbGxli+fHlex0dEREREBVSuE8lVq1Zh48aNmDJlCjQ0NOTt1atXx/379/M0OCIiIqL8oMyPSCzKcp1Ivnz5ElWqZL37SCqVIj4+Pk+CIiIiIqKCL9eJpKOjIwICArK0nzhxAmXLls2LmIiIiIjylUikvEdRlutPtvH29oaXlxeSkpIgk8lw48YN/Pbbb/Dx8cGmTZuUESMRERERFUC5TiQHDhwIHR0dTJ06FQkJCejRowdsbW2xYsUKdOvWTRkxEhERESlVUV/LqCy5TiQBoGfPnujZsycSEhIQFxcn/9xGIiIiIlIfghJJAAgPD0dgYCCAzCzewoIf90VERESFU1Hf71FZcn2zzcePH9G7d2/Y2tqiYcOGaNiwIWxtbdGrVy/ExMQoI0YiIiIipeL2P8LkOpEcOHAgrl+/jqNHjyI6OhrR0dE4cuQIbt26hSFDhigjRiIiIiIqgHI9tX3kyBGcPHkS9erVk7d5eHhg48aNaNGiRZ4GR0RERJQfinbdUHlyXZE0MzODkZFRlnYjIyOYmJjkSVBEREREVPDlOpGcOnUqvL29ERoaKm8LDQ3FuHHjMG3atDwNjoiIiCg/iEUipT2KshxNbVepUkVhsejTp09hb28Pe3t7AEBQUBCkUikiIiK4TpKIiIhITeQokezQoYOSwyAiIiJSnSJeOFSaHCWSM2bMUHYcRERERFTICN6QnIiIiKioKOr7PSpLrhPJ9PR0LFu2DL///juCgoKQkpKicD4qKirPgiMiIiKigivXd23PmjULS5cuRdeuXRETEwNvb2906tQJYrEYM2fOVEKIRERERMolEinvUZTluiK5a9cubNy4Ea1bt8bMmTPRvXt3ODs7o2LFirh27Rp++uknZcRZJOzZsRlXzp/Bm6CXkEikKOdaGQN+HAU7hxIAgNCQd/Ds3Crb506ZuwgNmrjj+dNA/L5zCx7cu4PY6GhY2diidYf/oWPXnvl4JYXfgV0bcWj3JoU26+IOWPDL7wAAn4nDEHj/tsL5Ri07ou/wiQCAS75HsHn5nGzHXrnrOAyNTZUQddGVmpSA24d34vXdq0j6GANTO2fU+t8QWJQonaXv1d2rEHjpOGr+MBjlm3aQt8eEvcXN/VsQ/vwRMtJTYVLMEVXb9oaNS6V8vJKi5dCebdizZQ1adOwGz2FjEBEajJ/6tM+278ipPqjdoBk+xkZj9YJpCHrxDHEfY2BoZILqdRqia78foaunn89XUPTEx8fjlzUrcP7caXyIikJpl7IYM34yylVwBQBsWLcaviePISw0FFpaWihTrhyGDR+FCq78Pvieor5Nj7LkOpEMDQ2Fq2vm/7D6+vryz9du06YN95H8jnt3bqFt564oXbY80tPTsW39KkweNRQbd++Hto4uLCyt8dtfZxSec+zQH/hj93bUqJ35SULPAh/B2MQUE2bMh4WlNR7dD8CKn+dArCFG+x+6q+KyCq1iDk4YN3e1/FhDQ0PhfEOP9ujY68t2VlJtqfzftRo0g2s1N4X+m5bNRmpqCpNIAS7/ugLRwa/RoO9Y6BqZ4fmNszi5YjI6zlgPPWNzeb/XAVcR8TIQukZmWcY4vXYmDC2LocUoH2hIJHh05iBOr52JzrM3Q9eI70luPQ98iDNHD8DeqZS8zczCCuv2HFfod+bYARzZ9ysq16gDABCJxKju1hBd+g6DoZEJwoLfYOuqhYj7GIsRk+bm6zUURfNmTcXzZ08xc+7PsLCwxPGjf8FraH/s/fMILK2sYO9QAuMmTkWx4nZISkrCb7u2Y8Swgdh/+CRMTPl9QHkv11PbxYsXR0hICADA2dkZp06dAgDcvHkTUqn0W09Ve/OXrYN76/Yo4VQSzqVcMGbqbISHheDpk8cAMhMZUzNzhcfVC2fRoIk7dHR1AQAebTpi2OgJqFilOmyKFUfTFm3g3ro9rpw/862XpmyIxRowNjWTPwyMjBXOS7S1Fc7r6H6ppkikiufEGmI8vncLDdzb5vNVFH5pKcl4fecKqnfsD+tSrjC0tEWVNr1gaGGLJxeOyvvFR7/Htb3r0KDfOIj/lfQnxcUgNjwYru7/g2lxRxhZFkP1jv2QlpKM6ODX+X1JhV5SYgJWL5iOQaMnQ0/fQN4u1tCAsam5wuPmlfOo3aAZtHUyf0bpGxiiedsf4Fy6HCysbFChSk00b/sDnty/o6rLKTKSkpJw7owvRowai6rVasDO3gGDhw2HnZ09/tz3GwCgRas2qFm7DooVt4NzyVIYNWYi4uPi8PRpoIqjL/g4tS1MrhPJjh074syZzKRlxIgRmDZtGkqVKoU+ffqgf//+eR5gURYfHwcAMDA0zPb80yeP8PxpIDzadvz2OHEfYWCY9WMr6dvCgt9gVO/WGNe/I9Yvmo7I8FCF89fOncTw7u6Y8mN37Nu2BslJSV8d68qZY5BItVGjbhNlh13kyDLSIcvIgIaWRKFdQyJB+PNHn/pk4OLWxajQvDNMbB2yjCHVM4SRVXE8v34GqclJyEhPx5NLx6FtYAwz+5L5ch1FyZZVC1GlZl24Vq31zX4v/n6M18//RuMW7b7aJyoyAjeunEPZilXzOky1k56ejvT0dEj+VbSRSrVx987tLP1TU1Nw8M/foa9vgNKly+RXmKRmcj21vWDBAvm/u3btCgcHB1y9ehWlSpVC27asxuRURkYG1i9fiPIVK6OEc6ls+5z46wDsSzihvGvlr47z8H4ALpw5hTmLVykp0qLJ2aU8Bo6eDpvi9oiOisSh3Zswf/wQzF27Gzq6enBr6A4zSxsYm5njzctn2Ld1NULfBmHE1J+zHe/SqcNwa+gBiVQ7n6+k8NPS1oWFU1ncPfYbjK3toG1ojJc3LyDixRMYWNgAAO6f2gexhgbKNc5+fZ5IJILHyPk4s342fh3dGSKRCNoGxnAfMQdSPYNsn0PZu3ruFF49e4K5q7d/t++5E4dQzN4RpctnXX+3cv4U+PtdQEpyMqrWro/B3lOVEa5a0dPTg2vFytiyYR0cHZ1hamaGUyeO4v69ABS3s5f3u3TxHKZOGIukpESYm1tg9frNMDYxUWHkhQO3/xEm1xXJf6tduza8vb1Rq1YtzJ8/P9fPT0xMxOXLl/Ho0aMs55KSkrBjx45vPj85ORmxsbEKj+Tk5FzHkd9WL5mP1y+eY9LshdmeT05Owjnf4/Bo0+GrY7x6/hSzJoxCr/5DUK1WHSVFWjRVrF4HNes3hZ1jKbhWq43Rs5YhIf4jblzKrLY3atkRrtVqw65ESdRp3AKDxsyEv995hIe8zTLWs8f3EfzmFae1/4MGfcdCBhn2TuqNHSPa49G5w3Cs0RAisRjvXz/Fo3OHUb+P91d/0MtkMvjtWQttA2O0GrMQbSYsh0MlN5xeOxMJMdySLKciw0Oxfd0SeE2cA4nk20uVUpKTcPXcSTT6SjWyz9DRmL/mV4yZtRhhIW+xc/0yZYSsdmbN+xkyyNDavSHq1ayEvbt/hXuL1hCLv/w6r16jFn7dux+btu9G7br1MGn8aERFRaowairK8mxD8pCQEEybNg2TJ0/O8XP+/vtvuLu7IygoCCKRCPXq1cOePXtgY5NZhYiJiUG/fv3Qp0+fr47h4+ODWbNmKbSNHDcFoyYU3L9+Vy+Zj+tXLmLJ2i2wsLTKts+ls75ITkpEs5bZJyevXz7HhJ8Go2W7zujRb7Ayw1ULevoGsC5mj/CQN9med3YpDwAIC34LS5viCucunDwEe6fSKFGqrNLjLKoMLWzQynshUpOTkJqUAF0jU5zb5AMDc2uEPXuIxI/R+H2Kp7y/LCMDN//chEdnD+J/87YhJPAu3t6/gR5Lfofk01o9c/uSePf4Dp5dO42KHl1UdWmFyounTxAbHYXJP/aWt2VkpOPJ/Ts4dWgfdh69Il+fev3SWSQnJ6FBs9bZjvV5DWUx+xLQNzDCLO9B6NRzIEzMzLPtTzlT3M4ev2zeicTEBMTHxcHcwhKTx49GsWJffi7p6OjCzt4BdvYOcK1YGZ3beuDwgT/RdwB/V3zLf66sqSmVfrLNhAkTUKFCBdy6dQvR0dEYNWoU6tati/Pnz8Pe3v77AwCYNGkSvL29FdpC4mTKCPc/k8lkWLPUB1cvnMWiNZthbVv8q31PHjmI2vUawdgk6112r148w4QRg9C8VTv0GzpCmSGrjaTEBISHvEOdJi2zPR/04m8AgLGp4t3CSYkJuHn5DH7w/FHpMaoDLak2tKTaSI7/iOBHt1G9Y384VKkL2zKVFfqdWjUNzrWaoJRbcwCZN+wAWaemRCIRZBkF8+dBQVShSg0s/OU3hbb1S2bD1q4E2nXpo3CT07kTh1CtdgMYGn9/ylSWkQEASEtN+U5PyikdHV3o6OgiNjYG165ewYhRY7/aN0Mmy/LhIUR5RaWJ5NWrV3H69GmYm5vD3Nwcf/31F3788UfUr18f586dg56e3nfHkEqlWe4Wj0r9+k0RqrR68Xyc8z2OmT8vh46uHqIi3wMA9PT1If3H2rp3b4NwP8Afc5asyTLGq+dPMX7EIFSvVQeduvWWjyEWi7NNOil7ezatQOVa9WFmaY3oyPc4uGsjxGIxajV0R3jIW/idP4lK1etAz9AIb18+w+6Ny+FSoQrsHBXXs16/eBrp6elwa9xCRVdSNLx75A+ZTAYjq+KIjQjGrf1bYGRVHKXqNIdYQxPa+oo3pIk1NKBjaAIj68w/xiydykCiq49L25egcuse0NCS4O/LJxEXGQY71xqquKRCSUdXD3aOijcnSbV1oG9opNAe+u4Nnty/g/Fzl2cZ486NK4j5EAnn0uWgraOLN69fYPfGlXApXwkW1rbKvoQiz+/qZUAmg30JR7wNeo2VyxajhKMj2rbviMTEBGzd+AvqN2oMc3MLREdH44+9uxERHoamzT1UHXqBxzWSwqg0kUxMTISm5pcQRCIR1q1bh+HDh6Nhw4bYvXu3CqPLe0cOZG52Pc5rgEL7mCmz4d76y00EJ48chLmlFarVVNynEAAunTuNmOgPOHPyKM6c/LI1ipW1LXbsP56lP2UvKjIc6xdOQ1xsDAyMjFGqfCVMW7oZhkYmSE1JwaOAmzh1aA+Sk5JgZmGJ6nUbo123flnGuXTqMKrVaaSwRQrlXkpiPPwPbkN89HtIdQ3gUKUuqrX3hFgjZz+itPWN4D5iNvwP7cCJ5ZOQkZ4GYxsHNB06DabFnZQcvfo5f/IwTM0tUbFa7SznJBIpzh4/iJ3rlyE1NRVmFlaoWa8R2nXtm/+BFkFxHz9i7aplCA8LhaGREZo0dcew4aOgqaWF9IwMvHr1AkfHHER09AcYGRujXHlXbNjyK5xLZn9TJ30hZh4piEgmk+Vo3uff08f/FhERgd27dyM9PT3HL16zZk2MGDECvXv3znJu+PDh2LVrF2JjY3M1JgC8iiyYFUl1FPKB70VBciGIC+4LCndnC1WHQJ84W/ITdwoKIx3VrVQcdeiJ0sZe3r7obr+U44rknTvf30y2QYMGuXrxjh074rfffss2kVy9enXmFjnr1+dqTCIiIqLcYkVSmBxXJAsTViQLDlYkCxZWJAsOViQLDlYkCw5VViS9DyuvIrm0HSuSREREREUWb7YRhtsmEREREZEgrEgSERGR2uMaSWFYkSQiIiIiQViRJCIiIrXHJZLCCKpIXrp0Cb169YKbmxvevXsHANi5cycuX76cp8ERERER5QexSKS0R1GW60Tyzz//hIeHB3R0dHDnzh0kJ2d+xm1MTAzmz5+f5wESERERUcGU60Ry7ty5WL9+PTZu3AgtLS15e926dXH79u08DY6IiIgoP4iV+CjKcn19gYGB2X6CjZGREaKjo/MiJiIiIiIqBHKdSFpbW+PZs2dZ2i9fvgwnJ6c8CYqIiIgoP4lEynvk1sWLF9G2bVvY2tpCJBLh4MGDCudlMhmmT58OGxsb6OjooFmzZnj69KlCn6ioKPTs2ROGhoYwNjbGgAEDEBcXp9Dn3r17qF+/PrS1tWFnZ4eFCxfmOtZcJ5KDBg3CyJEjcf36dYhEIgQHB2PXrl0YO3Yshg0blusAiIiIiOiL+Ph4VKpUCWvWrMn2/MKFC7Fy5UqsX78e169fh56eHjw8PJCU9OVjiXv27ImHDx/C19cXR44cwcWLFzF48GD5+djYWLi7u8PBwQH+/v5YtGgRZs6ciQ0bNuQq1lxv/zNx4kRkZGSgadOmSEhIQIMGDSCVSjF27FiMGDEit8MRERERqVxBuru6ZcuWaNmyZbbnZDIZli9fjqlTp6J9+/YAgB07dsDKygoHDx5Et27d8PjxY5w4cQI3b95E9erVAQCrVq1Cq1atsHjxYtja2mLXrl1ISUnBli1bIJFIUL58eQQEBGDp0qUKCef35LoiKRKJMGXKFERFReHBgwe4du0aIiIiMGfOnNwORURERFTkJScnIzY2VuHxedeb3Hr58iVCQ0PRrFkzeZuRkRFq1aoFPz8/AICfnx+MjY3lSSQANGvWDGKxGNevX5f3adCgASQSibyPh4cHAgMD8eHDhxzHI/hmIolEgnLlyqFmzZrQ19cXOgwRERGRyilzjaSPjw+MjIwUHj4+PoLiDA0NBQBYWVkptFtZWcnPhYaGwtLSUuG8pqYmTE1NFfpkN8Y/XyMncj213bhxY4i+Uf49e/ZsbockIiIiUillftb2pEmT4O3trdAmlUqV94L5KNeJZOXKlRWOU1NTERAQgAcPHsDT0zOv4iIiIiIqEqRSaZ4ljtbW1gCAsLAw2NjYyNvDwsLkOZq1tTXCw8MVnpeWloaoqCj5862trREWFqbQ5/Px5z45ketEctmyZdm2z5w5M8tt5URERESFQUG62eZbHB0dYW1tjTNnzsgTx9jYWFy/fl2+e46bmxuio6Ph7++PatWqAcicMc7IyECtWrXkfaZMmYLU1FT5B8z4+vrCxcUFJiYmOY4nzzZc79WrF7Zs2ZJXwxERERGppbi4OAQEBCAgIABA5g02AQEBCAoKgkgkwqhRozB37lwcPnwY9+/fR58+fWBra4sOHToAAMqWLYsWLVpg0KBBuHHjBq5cuYLhw4ejW7dusLW1BQD06NEDEokEAwYMwMOHD7F3716sWLEiyxT89+S6Ivk1fn5+0NbWzqvhiIiIiPJNQSpI3rp1C40bN5Yff07uPD09sW3bNowfPx7x8fEYPHgwoqOjUa9ePZw4cUIhD9u1axeGDx+Opk2bQiwWo3Pnzli5cqX8vJGREU6dOgUvLy9Uq1YN5ubmmD59eq62/gEAkUwmk+XmCZ06dVI4lslkCAkJwa1btzBt2jTMmDEjVwEow6vIpO93onwR8oHvRUFyIShS1SHQJ+7OFqoOgT5xtuTOIwWFkY7qPpl6zumsn9qXV6Y1K6m0sVUt1xVJIyMjhWOxWAwXFxfMnj0b7u7ueRYYERERUX5R5l3bRVmuEsn09HT069cPrq6uuVqISURERERFT65qyBoaGnB3d0d0dLSSwiEiIiLKfyIl/leU5XoxQoUKFfDixQtlxEJERESkEmKR8h5FWa4Tyblz52Ls2LE4cuQIQkJCsnx2JBERERGphxyvkZw9ezbGjBmDVq1aAQDatWun8FGJMpkMIpEI6enpeR8lERERkRIV9cqhsuQ4kZw1axaGDh2Kc+fOKTMeIiIiIiokcpxIft5usmHDhkoLhoiIiEgVRAVpR/JCJFdrJPlFJiIiIqLPcrWPZOnSpb+bTEZFRf2ngIiIiIjyG9dICpOrRHLWrFlZPtmGiIiIiNRTrhLJbt26wdLSUlmxEBEREakEV+8Jk+NEkusjiYiIqKgSM88RJMc323y+a5uIiIiICMhFRTIjI0OZcRARERGpDG+2ESbXH5FIRERERATk8mYbIiIioqKISySFYUWSiIiIiARhRZKIiIjUnhgsSQpRJBNJM32JqkOgTwy0i+T/YoWWjkRD1SHQJ1OPP1F1CPTJlKalVB0CfeJW0ljVIVAu8bc8ERERqT2ukRSGiSQRERGpPW7/IwxvtiEiIiIiQViRJCIiIrXHj0gUhhVJIiIiIhKEFUkiIiJSeyxICsOKJBEREREJwookERERqT2ukRSGFUkiIiIiEoQVSSIiIlJ7LEgKw0SSiIiI1B6naIXh142IiIiIBGFFkoiIiNSeiHPbgrAiSURERESCsCJJREREao/1SGFYkSQiIiIiQViRJCIiIrXHDcmFYUWSiIiIiARhRZKIiIjUHuuRwjCRJCIiIrXHmW1hOLVNRERERIKwIklERERqjxuSC8OKJBEREVEBUaJECYhEoiwPLy8vAECjRo2ynBs6dKjCGEFBQWjdujV0dXVhaWmJcePGIS0tTSnxsiJJREREaq+gVNZu3ryJ9PR0+fGDBw/QvHlz/O9//5O3DRo0CLNnz5Yf6+rqyv+dnp6O1q1bw9raGlevXkVISAj69OkDLS0tzJ8/P8/jZSJJREREVEBYWFgoHC9YsADOzs5o2LChvE1XVxfW1tbZPv/UqVN49OgRTp8+DSsrK1SuXBlz5szBhAkTMHPmTEgkkjyNt6Ak4EREREQqk910cl49kpOTERsbq/BITk7+bkwpKSn49ddf0b9/f4U1nLt27YK5uTkqVKiASZMmISEhQX7Oz88Prq6usLKykrd5eHggNjYWDx8+zNsvGphIEhERESmVj48PjIyMFB4+Pj7ffd7BgwcRHR2Nvn37ytt69OiBX3/9FefOncOkSZOwc+dO9OrVS34+NDRUIYkEID8ODQ3Nmwv6B05tExERkdpT5j3bkyZNgre3t0KbVCr97vM2b96Mli1bwtbWVt42ePBg+b9dXV1hY2ODpk2b4vnz53B2ds67oHOIiSQRERGREkml0hwljv/0+vVrnD59Gvv37/9mv1q1agEAnj17BmdnZ1hbW+PGjRsKfcLCwgDgq+sq/wtObRMREZHaU+YaSSG2bt0KS0tLtG7d+pv9AgICAAA2NjYAADc3N9y/fx/h4eHyPr6+vjA0NES5cuUExfItrEgSERGR2itIlbWMjAxs3boVnp6e0NT8kqo9f/4cu3fvRqtWrWBmZoZ79+5h9OjRaNCgASpWrAgAcHd3R7ly5dC7d28sXLgQoaGhmDp1Kry8vHJdFc0JJpJEREREBcjp06cRFBSE/v37K7RLJBKcPn0ay5cvR3x8POzs7NC5c2dMnTpV3kdDQwNHjhzBsGHD4ObmBj09PXh6eirsO5mXmEgSERGR2itIH5Ho7u4OmUyWpd3Ozg4XLlz47vMdHBxw7NgxZYSWRUGq5BIRERFRIcKKJBEREam9glOPLFxYkSQiIiIiQViRJCIiIrVXgJZIFiqsSBIRERGRIKxIEhERkdoTc5WkIEwkiYiISO1xalsYJpIq1LZFU4QEB2dp/1/X7pgwZTrmzZ6BG9f88D4iHDq6uqhYqQp+Gj0GJRydVBBt0XLH/xZ279iCwMeP8P59BHyWrETDxk2z7btw3iwc/PN3jBwzAV179pG3x8ZEY+nC+bh88TzEIjEaNW2OUeMmQldXL78uo0g6uGcbftu8Gi07dkffH8cAAGaNGYxH924r9GvWuhMGjZosP+7avHqWsX6aPA91G3soN+BCrLyNPjpXsoGzuS7M9CSYe/Iprr2Klp/vUc0W9Z1NYaEvQVqGDM8i4rHj5jv8HR4v76Mv1cDQug6o6WCMDJkMV19+wIYrQUhKywAAuNoYoH1FK5S20IOuRAPBMcnYfzcE559F5fflFjoHdm3Eod2bFNqsiztgwS+/AwB8Jg5D4H3F74tGLTui7/CJAIBLvkewefmcbMdeues4DI1NlRA1qRsmkiq0Y/c+pGeky4+fP3sKr8ED0NS9BQCgbLnyaNmqDaxtbBEbE41f1q2B15CBOHzcFxoaGqoKu0hISkpEydIuaNO+EyaNHfnVfhfOnsbD+3dhbmGZ5dzMKRMQ+T4CK9ZuQlpaKubNnIqf587ErPmLlBl6kfYs8CFOH90Pe6dSWc41bdURXTyHyI8lUu0sfYaNnYHKNdzkx7r6BsoJtIjQ1tTAi8gE+D6JwBSPrF/zdzFJWH8lCKGxyZBqitDe1RpzWpXGoD33EZuUBgAY28QJproSTD0aCE2xCKMaOWJ4gxJYfPYFAKCMtT5eRSbij4BQRCemoqa9MUY3dkJ8SjpuBsXk6/UWRsUcnDBu7mr58b9/9jf0aI+Ovb58X0i1v3wEXq0GzeBazU2h/6Zls5GamsIkMhsiTm0LwkRShUxMFb+Rt2/eiOJ29qhWvQYAoNMPXeTnbIsVw48jRqL7Dx0QEvwOxe3s8zXWosatbn241a3/zT4R4WFYunA+lq3ZgLE/DVM49+rFc1y7ehmbf92LsuUqAAC8x0/GmJ+GYfjocbDIJvGkb0tKTMBqn2kYPHoKDuzanOW8RKoNY1Pzb46hp2/w3T70hf+bGPi/+Xoyd+FfVcNNfkHwKGsBRzMd3H33EcWNtVHd3hij/nyIZ+8TAADrr7zGzJalseXaG0QlpGLfnRCFMQ4/CEOV4oao42jCRDIHxGINGJuaffW8RFv7q+clUm2FP7hiYz7g8b1b6D9ySp7HSeqLd20XEKmpKTh29C+069Ap249pSkxIwOGD+1GsWHFYWVurIEL1kpGRgVlTJ6JHn35wci6Z5fyDe3dhYGAoTyIBoHotN4jFYjy6fy8/Qy0yNq/6GVVq1UXFqrWyPX/57HEM7NwUYwZ1we7Nq5GclJTtGAM7N8Xk4X1w7sShbD9ijITRFIvQoqwl4pLT8DIyEQBQ1kofcclp8iQSAALexkImA1wsv77EQ1eigY/J6V89T1+EBb/BqN6tMa5/R6xfNB2R4aEK56+dO4nh3d0x5cfu2LdtTbbfF59dOXMMEqk2atRtouywCyWRSHmPokzlFcnHjx/j2rVrcHNzQ5kyZfDkyROsWLECycnJ6NWrF5o0+fb/8MnJyUhOTlZoS4EWpFLpV55RMJ0/ewZxHz+ibfuOCu379uzGymVLkJiYAIcSjlizYTO0tCQqilJ9/LptMzQ0NdGle69sz0dGvs9SUdbU1ISBoREiI9/nR4hFypVzJ/Hy6RPMX7Mj2/N1m7SAuaUNTM0t8PrFU+zetArBb15j7Mwvywi6eA5F+crVIdXWxr1b17B55c9ISkxEy47d8usyiqQa9kYY38wZUk0xPiSkYtrRv+XT2sa6WohOTFXonyEDPianwVhXK9vx6jmZoLSlHtZceqXs0As9Z5fyGDh6OmyK2yM6KhKHdm/C/PFDMHftbujo6sGtoTvMLG1gbGaONy+fYd/W1Qh9G4QRU3/OdrxLpw7DraFHtstCiIRSaSJ54sQJtG/fHvr6+khISMCBAwfQp08fVKpUCRkZGXB3d8epU6e+mUz6+Phg1qxZCm0Tp0zH5GkzlB1+njp04E/UqVsfFpaKU6ItW7dFLbc6eB8RgZ3bt2Li2NHYvGN3oUuUC5Mnjx7i9992YuvuP7KtDlPeeh8eiu1rl2DKz2sgkWT//3Wz1p3k/7Z3LAkTU3PMGT8MocFvYW1bHADQuddAeR/HkmWQnJSEv/btZCL5H90L/oif/ngIQ21NeJS1wIRmzhhz4BFiPiWTueFqa4BRjRyx6sIrBH34euWMMlWsXkf+bzvHUnByKY+x/drjxqUzaOjRDo1afik82JUoCWNTcyyc7IXwkLewtCmuMNazx/cR/OYVBo+ZmV/hFzrc/kcYlU5tz549G+PGjUNkZCS2bt2KHj16YNCgQfD19cWZM2cwbtw4LFiw4JtjTJo0CTExMQqPMeMn5tMV5I2Q4He4cc0P7Tv/kOWcvoEB7B1KoGr1Gli4dDlevXyJc2dOqyBK9XH3jj8+REWhU6tmqF+jIurXqIjQkGCsWrYInVo3BwCYmZnjQ5Ti+rG0tDR8jI2BmRnX6OXGy6dPEBMdhYnDeqG7Ry1096iFR/du48TBPejuUQsZ6VmnQEuWyVxSEPruzVfHLVm2AiIjwpCakqK02NVBcloGQmKTERgej5UXXiFDJoN7GQsAQHRCKox1FCuPYhFgINVEdIJipbKCjQGmtyiFjX5vcPZpZL7FX5To6RvAupg9wkOy///e2aU8ACAs+G2WcxdOHoK9U2mUKFVWqTGS+lFpRfLhw4fYsSNzKqtLly7o3bs3fvjhSzLVs2dPbN269ZtjSKXSLNW5j8kZeR+sEh0+eAAmpqaoV7/hN/vJZIAMMqSm8hejMrVo3Q7Vayne6TjaazBatG6L1u0yKwAVKlbCx4+xePLoIcqUy/zh7X/zOjIyMlDOtWK+x1yYVahSA4s27FFoW7d4NorZOaBdV0+Is9mh4NXzQACAyTeS9lfPAqFnYAgtCZeC5CURAC2NzMrN47A46Es14Wyui+ef1klWKmYIkQgI/McWQa42BpjeshS2XX+Lk48jVBF2kZCUmIDwkHeo06RltueDXvwNAFluvklKTMDNy2fwg+ePSo+xMOMElDAqXyP5eepQLBZDW1sbRkZG8nMGBgaIiSnad/VlZGTgr0P70aZdB2hqfnk73r59A98Tx1G7Tl2YmJggLCwM2zZvhLZUirr1Gqgw4qIhISEeb98EyY9D3r3F34GPYWhoBGsbWxgZGyv019TUhJmZORxKOAIASjg5o3adelgwdwbGT56OtLQ0LP15Hpp5tOQd27mko6sHe0fFG5q0tbWhb2gMe8eSCA1+iytnT6BKzbrQNzRC0Iun2LF+Kcq6VoXDp22C/P0uIvpDFEqVrQCJRIp7t6/j4J6taPNDb1VcUqGhrSmGjdGXP8StDKRwNNNBXHI6YpPS0LWqDa6/ikZUQioMtTXRprwlzPQkuPwisxr/NjoJt4KiMaJBCay99BoaYhGG1nXAxWdRiPpUkXS1NcCMFqVw+EEYrryIgrFO5s+5tAwZ4njDzTft2bQClWvVh5mlNaIj3+Pgro0Qi8Wo1dAd4SFv4Xf+JCpVrwM9QyO8ffkMuzcuh0uFKrBzVNzK6frF00hPT4db4xYqupLCgYmkMCpNJEuUKIGnT5/C2dkZAODn5wd7+y/b2gQFBcHGxkZV4eWLG9f8EBoSgnYdOim0SyVS3Ll9C7/9ugOxsbEwMzNDlWrVsXnHbzA1+/pWEJQzTx49xPDB/eTHK5cuBAC0atseU2fNz9EYM+f9jCU/z8NPQwdAJBajUZPmGD1+klLiVWeampq4f/sGju3/DclJiTCzsELN+k3QqccAeR8NTU2cOvw7dqxfCplMBmtbO/QeMhpNW3X8xshUykIPPu3KyI8H1cn8+Xs68D3WXHqF4sY6aOpuDkNtTcQmpeFpRDwmHH6isL5x8dkXGFrXAXPbuED2aUPyX658+SOtaWlzaGtpoEsVW3SpYitvvx8ci0l/BebDVRZeUZHhWL9wGuJiY2BgZIxS5Sth2tLNMDQyQWpKCh4F3MSpQ3uQnJQEMwtLVK/bGO269csyzqVTh1GtTiPocV9VUgKRTIX7Y6xfvx52dnZo3bp1tucnT56M8PBwbNq0KdvzX1PYpraLspQ0vhcFyZtP27aQ6k09/kTVIdAnU5pm3YydVMOtpLHKXtv3sfJ23GhetuiunVdpRXLo0KHfPD9/fs4qQ0RERESU/1S+RpKIiIhI1cRcIykIP9mGiIiIiARhRZKIiIjUnogbkgvCiiQRERERCcKKJBEREak97iMpDBNJIiIiUnuc2haGU9tEREREJAgrkkRERKT2uP2PMKxIEhEREZEgrEgSERGR2uMaSWFYkSQiIiIiQViRJCIiIrXH7X+EYUWSiIiIiARhRZKIiIjUHguSwjCRJCIiIrUn5ty2IJzaJiIiIiJBWJEkIiIitcd6pDCsSBIRERGRIKxIEhEREbEkKQgrkkREREQkCCuSREREpPb4EYnCsCJJRERERIKwIklERERqj9tICsNEkoiIiNQe80hhOLVNREREVEDMnDkTIpFI4VGmTBn5+aSkJHh5ecHMzAz6+vro3LkzwsLCFMYICgpC69atoaurC0tLS4wbNw5paWlKiZcVSSIiIqICVJIsX748Tp8+LT/W1PySro0ePRpHjx7Fvn37YGRkhOHDh6NTp064cuUKACA9PR2tW7eGtbU1rl69ipCQEPTp0wdaWlqYP39+nsfKRJKIiIioANHU1IS1tXWW9piYGGzevBm7d+9GkyZNAABbt25F2bJlce3aNdSuXRunTp3Co0ePcPr0aVhZWaFy5cqYM2cOJkyYgJkzZ0IikeRprJzaJiIiIrUnUuJ/ycnJiI2NVXgkJyd/NZanT5/C1tYWTk5O6NmzJ4KCggAA/v7+SE1NRbNmzeR9y5QpA3t7e/j5+QEA/Pz84OrqCisrK3kfDw8PxMbG4uHDh3n+dWMiSURERKREPj4+MDIyUnj4+Phk27dWrVrYtm0bTpw4gXXr1uHly5eoX78+Pn78iNDQUEgkEhgbGys8x8rKCqGhoQCA0NBQhSTy8/nP5/Iap7aJiIhI7Slz+59JkybB29tboU0qlWbbt2XLlvJ/V6xYEbVq1YKDgwN+//136OjoKC9IgViRJCIiIlIiqVQKQ0NDhcfXEsl/MzY2RunSpfHs2TNYW1sjJSUF0dHRCn3CwsLkayqtra2z3MX9+Ti7dZf/FRNJIiIiUnsiJT7+i7i4ODx//hw2NjaoVq0atLS0cObMGfn5wMBABAUFwc3NDQDg5uaG+/fvIzw8XN7H19cXhoaGKFeu3H+MJitObRMREREVkO1/xo4di7Zt28LBwQHBwcGYMWMGNDQ00L17dxgZGWHAgAHw9vaGqakpDA0NMWLECLi5uaF27doAAHd3d5QrVw69e/fGwoULERoaiqlTp8LLyyvHVdDcYCJJREREVEC8ffsW3bt3R2RkJCwsLFCvXj1cu3YNFhYWAIBly5ZBLBajc+fOSE5OhoeHB9auXSt/voaGBo4cOYJhw4bBzc0Nenp68PT0xOzZs5USr0gmk8mUMrIKfUzOUHUI9ElKGt+LguRNZKKqQ6BPph5/ouoQ6JMpTUupOgT6xK2kscpe+87rj0obu4qDgdLGVjWukSQiIiIiQTi1TURERGpPmdv/FGWsSBIRERGRIKxIEhERkdpjQVKYInmzTWKqqiOgzzhVULBkZBS5b/dCK+JjiqpDoE/KNBuj6hDok8Q7q1X22neDlHezTSX7onuzDSuSRERERCx8CMJEkoiIiNSeiJmkILzZhoiIiIgEYUWSiIiI1B7X9AvDiiQRERERCcKKJBEREak9FiSFYUWSiIiIiARhRZKIiIiIJUlBWJEkIiIiIkFYkSQiIiK1x30khWFFkoiIiIgEYUWSiIiI1B73kRSGiSQRERGpPeaRwnBqm4iIiIgEYUWSiIiIiCVJQViRJCIiIiJBWJEkIiIitcftf4RhRZKIiIiIBGFFkoiIiNQet/8RhhVJIiIiIhKEFUkiIiJSeyxICsNEkoiIiIiZpCCc2iYiIiIiQViRJCIiIrXH7X+EYUWSiIiIiARhRZKIiIjUHrf/EYYVSSIiIiIShBVJIiIiUnssSArDiiQRERERCcKKJBERERFLkoIwkSQiIiK1x+1/hOHUNhEREREJwookERERqT1u/yMMK5JEREREJAgrkkRERKT2WJAUhhVJIiIiIhKEFUkiIiIiliQFYUWSiIiIiARhIklERERqT6TE/3LDx8cHNWrUgIGBASwtLdGhQwcEBgYq9GnUqBFEIpHCY+jQoQp9goKC0Lp1a+jq6sLS0hLjxo1DWlraf/46/RuntomIiEjtFZTtfy5cuAAvLy/UqFEDaWlpmDx5Mtzd3fHo0SPo6enJ+w0aNAizZ8+WH+vq6sr/nZ6ejtatW8Pa2hpXr15FSEgI+vTpAy0tLcyfPz9P42UiqUKbN/6CM6dP4dXLF5Bqa6NS5SoYNXosSjg6yfu8CQrC0sU/I+COP1JSUlCnXn1MnDQNZubmKoy8aPK/dRPbtmzG40cPEBERgWUr16BJ02YKfV48f47lSxfB/9ZNpKWnw9nJGUuWr4KNra2Koi76tmzagFUrlqJHrz4YN2EyYmKisW7NKlzzu4LQkBCYmJiiUZOm+HH4SBgYGKg63ELttx2bcOX8GbwJegmJRIpyrpUx8MdRsHNwVOj36P5dbP1lJZ48ug8NsQacSrnAZ/l6SKXaAIDenVogLDRY4Tn9h45Etz4D8u1aCpux/d3RoUkllC5hhcTkVFy/+wJTVhzC09fh8j79O9VF15bVUblMcRjq68C6/jjExCXKz9evVgqnNo3Mdvx6PRfC/1EQpBJNrJrSDVXK2qOMoxWOX3qALt4blX59lHMnTpxQON62bRssLS3h7++PBg0ayNt1dXVhbW2d7RinTp3Co0ePcPr0aVhZWaFy5cqYM2cOJkyYgJkzZ0IikeRZvEwkVcj/1g107d4T5Su4Ij0tHatWLMWwwQOw/9BR6OjqIjEhAcMG90dplzLYsHk7AGDN6hX4afhQ7Nz9O8RirkzIS4mJCXBxcUGHTp3hPXJ4lvNvgoLQt3cPdOzUGcOG/wR9PX08f/YUEqlUBdGqh4cP7uPPP/aiVGkXeVtEeDgiIsIxesx4ODmXREhwMObNmYGIiHAsXrpShdEWfvfv3EK7zt1Qumx5pKenY+v6lZg0aig27j4AHZ3Masej+3cx2XsYuvUeAC/vSdDQ0MCLZ39DJFL8edRnkBdatessP9b5R7WEsqpftSTW770I/4evoampgVnD2+LIuuGo0mkuEpJSAAC62lrwvfoIvlcfYc5P7bOMce3uC5RoNkmhbfqPbdC4pgv8HwUBADTEYiQmp2Ltb+fRoWllpV9XYaLMgmRycjKSk5MV2qRSKaQ5+P0RExMDADA1NVVo37VrF3799VdYW1ujbdu2mDZtmrwq6efnB1dXV1hZWcn7e3h4YNiwYXj48CGqVKnyXy9JjomkCq39ZbPC8ex5C9CkgRsePXqIatVr4M6d2wgOfoc9fxyEvr4+AGDOvJ/RoE4N3Lh+DbXd6qgi7CKrXv2GqFe/4VfPr1q5DPUaNMDosePlbXb29vkRmlpKSIjH5IljMW3GHGzasE7eXrJUaSxZtkp+bGdnj+EjRmPKpMz1P5qa/LEm1Pxl6xWOx06dgy6tG+Hpk0eoWKU6AGD9yoXo8L8eCtXFf1csgcxqiakZZ05yqv3wtQrHg2f8ijdnF6BKOTtcuf0cALB693kAmZXH7KSmpSMs8qP8WFNTjDaNKmLdngvytoSkFIycvxcA4FbZCcYGOnl5GfQVPj4+mDVrlkLbjBkzMHPmzG8+LyMjA6NGjULdunVRoUIFeXuPHj3g4OAAW1tb3Lt3DxMmTEBgYCD2798PAAgNDVVIIgHIj0NDQ/Pgir4ocD9xZTIZRAVloUI+i4vL/AFgZGQEAEhNTYFIJFIoQUulUojFYty57c9EMh9lZGTg0oXz6Nt/IIYOGoAnTx6hWLHiGDBoSJbpb8obPvNmo379RqjtVkchkczOx7iP0NPXZxKZx+Lj4wAABoaZP5M+REXiycP7aOLeGqMG90bwuzewc3BEvyEjUKFSVYXn7t25Bbu2boCllQ0au7dE5669ocH3J8cM9TOXCXyISRA8RpuGFWFmpIedh67lVVhFmjJTj0mTJsHb21uhLSfVSC8vLzx48ACXL19WaB88eLD8366urrCxsUHTpk3x/PlzODs7503QOVTg5kalUikeP36s6jDyXUZGBhYtmI/KVaqiZKnSAADXipWho6OD5UsXITExEYkJCVi6+Gekp6fj/fsIFUesXqIiI5GQkIAtmzeibr36WL9hC5o0bQ7vkcNx6+YNVYdX5Jw4fhRPHj3CiFHe3+374cMHbPxlHTr/0CUfIlMfGRkZWL98IcpXrAJH58wKWGjwWwDAzs3r0LJdZ8xfug4lXcpiwk+D8O7Na/lz2/+vBybPXohFqzejdYcfsGfHJmxcs0wl11EYiUQiLBr7A67eeY5Hz0MEj+PZwQ2+fo/xLjw674IjQaRSKQwNDRUe30skhw8fjiNHjuDcuXMoXrz4N/vWqlULAPDs2TMAgLW1NcLCwhT6fD7+2rpKoVT25+G/M/PP0tPTsWDBApiZmQEAli5d+s1xslt3kCHO2bqDgsRn7iw8e/YU23bslreZmppi4ZIVmD9nJn7btRNisRgtWrZG2XLlIVbTqq2qZMgyAACNGzdFb8++AIAyZcvibsBt7Nu7B9Vr1FRhdEVLaGgIFi2Yj3Ubtnz3+zguLg4/eQ2Bk5MzhgzLuq6VhFu9ZB5evXiGpeu3ydsyZDIAQOsOP8CjTQcAQEmXsgi4dR0njhzEgGGZN3r80L2P/DlOJUtDU0sLK36eg/7DRubpIv+iavmkLihf0gZN+wlPvotZGqO5W1n0mrAlDyMr6grG71WZTIYRI0bgwIEDOH/+PBwdsy4d+beAgAAAgI2NDQDAzc0N8+bNQ3h4OCwtLQEAvr6+MDQ0RLly5fI0XpUlksuXL0elSpVgbGys0C6TyfD48WPo6enlaIo7u3UHk6fOwNTpM/MwWuXymTcbFy+cx5btv8LqX38p1KlbD0dOnMaHD1HQ0NCEoaEhmjasi2ItWqkoWvVkYmwCTU1NOP1rysDRyRkBt/1VFFXR9PjhQ0RFRaJH107ytvT0dNz2v4W9v+3Cdf970NDQQHx8HLyGDoSurh6WrlgNLS0tFUZdtKxeMh/XrlzEkrVbYWH55WfS5zWP9iUUvw/sSzghPOzrlbMy5VyRnp6GsJB32a6npC+WTfgfWtWvgGYDlv+nSmLv9rURGROPIxfu5V1wlC+8vLywe/duHDp0CAYGBvI1jUZGRtDR0cHz58+xe/dutGrVCmZmZrh37x5Gjx6NBg0aoGLFigAAd3d3lCtXDr1798bChQsRGhqKqVOnwsvLK88LbSpLJOfPn48NGzZgyZIlaNKkibxdS0sL27Zty3HGnN26gwxx4ahGymQyLJg/B2fP+GLT1p0oVtzuq31NTDLv1rpx3Q9RUZFo1LjJV/tS3tOSSFC+gitevXqp0P769SvY2BZTUVRFU83atbFv/2GFthnTJsPR0Ql9+w+EhoYG4uLi8OOQAZBIJFi+am2hm4EoqGQyGdYs9cGVC2exeM1m2NgqTqdZ2xSDmbkl3ga9Umh/G/QaNdzqfnXc508DIRaLYWxipoywi4xlE/6Hdk0qwX3QCrwOjvxPY/VpVxu7j9xAWlpGHkVX9BWUib516zLXhDdq1EihfevWrejbty8kEglOnz6N5cuXIz4+HnZ2dujcuTOmTp0q76uhoYEjR45g2LBhcHNzg56eHjw9PRX2ncwrKkskJ06ciKZNm6JXr15o27YtfHx8BFUUsrt9PjE1r6JUrvlzZ+H4sSNYvnIt9PT05Ose9fUNoK2dudD64IE/4eTkDBMTU9y7ewcLF8xHrz59FfaapLyREB+PoKAg+fG7t2/x5PFjGBkZwcbWFp79BmD8mNGoVq0GatSshSuXL+Hi+XPYtHWHCqMuevT09OXrhD/T0dGBkbExSpYqLU8ikxITMW/BIsTHx8lvCjExMYWGhoYqwi4SVi2eh3O+xzHr5xXQ0dVDVOR7AICevj6kUm2IRCL8r6cndmxaB6eSpeFcugx8jx3Gm9cvMW3eEgCZ2wM9eXQPlarWhK6uHh49uIv1KxaiiUdrGBgaqvLyCrTlk7qga8vq+N/oDYiLT4KVWeaeqDFxSUhKzvylZmVmACszQzjbZ1aGK5Syxcf4JLwJ/YAPsV9uymlUszQci5tj64Gr2b5WGSdrSDQ1YGKkBwNdKSqWzvxj+N7f75R5iQVeAckjIfu0hORr7OzscOHChW/2AQAHBwccO3Ysr8L6KpHsexErWVxcHLy8vBAQEIBdu3ahatWqCAgI+E9z+IUlkaxcwSXb9llzfdC+Q+a03opli3H44AHExMTAtlgx/K9LN/Tq07fQ3NleSMIEANy8cR0D+/XJ0t6ufUfMmb8AAHBg/x/YsnEDwsJCUaKEI4YNH4HGTQrPXdsZGSr9dhdsYL/ecClTFuMmTMatm9cxqL9ntv2OnjgN22LfXpReUER8TFF1CFm416mYbfvYKXPg3vrLvoV7dmzG4f178DE2Bs4lXTDQa7T8ru2ngY+wavE8vHn9CqkpKbC2LYamLdqgc7c+BXZ9ZJlmY1QdAhLvrM62fdD0nfj1r+sAgClDWmHq0KzLmv7ZBwC2ze8LexsTNPnKGssnR2fBwTZrdViniurXGX/t65AfgqOV9z1pa1ww/9/PCypPJD/bs2cPRo0ahYiICNy/f18tEkl1UJgSSXVQWBPJoqggJpLqqiAkkpRJlYlkSIzyvidtjIpuIllgNvXq1q0b6tWrB39/fzg4OKg6HCIiIiL6jgKTSAJA8eLFv7tXEhEREVFeExWYVZKFS4HbkJyIiIiICocCVZEkIiIiUgkWJAVhRZKIiIiIBGFFkoiIiNQeC5LCMJEkIiIitcft6oTh1DYRERERCcKKJBEREak9bv8jDCuSRERERCQIK5JERERELEgKwookEREREQnCiiQRERGpPRYkhWFFkoiIiIgEYUWSiIiI1B73kRSGiSQRERGpPW7/IwyntomIiIhIEFYkiYiISO1xalsYViSJiIiISBAmkkREREQkCBNJIiIiIhKEaySJiIhI7XGNpDCsSBIRERGRIKxIEhERkdrjPpLCMJEkIiIitcepbWE4tU1EREREgrAiSURERGqPBUlhWJEkIiIiIkFYkSQiIiJiSVIQViSJiIiISBBWJImIiEjtcfsfYViRJCIiIiJBWJEkIiIitcd9JIVhRZKIiIiIBGFFkoiIiNQeC5LCMJEkIiIiYiYpCKe2iYiIiEgQViSJiIhI7XH7H2FYkSQiIiIiQViRJCIiIrXH7X+EYUWSiIiIiAQRyWQymaqDoKySk5Ph4+ODSZMmQSqVqjoctcb3ouDge1Fw8L0oWPh+kKowkSygYmNjYWRkhJiYGBgaGqo6HLXG96Lg4HtRcPC9KFj4fpCqcGqbiIiIiARhIklEREREgjCRJCIiIiJBmEgWUFKpFDNmzOCi6QKA70XBwfei4OB7UbDw/SBV4c02RERERCQIK5JEREREJAgTSSIiIiIShIkkEREREQnCRJKIiIiIBGEiWQCtWbMGJUqUgLa2NmrVqoUbN26oOiS1dPHiRbRt2xa2trYQiUQ4ePCgqkNSWz4+PqhRowYMDAxgaWmJDh06IDAwUNVhqaV169ahYsWKMDQ0hKGhIdzc3HD8+HFVh0UAFixYAJFIhFGjRqk6FFIjTCQLmL1798Lb2xszZszA7du3UalSJXh4eCA8PFzVoamd+Ph4VKpUCWvWrFF1KGrvwoUL8PLywrVr1+Dr64vU1FS4u7sjPj5e1aGpneLFi2PBggXw9/fHrVu30KRJE7Rv3x4PHz5UdWhq7ebNm/jll19QsWJFVYdCaobb/xQwtWrVQo0aNbB69WoAQEZGBuzs7DBixAhMnDhRxdGpL5FIhAMHDqBDhw6qDoUAREREwNLSEhcuXECDBg1UHY7aMzU1xaJFizBgwABVh6KW4uLiULVqVaxduxZz585F5cqVsXz5clWHRWqCFckCJCUlBf7+/mjWrJm8TSwWo1mzZvDz81NhZEQFS0xMDIDMBIZUJz09HXv27EF8fDzc3NxUHY7a8vLyQuvWrRV+dxDlF01VB0BfvH//Hunp6bCyslJot7KywpMnT1QUFVHBkpGRgVGjRqFu3bqoUKGCqsNRS/fv34ebmxuSkpKgr6+PAwcOoFy5cqoOSy3t2bMHt2/fxs2bN1UdCqkpJpJEVKh4eXnhwYMHuHz5sqpDUVsuLi4ICAhATEwM/vjjD3h6euLChQtMJvPZmzdvMHLkSPj6+kJbW1vV4ZCaYiJZgJibm0NDQwNhYWEK7WFhYbC2tlZRVEQFx/Dhw3HkyBFcvHgRxYsXV3U4aksikaBkyZIAgGrVquHmzZtYsWIFfvnlFxVHpl78/f0RHh6OqlWrytvS09Nx8eJFrF69GsnJydDQ0FBhhKQOuEayAJFIJKhWrRrOnDkjb8vIyMCZM2e4/ojUmkwmw/Dhw3HgwAGcPXsWjo6Oqg6J/iEjIwPJycmqDkPtNG3aFPfv30dAQID8Ub16dfTs2RMBAQFMIilfsCJZwHh7e8PT0xPVq1dHzZo1sXz5csTHx6Nfv36qDk3txMXF4dmzZ/Ljly9fIiAgAKamprC3t1dhZOrHy8sLu3fvxqFDh2BgYIDQ0FAAgJGREXR0dFQcnXqZNGkSWrZsCXt7e3z8+BG7d+/G+fPncfLkSVWHpnYMDAyyrBPW09ODmZkZ1w9TvmEiWcB07doVERERmD59OkJDQ1G5cmWcOHEiyw04pHy3bt1C48aN5cfe3t4AAE9PT2zbtk1FUamndevWAQAaNWqk0L5161b07ds3/wNSY+Hh4ejTpw9CQkJgZGSEihUr4uTJk2jevLmqQyMiFeA+kkREREQkCNdIEhEREZEgTCSJiIiISBAmkkREREQkCBNJIiIiIhKEiSQRERERCcJEkoiIiIgEYSJJRERERIIwkSQiIiIiQZhIEpFgffv2RYcOHeTHjRo1wqhRo/I9jvPnz0MkEiE6Olppr/HvaxUiP+IkIspPTCSJipi+fftCJBJBJBJBIpGgZMmSmD17NtLS0pT+2vv378ecOXNy1De/k6oSJUpg+fLl+fJaRETqgp+1TVQEtWjRAlu3bkVycjKOHTsGLy8vaGlpYdKkSVn6pqSkQCKR5Mnrmpqa5sk4RERUOLAiSVQESaVSWFtbw8HBAcOGDUOzZs1w+PBhAF+maOfNmwdbW1u4uLgAAN68eYMuXbrA2NgYpqamaN++PV69eiUfMz09Hd7e3jA2NoaZmRnGjx8PmUym8Lr/ntpOTk7GhAkTYGdnB6lUipIlS2Lz5s149eoVGjduDAAwMTGBSCRC3759AQAZGRnw8fGBo6MjdHR0UKlSJfzxxx8Kr3Ps2DGULl0aOjo6aNy4sUKcQqSnp2PAgAHy13RxccGKFSuy7Ttr1ixYWFjA0NAQQ4cORUpKivxcTmL/p9evX6Nt27YwMTGBnp4eypcvj2PHjv2nayEiyk+sSBKpAR0dHURGRsqPz5w5A0NDQ/j6+gIAUlNT4eHhATc3N1y6dAmampqYO3cuWrRogXv37kEikWDJkiXYtm0btmzZgrJly2LJkiU4cOAAmjRp8tXX7dOnD/z8/LBy5UpUqlQJL1++xPv372FnZ4c///wTnTt3RmBgIAwNDaGjowMA8PHxwa+//or169ejVKlSuHjxInr16gULCws0bNgQb968QadOneDl5YXBgwfj1q1bGDNmzH/6+mRkZKB48eLYt28fzMzMcPXqVQwePBg2Njbo0qWLwtdNW1sb58+fx6tXr9CvXz+YmZlh3rx5OYr937y8vJCSkoKLFy9CT08Pjx49gr6+/n+6FiKifCUjoiLF09NT1r59e5lMJpNlZGTIfH19ZVKpVDZ27Fj5eSsrK1lycrL8OTt37pS5uLjIMjIy5G3JyckyHR0d2cmTJ2UymUxmY2MjW7hwofx8amqqrHjx4vLXkslksoYNG8pGjhwpk8lkssDAQBkAma+vb7Zxnjt3TgZA9uHDB3lbUlKSTFdXV3b16lWFvgMGDJB1795dJpPJZJMmTZKVK1dO4fyECROyjPVvDg4OsmXLln31/L95eXnJOnfuLD/29PSUmZqayuLj4+Vt69atk+nr68vS09NzFPu/r9nV1VU2c+bMHMdERFTQsCJJVAQdOXIE+vr6SE1NRUZGBnr06IGZM2fKz7u6uiqsi7x79y6ePXsGAwMDhXGSkpLw/PlzxMTEICQkBLVq1ZKf09TURPXq1bNMb38WEBAADQ2NbCtxX/Ps2TMkJCSgefPmCu0pKSmoUqUKAODx48cKcQCAm5tbjl/ja9asWYMtW7YgKCgIiYmJSElJQeXKlRX6VKpUCbq6ugqvGxcXhzdv3iAuLu67sf/bTz/9hGHDhuHUqVNo1qwZOnfujIoVK/7nayEiyi9MJImKoMaNG2PdunWQSCSwtbWFpqbit7qenp7CcVxcHKpVq4Zdu3ZlGcvCwkJQDJ+nqnMjLi4OAHD06FEUK1ZM4ZxUKhUUR07s2bMHY8eOxZIlS+Dm5gYDAwMsWrQI169fz/EYQmIfOHAgPDw8cPToUZw6dQo+Pj5YsmQJRowYIfxiiIjyERNJoiJIT08PJUuWzHH/qlWrYu/evbC0tIShoWG2fWxsbHD9+nU0aNAAAJCWlgZ/f39UrVo12/6urq7IyMjAhQsX0KxZsyznP1dE09PT5W3lypWDVCpFUFDQVyuZZcuWld849Nm1a9e+f5HfcOXKFdSpUwc//vijvO358+dZ+t29exeJiYnyJPnatWvQ19eHnZ0dTE1Nvxt7duzs7DB06FAMHToUkyZNwsaNG5lIElGhwbu2iQg9e/aEubk52rdvj0uXLuHly5c4f/48fvrpJ7x9+xYAMHLkSCxYsAAHDx7EkydP8OOPP35zD8gSJUrA09MT/fv3x8GDB+Vj/v777wAABwcHiEQiHDlyBBEREYiLi4OBgQHGjh2L0aNHY/v27Xj+/Dlu376NVatWYfv27QCAoUOH4unTpxg3bhwCAwOxe/dubNu2LUfX+e7dOwQEBCg8Pnz4gFKlSuHWrVs4efIk/v77b0ybNg03b97M8vyUlBQMGDAAjx49wrFjxzBjxgwMHz4cYrE4R7H/26hRo3Dy5Em8fPkSt2/fxrlz51C2bNkcXQsRUYGg6kWaRJS3/nmzTW7Oh4SEyPr06SMzNzeXSaVSmZOTk2zQoEGymJgYmUyWeXPNyJEjZYaGhjJjY2OZt7e3rE+fPl+92UYmk8kSExNlo0ePltnY2MgkEomsZMmSsi1btsjPz549W2ZtbS0TiUQyT09PmUyWeYPQ8uXLZS4uLjItLS2ZhYWFzMPDQ3bhwgX58/766y9ZyZIlZVKpVFa/fn3Zli1bcnSzDYAsj507d8qSkpJkffv2lRkZGcmMjY1lw4YNk02cOFFWqVKlLF+36dOny8zMzGT6+vqyQYMGyZKSkuR9vhf7v2+2GT58uMzZ2VkmlUplFhYWst69e8vev3//1WsgIipoRDLZV1bKExERERF9A6e2iYiIiEgQJpJEREREJAgTSSIiIiIShIkkEREREQnCRJKIiIiIBGEiSURERESCMJEkIiIiIkGYSBIRERGRIEwkiYiIiEgQJpJEREREJAgTSSIiIiIS5P+mec3ajCcFsQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Misclassified Text Examples:\n",
            "True Label: 1, Predicted Label: 2\n",
            "Text: it is good at first until there is an issue and they do not care . they just want to keep getting that fee whether you are happy or not .\n",
            "\n",
            "True Label: 1, Predicted Label: 2\n",
            "Text: ordered cards . . . . price was a key factor . . . . did all was advised used large file . . . the side of the card was washed out and very with visible . . . . . the client had to order else where . . .\n",
            "\n",
            "True Label: 0, Predicted Label: 4\n",
            "Text: i sent in boxes of test strips . the paper got with the box to send in and what was paid was way different . this is a good place to stay away from . know that they will never rip me off again .\n",
            "\n",
            "True Label: 4, Predicted Label: 3\n",
            "Text: My TikTok videos used to have limitations but since connected to the protection system everything works smoothly .\n",
            "\n",
            "True Label: 0, Predicted Label: 2\n",
            "Text: I wasn't sure or ready to make a . she told me would receive a packet in the mail so could see and compare . have since found out that what am being sent is my policy .\n",
            "\n",
            "       rating                                               text\n",
            "0           1  it is extremely pricey so specifically asked i...\n",
            "1           1  Wrong part ordered at first by the salesman . ...\n",
            "2           1  My order was canceled without explanation . Re...\n",
            "3           1  The review . com is connected with the review ...\n",
            "4           1  Put a away into a bank account do not touch it...\n",
            "...       ...                                                ...\n",
            "60870       5  our driver was great . He even participated in...\n",
            "60871       5  The Notary was very patient and . There were s...\n",
            "60872       5  traffic initial service but J directed me and ...\n",
            "60873       5  Green City Pros delivered exceptional AC repla...\n",
            "60874       5  The understanding of what was looking for and ...\n",
            "\n",
            "[60875 rows x 2 columns]\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAHqCAYAAADVi/1VAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAdfVJREFUeJzt3XlcVdX+//H3AeEAKjghQyLOs6I5EFYOVwrRzKlSs0RzuJZDhk2UOdXNcijNTK1UMnNIU6trOWFmKWlaqGl603AGnAKEFAz27w9/nm8nQBFhH5HX8/HYj9xrr733Zy0wP4/P2Wdti2EYhgAAAAAAAAATOTk6AAAAAAAAAJQ8FKUAAAAAAABgOopSAAAAAAAAMB1FKQAAAAAAAJiOohQAAAAAAABMR1EKAAAAAAAApqMoBQAAAAAAANNRlAIAAAAAAIDpKEoBAAAAAADAdBSlgNtQ//79Va1atQKdO378eFkslsIN6BZz5MgRWSwWRUdHm35vi8Wi8ePH2/ajo6NlsVh05MiR655brVo19e/fv1DjuZnfFQAAzER+c23kN/+H/AYoPihKASayWCz52jZv3uzoUEu8kSNHymKx6NChQ3n2efnll2WxWLRnzx4TI7txp06d0vjx4xUXF+foUGyuJs5Tp051dCgAgJtEflN8kN+Y59dff5XFYpGbm5uSk5MdHQ5wyyrl6ACAkuTjjz+221+4cKE2bNiQo71+/fo3dZ8PPvhA2dnZBTp3zJgxevHFF2/q/reDvn37aubMmVq8eLHGjh2ba58lS5aocePGatKkSYHv8/jjj6t3796yWq0Fvsb1nDp1ShMmTFC1atXUtGlTu2M387sCAIBEflOckN+YZ9GiRfL19dUff/yhFStWaNCgQQ6NB7hVUZQCTPTYY4/Z7f/www/asGFDjvZ/+vPPP+Xh4ZHv+7i4uBQoPkkqVaqUSpXifw3BwcGqVauWlixZkmvSFhsbq/j4eL3xxhs3dR9nZ2c5Ozvf1DVuxs38rgAAIJHfFCfkN+YwDEOLFy/Wo48+qvj4eH3yySe3bFEqPT1dpUuXdnQYKMH4+h5wi2nXrp0aNWqkXbt2qU2bNvLw8NBLL70kSfr888/VuXNn+fv7y2q1qmbNmnr11VeVlZVld41/fo/+71+Vev/991WzZk1ZrVa1bNlSP/74o925ua25YLFYNHz4cK1evVqNGjWS1WpVw4YNtXbt2hzxb968WS1atJCbm5tq1qypuXPn5nsdh++++04PP/ywqlatKqvVqoCAAD3zzDO6ePFijvGVKVNGJ0+eVLdu3VSmTBl5e3vr2WefzTEXycnJ6t+/v7y8vFSuXDlFRETk+xHqvn376sCBA/rpp59yHFu8eLEsFov69OmjzMxMjR07Vs2bN5eXl5dKly6te++9V998881175HbmguGYei1115TlSpV5OHhofbt22vfvn05zj1//ryeffZZNW7cWGXKlJGnp6fCw8O1e/duW5/NmzerZcuWkqQBAwbYvkJxdb2J3NZcSE9P1+jRoxUQECCr1aq6detq6tSpMgzDrt+N/F4U1OnTpzVw4ED5+PjIzc1NQUFB+uijj3L0W7p0qZo3b66yZcvK09NTjRs31owZM2zHL1++rAkTJqh27dpyc3NTxYoVdc8992jDhg2FFisAIG/kN+Q3JSm/2bp1q44cOaLevXurd+/e2rJli06cOJGjX3Z2tmbMmKHGjRvLzc1N3t7e6tixo3bu3GnXb9GiRWrVqpU8PDxUvnx5tWnTRuvXr7eL+e9rel31z/W6rv5cvv32Wz311FOqXLmyqlSpIkk6evSonnrqKdWtW1fu7u6qWLGiHn744VzXBUtOTtYzzzyjatWqyWq1qkqVKurXr5/Onj2rtLQ0lS5dWk8//XSO806cOCFnZ2dNmjQpnzOJkoCPC4Bb0Llz5xQeHq7evXvrsccek4+Pj6Qr/5CUKVNGkZGRKlOmjDZt2qSxY8cqNTVVU6ZMue51Fy9erAsXLujf//63LBaLJk+erB49euj333+/7idK33//vVauXKmnnnpKZcuW1TvvvKOePXvq2LFjqlixoiTp559/VseOHeXn56cJEyYoKytLEydOlLe3d77GvXz5cv3555968sknVbFiRe3YsUMzZ87UiRMntHz5cru+WVlZCgsLU3BwsKZOnaqNGzdq2rRpqlmzpp588klJV5Kfrl276vvvv9fQoUNVv359rVq1ShEREfmKp2/fvpowYYIWL16sO++80+7en376qe69915VrVpVZ8+e1Ycffqg+ffpo8ODBunDhgubNm6ewsDDt2LEjxyPl1zN27Fi99tpr6tSpkzp16qSffvpJ999/vzIzM+36/f7771q9erUefvhhVa9eXUlJSZo7d67atm2r/fv3y9/fX/Xr19fEiRM1duxYDRkyRPfee68kqXXr1rne2zAMPfjgg/rmm280cOBANW3aVOvWrdNzzz2nkydP6u2337brn5/fi4K6ePGi2rVrp0OHDmn48OGqXr26li9frv79+ys5OdmW7GzYsEF9+vRRhw4d9Oabb0q6so7D1q1bbX3Gjx+vSZMmadCgQWrVqpVSU1O1c+dO/fTTT7rvvvtuKk4AQP6Q35DflJT85pNPPlHNmjXVsmVLNWrUSB4eHlqyZImee+45u34DBw5UdHS0wsPDNWjQIP3111/67rvv9MMPP6hFixaSpAkTJmj8+PFq3bq1Jk6cKFdXV23fvl2bNm3S/fffn+/5/7unnnpK3t7eGjt2rNLT0yVJP/74o7Zt26bevXurSpUqOnLkiGbPnq127dpp//79tqca09LSdO+99+rXX3/VE088oTvvvFNnz57VF198oRMnTqhp06bq3r27li1bprfeesvuibklS5bIMAz17du3QHHjNmUAcJhhw4YZ//xr2LZtW0OSMWfOnBz9//zzzxxt//73vw0PDw/j0qVLtraIiAgjMDDQth8fH29IMipWrGicP3/e1v75558bkowvv/zS1jZu3LgcMUkyXF1djUOHDtnadu/ebUgyZs6caWvr0qWL4eHhYZw8edLW9ttvvxmlSpXKcc3c5Da+SZMmGRaLxTh69Kjd+CQZEydOtOvbrFkzo3nz5rb91atXG5KMyZMn29r++usv49577zUkGQsWLLhuTC1btjSqVKliZGVl2drWrl1rSDLmzp1ru2ZGRobdeX/88Yfh4+NjPPHEE3btkoxx48bZ9hcsWGBIMuLj4w3DMIzTp08brq6uRufOnY3s7Gxbv5deesmQZERERNjaLl26ZBeXYVz5WVutVru5+fHHH/Mc7z9/V67O2WuvvWbX76GHHjIsFovd70B+fy9yc/V3csqUKXn2mT59uiHJWLRoka0tMzPTCAkJMcqUKWOkpqYahmEYTz/9tOHp6Wn89ddfeV4rKCjI6Ny58zVjAgAUDvKb64+P/OaK2y2/MYwruUrFihWNl19+2db26KOPGkFBQXb9Nm3aZEgyRo4cmeMaV+fot99+M5ycnIzu3bvnmJO/z+M/5/+qwMBAu7m9+nO55557cuRNuf2exsbGGpKMhQsX2trGjh1rSDJWrlyZZ9zr1q0zJBlff/213fEmTZoYbdu2zXEeSja+vgfcgqxWqwYMGJCj3d3d3fbnCxcu6OzZs7r33nv1559/6sCBA9e9bq9evVS+fHnb/tVPlX7//ffrnhsaGqqaNWva9ps0aSJPT0/buVlZWdq4caO6desmf39/W79atWopPDz8uteX7MeXnp6us2fPqnXr1jIMQz///HOO/kOHDrXbv/fee+3G8tVXX6lUqVK2TxalK2scjBgxIl/xSFfWyThx4oS2bNlia1u8eLFcXV318MMP267p6uoq6cpj2OfPn9dff/2lFi1a5Ppo/LVs3LhRmZmZGjFihN1XAkaNGpWjr9VqlZPTlf+NZ2Vl6dy5cypTpozq1q17w/e96quvvpKzs7NGjhxp1z569GgZhqGvv/7arv16vxc346uvvpKvr6/69Olja3NxcdHIkSOVlpamb7/9VpJUrlw5paenX/OreOXKldO+ffv022+/3XRcAICCIb8hvykJ+c3XX3+tc+fO2eUvffr00e7du+2+rvjZZ5/JYrFo3LhxOa5xdY5Wr16t7OxsjR071jYn/+xTEIMHD86x5tfff08vX76sc+fOqVatWipXrpzdvH/22WcKCgpS9+7d84w7NDRU/v7++uSTT2zHfvnlF+3Zs+e6a82h5KEoBdyC7rjjDlsS8Hf79u1T9+7d5eXlJU9PT3l7e9v+x56SknLd61atWtVu/2oC98cff9zwuVfPv3ru6dOndfHiRdWqVStHv9zacnPs2DH1799fFSpUsK2j0LZtW0k5x3f1e/d5xSNd+W68n5+fypQpY9evbt26+YpHknr37i1nZ2ctXrxYknTp0iWtWrVK4eHhdgnwRx99pCZNmtjWK/L29taaNWvy9XP5u6NHj0qSateubdfu7e1tdz/pSoL49ttvq3bt2rJarapUqZK8vb21Z8+eG77v3+/v7++vsmXL2rVffWPS1fiuut7vxc04evSoateunSMJ+2csTz31lOrUqaPw8HBVqVJFTzzxRI51HyZOnKjk5GTVqVNHjRs31nPPPXfLv+oaAG435DfkNyUhv1m0aJGqV68uq9WqQ4cO6dChQ6pZs6Y8PDzsijSHDx+Wv7+/KlSokOe1Dh8+LCcnJzVo0OC6970R1atXz9F28eJFjR071rbm1tV5T05Otpv3w4cPq1GjRte8vpOTk/r27avVq1frzz//lHTlK41ubm62oidwFUUp4Bb0908qrkpOTlbbtm21e/duTZw4UV9++aU2bNhgW0MnP6+9zestKMY/Fngs7HPzIysrS/fdd5/WrFmjF154QatXr9aGDRtsC1b+c3xmvdGlcuXKuu+++/TZZ5/p8uXL+vLLL3XhwgW778IvWrRI/fv3V82aNTVv3jytXbtWGzZs0L/+9a8ifR3x66+/rsjISLVp00aLFi3SunXrtGHDBjVs2NC01yAX9e9FflSuXFlxcXH64osvbOtFhIeH262t0aZNGx0+fFjz589Xo0aN9OGHH+rOO+/Uhx9+aFqcAFDSkd+Q3+RHcc5vUlNT9eWXXyo+Pl61a9e2bQ0aNNCff/6pxYsXm5oj/XOB/Kty+7s4YsQI/ec//9EjjzyiTz/9VOvXr9eGDRtUsWLFAs17v379lJaWptWrV9veRvjAAw/Iy8vrhq+F2xsLnQPFxObNm3Xu3DmtXLlSbdq0sbXHx8c7MKr/U7lyZbm5uenQoUM5juXW9k979+7V//73P3300Ufq16+frf1m3o4WGBiomJgYpaWl2X2aePDgwRu6Tt++fbV27Vp9/fXXWrx4sTw9PdWlSxfb8RUrVqhGjRpauXKl3aPUuT2OnZ+YJem3335TjRo1bO1nzpzJ8encihUr1L59e82bN8+uPTk5WZUqVbLt38jj3YGBgdq4caMuXLhg92ni1a9PXI3PDIGBgdqzZ4+ys7PtnpbKLRZXV1d16dJFXbp0UXZ2tp566inNnTtXr7zyiu2T7AoVKmjAgAEaMGCA0tLS1KZNG40fP/6WfUUzAJQE5Dc3jvzmilsxv1m5cqUuXbqk2bNn28UqXfn5jBkzRlu3btU999yjmjVrat26dTp//nyeT0vVrFlT2dnZ2r9//zUXli9fvnyOty9mZmYqISEh37GvWLFCERERmjZtmq3t0qVLOa5bs2ZN/fLLL9e9XqNGjdSsWTN98sknqlKlio4dO6aZM2fmOx6UHDwpBRQTVz+x+funK5mZmXrvvfccFZIdZ2dnhYaGavXq1Tp16pSt/dChQzm+p5/X+ZL9+AzD0IwZMwocU6dOnfTXX39p9uzZtrasrKwb/gexW7du8vDw0Hvvvaevv/5aPXr0kJub2zVj3759u2JjY2845tDQULm4uGjmzJl215s+fXqOvs7Ozjk+bVu+fLlOnjxp11a6dGlJyterojt16qSsrCy9++67du1vv/22LBZLvtfPKAydOnVSYmKili1bZmv766+/NHPmTJUpU8b21Ydz587Znefk5KQmTZpIkjIyMnLtU6ZMGdWqVct2HADgGOQ3N4785opbMb9ZtGiRatSooaFDh+qhhx6y25599lmVKVPG9hW+nj17yjAMTZgwIcd1ro6/W7ducnJy0sSJE3M8rfT3OapZs6bd+mCS9P777+f5pFRucpv3mTNn5rhGz549tXv3bq1atSrPuK96/PHHtX79ek2fPl0VK1Y0NY9E8cGTUkAx0bp1a5UvX14REREaOXKkLBaLPv74Y1MfAb6e8ePHa/369br77rv15JNP2v7xb9SokeLi4q55br169VSzZk09++yzOnnypDw9PfXZZ5/d1NpEXbp00d13360XX3xRR44cUYMGDbRy5cobXo+gTJky6tatm23dhX++xvaBBx7QypUr1b17d3Xu3Fnx8fGaM2eOGjRooLS0tBu6l7e3t5599llNmjRJDzzwgDp16qSff/5ZX3/9dY5P3B544AFNnDhRAwYMUOvWrbV371598skndp9ASlcSlXLlymnOnDkqW7asSpcureDg4FzXE+jSpYvat2+vl19+WUeOHFFQUJDWr1+vzz//XKNGjbJb9LMwxMTE6NKlSznau3XrpiFDhmju3Lnq37+/du3apWrVqmnFihXaunWrpk+fbvukc9CgQTp//rz+9a9/qUqVKjp69Khmzpyppk2b2taKaNCggdq1a6fmzZurQoUK2rlzp1asWKHhw4cX6ngAADeG/ObGkd9ccavlN6dOndI333yTYzH1q6xWq8LCwrR8+XK98847at++vR5//HG98847+u2339SxY0dlZ2fru+++U/v27TV8+HDVqlVLL7/8sl599VXde++96tGjh6xWq3788Uf5+/tr0qRJkq7kQkOHDlXPnj113333affu3Vq3bl2Oub2WBx54QB9//LG8vLzUoEEDxcbGauPGjapYsaJdv+eee04rVqzQww8/rCeeeELNmzfX+fPn9cUXX2jOnDkKCgqy9X300Uf1/PPPa9WqVXryySfl4uJSgJnFbc+EN/wByENer0xu2LBhrv23bt1q3HXXXYa7u7vh7+9vPP/887ZXrn7zzTe2fnm9MnnKlCk5rql/vEI2r1cmDxs2LMe5/3zNrGEYRkxMjNGsWTPD1dXVqFmzpvHhhx8ao0ePNtzc3PKYhf+zf/9+IzQ01ChTpoxRqVIlY/DgwbZX8P79db8RERFG6dKlc5yfW+znzp0zHn/8ccPT09Pw8vIyHn/8cePnn3/O9yuTr1qzZo0hyfDz88v1lbyvv/66ERgYaFitVqNZs2bGf//73xw/B8O4/iuTDcMwsrKyjAkTJhh+fn6Gu7u70a5dO+OXX37JMd+XLl0yRo8ebet39913G7GxsUbbtm1zvG73888/Nxo0aGB7ffXVsecW44ULF4xnnnnG8Pf3N1xcXIzatWsbU6ZMsXv18NWx5Pf34p+u/k7mtX388ceGYRhGUlKSMWDAAKNSpUqGq6ur0bhx4xw/txUrVhj333+/UblyZcPV1dWoWrWq8e9//9tISEiw9XnttdeMVq1aGeXKlTPc3d2NevXqGf/5z3+MzMzMa8YJALhx5Df2yG+uuN3zm2nTphmSjJiYmDz7REdHG5KMzz//3DAMw/jrr7+MKVOmGPXq1TNcXV0Nb29vIzw83Ni1a5fdefPnzzeaNWtmWK1Wo3z58kbbtm2NDRs22I5nZWUZL7zwglGpUiXDw8PDCAsLMw4dOpQj5qs/lx9//DFHbH/88Yct5ypTpowRFhZmHDhwINdxnzt3zhg+fLhxxx13GK6urkaVKlWMiIgI4+zZszmu26lTJ0OSsW3btjznBSWbxTBuoY8hANyWunXrpn379um3335zdCgAAACFgvwGuL7u3btr7969+VqDDSUTa0oBKFQXL1602//tt9/01VdfqV27do4JCAAA4CaR3wA3LiEhQWvWrNHjjz/u6FBwC+NJKQCFys/PT/3791eNGjV09OhRzZ49WxkZGfr5559Vu3ZtR4cHAABww8hvgPyLj4/X1q1b9eGHH+rHH3/U4cOH5evr6+iwcItioXMAhapjx45asmSJEhMTZbVaFRISotdff52EDQAAFFvkN0D+ffvttxowYICqVq2qjz76iIIUroknpQAAAAAAAGA61pQCAAAAAACA6ShKAQAAAAAAwHSsKVVA2dnZOnXqlMqWLSuLxeLocAAAgEkMw9CFCxfk7+8vJyc+37sW8iUAAEqm/OZLFKUK6NSpUwoICHB0GAAAwEGOHz+uKlWqODqMWxr5EgAAJdv18iWKUgVUtmxZSVcm2NPT08HRAAAAs6SmpiogIMCWCyBv5EsAAJRM+c2XKEoV0NVH0D09PUmyAAAogfg62vWRLwEAULJdL19iIQQAAAAAAACYjqIUAAAAAAAATEdRCgAAAAAAAKZjTSkAAApJVlaWLl++7OgwcJNcXFzk7Ozs6DAAACgxsrOzlZmZ6egwcAMKK19yaFFqy5YtmjJlinbt2qWEhAStWrVK3bp1y7P/ypUrNXv2bMXFxSkjI0MNGzbU+PHjFRYWZtdv1qxZmjJlihITExUUFKSZM2eqVatWtuOXLl3S6NGjtXTpUmVkZCgsLEzvvfeefHx8imqoAIDbmGEYSkxMVHJysqNDQSEpV66cfH19WcwcAIAilpmZqfj4eGVnZzs6FNygwsiXHFqUSk9PV1BQkJ544gn16NHjuv23bNmi++67T6+//rrKlSunBQsWqEuXLtq+fbuaNWsmSVq2bJkiIyM1Z84cBQcHa/r06QoLC9PBgwdVuXJlSdIzzzyjNWvWaPny5fLy8tLw4cPVo0cPbd26tUjHCwC4PV0tSFWuXFkeHh4UMooxwzD0559/6vTp05IkPz8/B0cEAMDtyzAMJSQkyNnZWQEBAXJyYoWh4qAw8yWLYRhGYQV2MywWy3WflMpNw4YN1atXL40dO1aSFBwcrJYtW+rdd9+VdOUxwICAAI0YMUIvvviiUlJS5O3trcWLF+uhhx6SJB04cED169dXbGys7rrrrnzdNzU1VV5eXkpJSeEVxwBQgmVlZel///ufKleurIoVKzo6HBSSc+fO6fTp06pTp06OR9PJAfKPuQIAXMvly5d16NAh+fv7y8vLy9Hh4AYVRr5UrMuQ2dnZunDhgipUqCDpymN/u3btUmhoqK2Pk5OTQkNDFRsbK0natWuXLl++bNenXr16qlq1qq0PAAD5dXUNKQ8PDwdHgsJ09efJGmEAABSdrKwsSZKrq6uDI0FBFEa+VKwXOp86darS0tL0yCOPSJLOnj2rrKysHGtD+fj46MCBA5KufMXC1dVV5cqVy9EnMTExz3tlZGQoIyPDtp+amlpIowAA3A74yt7thZ8nAADm4d/d4qkwfm7F9kmpxYsXa8KECfr0009ta0UVpUmTJsnLy8u2BQQEFPk9AQAAAAAAblfFsii1dOlSDRo0SJ9++qnd1/AqVaokZ2dnJSUl2fVPSkqSr6+vJMnX11eZmZk53pD09z65iYqKUkpKim07fvx44Q0IAIDbQLVq1TR9+nRHhwEAAFDslNQ8qtgVpZYsWaIBAwZoyZIl6ty5s90xV1dXNW/eXDExMba27OxsxcTEKCQkRJLUvHlzubi42PU5ePCgjh07ZuuTG6vVKk9PT7sNAIDiyGKxXHMbP358ga77448/asiQITcVW7t27TRq1KibugYAAEBRuZXzqKuWLFkiZ2dnDRs2rFCuV5QcuqZUWlqaDh06ZNuPj49XXFycKlSooKpVqyoqKkonT57UwoULJV35yl5ERIRmzJih4OBg2xpQ7u7utpX6IyMjFRERoRYtWqhVq1aaPn260tPTNWDAAEmSl5eXBg4cqMjISFWoUEGenp4aMWKEQkJC8v3mPQAAirOEhATbn5ctW6axY8fq4MGDtrYyZcrY/mwYhrKyslSq1PVTBm9v78INFAAA4BZTHPKoefPm6fnnn9fcuXM1bdo0ubm5Fdq1C5tDn5TauXOnmjVrpmbNmkm6UlBq1qyZxo4dK+nKD/vYsWO2/u+//77++usvDRs2TH5+frbt6aeftvXp1auXpk6dqrFjx6pp06aKi4vT2rVr7RY/f/vtt/XAAw+oZ8+eatOmjXx9fbVy5UqTRg0AgGP5+vraNi8vL1ksFtv+gQMHVLZsWX399ddq3ry5rFarvv/+ex0+fFhdu3aVj4+PypQpo5YtW2rjxo121/3nY+cWi0UffvihunfvLg8PD9WuXVtffPHFTcX+2WefqWHDhrJarapWrZqmTZtmd/y9995T7dq15ebmJh8fHz300EO2YytWrFDjxo3l7u6uihUrKjQ0VOnp6TcVDwAAKFlu9TwqPj5e27Zt04svvqg6derkWuuYP3++LZ/y8/PT8OHDbceSk5P173//Wz4+PnJzc1OjRo303//+t+ATdh0OfVKqXbt2Mgwjz+PR0dF2+5s3b87XdYcPH243qf/k5uamWbNmadasWfm6HgAA+WUYhi5eznLIvd1dnAvt7TUvvviipk6dqho1aqh8+fI6fvy4OnXqpP/85z+yWq1auHChunTpooMHD6pq1ap5XmfChAmaPHmypkyZopkzZ6pv3746evSoKlSocMMx7dq1S4888ojGjx+vXr16adu2bXrqqadUsWJF9e/fXzt37tTIkSP18ccfq3Xr1jp//ry+++47SVc+6OrTp48mT56s7t2768KFC/ruu++umYcAAABzkUfZK0getWDBAnXu3FleXl567LHHNG/ePD366KO247Nnz1ZkZKTeeOMNhYeHKyUlRVu3bpV0Zfmj8PBwXbhwQYsWLVLNmjW1f/9+OTs7F8q85MahRSkAAG43Fy9nqcHYdQ659/6JYfJwLZx/2idOnKj77rvPtl+hQgUFBQXZ9l999VWtWrVKX3zxxTU/COrfv7/69OkjSXr99df1zjvvaMeOHerYseMNx/TWW2+pQ4cOeuWVVyRJderU0f79+zVlyhT1799fx44dU+nSpfXAAw+obNmyCgwMtD2NnZCQoL/++ks9evRQYGCgJKlx48Y3HAMAACg65FH2bjSPys7OVnR0tGbOnClJ6t27t0aPHq34+HhVr15dkvTaa69p9OjRdt84a9mypSRp48aN2rFjh3799VfVqVNHklSjRo2CTEG+FbuFzgEAQNFr0aKF3X5aWpqeffZZ1a9fX+XKlVOZMmX066+/2n3NPjdNmjSx/bl06dLy9PTU6dOnCxTTr7/+qrvvvtuu7e6779Zvv/2mrKws3XfffQoMDFSNGjX0+OOP65NPPtGff/4pSQoKClKHDh3UuHFjPfzww/rggw/0xx9/FCgOAACAa3FUHrVhwwalp6erU6dOkqRKlSrpvvvu0/z58yVJp0+f1qlTp9ShQ4dcz4+Li1OVKlVsBSkz8KQUAACFyN3FWfsnhjns3oWldOnSdvvPPvusNmzYoKlTp6pWrVpyd3fXQw89pMzMzGtex8XFxW7fYrEoOzu70OL8u7Jly+qnn37S5s2btX79eo0dO1bjx4/Xjz/+qHLlymnDhg3atm2b1q9fr5kzZ+rll1/W9u3bbZ8cAgAAxyKPsnejedS8efN0/vx5ubu729qys7O1Z88eTZgwwa49N9c7XhQoSgEAUIgsFkuhPfp9K9m6dav69++v7t27S7ryid+RI0dMjaF+/fq2NQ/+HledOnVsax2UKlVKoaGhCg0N1bhx41SuXDlt2rRJPXr0kMVi0d133627775bY8eOVWBgoFatWqXIyEhTxwEAAHJHHlVw586d0+eff66lS5eqYcOGtvasrCzdc889Wr9+vTp27Khq1aopJiZG7du3z3GNJk2a6MSJE/rf//5n2tNSt99PGwAAFLratWtr5cqV6tKliywWi1555ZUie+LpzJkziouLs2vz8/PT6NGj1bJlS7366qvq1auXYmNj9e677+q9996TJP33v//V77//rjZt2qh8+fL66quvlJ2drbp162r79u2KiYnR/fffr8qVK2v79u06c+aM6tevXyRjAAAAuMqMPOrjjz9WxYoV9cgjj+RYsL1Tp06aN2+eOnbsqPHjx2vo0KGqXLmybVHzrVu3asSIEWrbtq3atGmjnj176q233lKtWrV04MABWSyWAq0Hmh+sKQUAAK7rrbfeUvny5dW6dWt16dJFYWFhuvPOO4vkXosXL1azZs3stg8++EB33nmnPv30Uy1dulSNGjXS2LFjNXHiRPXv31+SVK5cOa1cuVL/+te/VL9+fc2ZM0dLlixRw4YN5enpqS1btqhTp06qU6eOxowZo2nTpik8PLxIxgAAAHCVGXnU/Pnz1b1791zfINizZ0998cUXOnv2rCIiIjR9+nS99957atiwoR544AH99ttvtr6fffaZWrZsqT59+qhBgwZ6/vnnlZVVdG9EtBi8C7lAUlNT5eXlpZSUFHl6ejo6HACAg1y6dMn2RhM3NzdHh4NCcq2fKzlA/jFXAIBrIY8q3gojX+JJKQAAAAAAAJiOohQAAAAAAABMR1EKAAAAAAAApqMoBQAAAAAAANNRlAIAAAAAAIDpKEoBAAAAAADAdBSlAAAAAAAAYDqKUgAAAAAAADAdRSkAAAAAAACYjqIUAAAokHbt2mnUqFGODgMAAKDYIY+6gqIUAAAlTJcuXdSxY8dcj3333XeyWCzas2fPTd8nOjpa5cqVu+nrAAAA3CrMyqOuunjxoipUqKBKlSopIyOj0K57q6AoBQBACTNw4EBt2LBBJ06cyHFswYIFatGihZo0aeKAyAAAAG5tZudRn332mRo2bKh69epp9erVhXbdWwVFKQAASpgHHnhA3t7eio6OtmtPS0vT8uXLNXDgQJ07d059+vTRHXfcIQ8PDzVu3FhLliwp1DiOHTumrl27qkyZMvL09NQjjzyipKQk2/Hdu3erffv2Klu2rDw9PdW8eXPt3LlTknT06FF16dJF5cuXV+nSpdWwYUN99dVXhRpfcTNr1ixVq1ZNbm5uCg4O1o4dO/LsGx0dLYvFYre5ubnZ9UlLS9Pw4cNVpUoVubu7q0GDBpozZ05RDwMAgFua2XnUvHnz9Nhjj+mxxx7TvHnzchzft2+fHnjgAXl6eqps2bK69957dfjwYdvx+fPnq2HDhrJarfLz89Pw4cMLFEdRKeXoAAAAuK0YhnT5T8fc28VDsliu261UqVLq16+foqOj9fLLL8vy/89Zvny5srKy1KdPH6Wlpal58+Z64YUX5OnpqTVr1ujxxx9XzZo11apVq5sONTs721aQ+vbbb/XXX39p2LBh6tWrlzZv3ixJ6tu3r5o1a6bZs2fL2dlZcXFxcnFxkSQNGzZMmZmZ2rJli0qXLq39+/erTJkyNx1XcbVs2TJFRkZqzpw5Cg4O1vTp0xUWFqaDBw+qcuXKuZ7j6empgwcP2vYt//jdiYyM1KZNm7Ro0SJVq1ZN69ev11NPPSV/f389+OCDRToeAEAJRR5l5/Dhw4qNjdXKlStlGIaeeeYZHT16VIGBgZKkkydPqk2bNmrXrp02bdokT09Pbd26VX/99Zckafbs2YqMjNQbb7yh8PBwpaSkaOvWrQWYnKJDUQoAgMJ0+U/pdX/H3PulU5Jr6Xx1feKJJzRlyhR9++23ateunaQrj5z37NlTXl5e8vLy0rPPPmvrP2LECK1bt06ffvppoRSlYmJitHfvXsXHxysgIECStHDhQjVs2FA//vijWrZsqWPHjum5555TvXr1JEm1a9e2nX/s2DH17NlTjRs3liTVqFHjpmMqzt566y0NHjxYAwYMkCTNmTNHa9as0fz58/Xiiy/meo7FYpGvr2+e19y2bZsiIiJsvx9DhgzR3LlztWPHDopSAICiQR5lZ/78+QoPD1f58uUlSWFhYVqwYIHGjx8v6cpT0l5eXlq6dKntg7s6derYzn/ttdc0evRoPf3007a2li1b5vv+ZuDrewAAlED16tVT69atNX/+fEnSoUOH9N1332ngwIGSpKysLL366qtq3LixKlSooDJlymjdunU6duxYodz/119/VUBAgK0gJUkNGjRQuXLl9Ouvv0q68qTOoEGDFBoaqjfeeMPuUfSRI0fqtdde0913361x48YV6oKixU1mZqZ27dql0NBQW5uTk5NCQ0MVGxub53lpaWkKDAxUQECAunbtqn379tkdb926tb744gudPHlShmHom2++0f/+9z/df//9eV4zIyNDqampdhsAALcbM/KorKwsffTRR3rsscdsbY899piio6OVnZ0tSYqLi9O9995rK0j93enTp3Xq1Cl16NDhZoZa5HhSCgCAwuTiceWTNkfd+wYMHDhQI0aM0KxZs7RgwQLVrFlTbdu2lSRNmTJFM2bM0PTp09W4cWOVLl1ao0aNUmZmZlFEnqvx48fr0Ucf1Zo1a/T1119r3LhxWrp0qbp3765BgwYpLCxMa9as0fr16zVp0iRNmzZNI0aMMC2+W8XZs2eVlZUlHx8fu3YfHx8dOHAg13Pq1q2r+fPnq0mTJkpJSdHUqVPVunVr7du3T1WqVJEkzZw5U0OGDFGVKlVUqlQpOTk56YMPPlCbNm3yjGXSpEmaMGFC4Q0OAFCykEfZrFu3TidPnlSvXr3s2rOyshQTE6P77rtP7u7ueZ5/rWO3Ep6UAgCgMFksVx79dsSWj3UQ/u6RRx6Rk5OTFi9erIULF+qJJ56wrYuwdetWde3aVY899piCgoJUo0YN/e9//yu0aapfv76OHz+u48eP29r279+v5ORkNWjQwNZWp04dPfPMM1q/fr169OihBQsW2I4FBARo6NChWrlypUaPHq0PPvig0OK73YWEhKhfv35q2rSp2rZtq5UrV8rb21tz58619Zk5c6Z++OEHffHFF9q1a5emTZumYcOGaePGjXleNyoqSikpKbbt7z9fAACuizzKZt68eerdu7fi4uLstt69e9sWPG/SpIm+++47Xb58Ocf5ZcuWVbVq1RQTE3ND9zUbT0oBAFBClSlTRr169VJUVJRSU1PVv39/27HatWtrxYoV2rZtm8qXL6+33npLSUlJdgWj/MjKylJcXJxdm9VqVWhoqBo3bqy+fftq+vTp+uuvv/TUU0+pbdu2atGihS5evKjnnntODz30kKpXr64TJ07oxx9/VM+ePSVJo0aNUnh4uOrUqaM//vhD33zzjerXr3+zU1IsVapUSc7OznZvLpSkpKSka64Z9XcuLi5q1qyZDh06JEm6ePGiXnrpJa1atUqdO3eWdCXxjYuL09SpU+2+Kvh3VqtVVqv1JkYDAEDxUJR51JkzZ/Tll1/qiy++UKNGjeyO9evXT927d9f58+c1fPhwzZw5U71791ZUVJS8vLz0ww8/qFWrVqpbt67Gjx+voUOHqnLlygoPD9eFCxe0devWW+rJcp6UAgCgBBs4cKD++OMPhYWFyd///xYWHTNmjO68806FhYWpXbt28vX1Vbdu3W74+mlpaWrWrJnd1qVLF1ksFn3++ecqX7682rRpo9DQUNWoUUPLli2TJDk7O+vcuXPq16+f6tSpo0ceeUTh4eG2r4ZlZWVp2LBhql+/vjp27Kg6derovffeK5Q5KW5cXV3VvHlzu09Cs7OzFRMTo5CQkHxdIysrS3v37pWfn58k6fLly7p8+bKcnOxTRWdnZ9s6FgAAlHRFlUctXLhQpUuXznU9qA4dOsjd3V2LFi1SxYoVtWnTJqWlpalt27Zq3ry5PvjgA9saUxEREZo+fbree+89NWzYUA888IB+++23mx53YbIYhmE4OojiKDU1VV5eXkpJSZGnp6ejwwEAOMilS5cUHx+v6tWry83NzdHhoJBc6+d6K+YAy5YtU0REhObOnatWrVpp+vTp+vTTT3XgwAH5+PioX79+uuOOOzRp0iRJ0sSJE3XXXXepVq1aSk5O1pQpU7R69Wrt2rXL9iluu3btdPbsWb377rsKDAzUt99+qyeffFJvvfWWnnzyyXzFdSvOFQDg1kEeVbwVRr7E1/cAAACKuV69eunMmTMaO3asEhMT1bRpU61du9a2+PmxY8fsnnr6448/NHjwYCUmJqp8+fJq3ry5tm3bZve1gqVLlyoqKkp9+/bV+fPnFRgYqP/85z8aOnSo6eMDAAC3J56UKiA++QMASHzCd7sqbk9K3aqYKwDAtZBHFW+FkS+xphQAAAAAAABMR1EKAAAAAAAApqMoBQAAAAAAANNRlAIAoBBkZ2c7OgQUIn6eAACYh6Wui6fCyJd4+x4AADfB1dVVTk5OOnXqlLy9veXq6iqLxeLosFBAhmEoMzNTZ86ckZOTk1xdXR0dEgAAty0XFxdZLBadOXNG3t7e5FDFRGHmSxSlAAC4CU5OTqpevboSEhJ06tQpR4eDQuLh4aGqVavKyYmHygEAKCrOzs6qUqWKTpw4oSNHjjg6HNygwsiXHFqU2rJli6ZMmaJdu3YpISFBq1atUrdu3fLsn5CQoNGjR2vnzp06dOiQRo4cqenTp9v1adeunb799tsc53bq1Elr1qyRJPXv318fffSR3fGwsDCtXbv2pscEACh5XF1dVbVqVf3111/KyspydDi4Sc7OzipVqhSf1gIAYIIyZcqodu3aunz5sqNDwQ0orHzJoUWp9PR0BQUF6YknnlCPHj2u2z8jI0Pe3t4aM2aM3n777Vz7rFy5UpmZmbb9c+fOKSgoSA8//LBdv44dO2rBggW2favVWsBRAAAgWSwWubi4yMXFxdGhAAAAFCvOzs5ydnZ2dBhwAIcWpcLDwxUeHp7v/tWqVdOMGTMkSfPnz8+1T4UKFez2ly5dKg8PjxxFKavVKl9f3xuMGAAAAAAAAIXhtl8oYd68eerdu7dKly5t175582ZVrlxZdevW1ZNPPqlz585d8zoZGRlKTU212wAAAAAAAFAwt3VRaseOHfrll180aNAgu/aOHTtq4cKFiomJ0Ztvvqlvv/1W4eHh11wHZNKkSfLy8rJtAQEBRR0+AAAAAADAbeu2fvvevHnz1LhxY7Vq1cquvXfv3rY/N27cWE2aNFHNmjW1efNmdejQIddrRUVFKTIy0rafmppKYQoAAAAAAKCAbtsnpdLT07V06VINHDjwun1r1KihSpUq6dChQ3n2sVqt8vT0tNsAAAAAAABQMLdtUWr58uXKyMjQY489dt2+J06c0Llz5+Tn52dCZAAAAAAAAHDo1/fS0tLsnk6Kj49XXFycKlSooKpVqyoqKkonT57UwoULbX3i4uJs5545c0ZxcXFydXVVgwYN7K49b948devWTRUrVsxxzwkTJqhnz57y9fXV4cOH9fzzz6tWrVoKCwsrusECAAAAAADAxqFFqZ07d6p9+/a2/atrNkVERCg6OloJCQk6duyY3TnNmjWz/XnXrl1avHixAgMDdeTIEVv7wYMH9f3332v9+vU57uns7Kw9e/boo48+UnJysvz9/XX//ffr1VdfldVqLeQRAgAAAAAAIDcWwzAMRwdRHKWmpsrLy0spKSmsLwUAQAlCDpB/zBUAACVTfnOA23ZNKQAAAAAAANy6KEoBAAAAAADAdBSlAAAAAAAAYDqKUgAAAAAAADAdRSkAAAAAAACYjqIUAAAAAAAATEdRCgAAAAAAAKajKAUAAAAAAADTUZQCAAAAAACA6ShKAQAAAAAAwHQUpQAAAAAAAGA6ilIAAAAAAAAwHUUpAAAAAAAAmI6iFAAAAAAAAExHUQoAAAAAAACmoygFAAAAAAAA01GUAgAAAAAAgOkoSgEAAAAAAMB0FKUAAAAAAABgOopSAAAAAAAAMB1FKQAAAAAAAJiOohQAAAAAAABMR1EKAAAAAAAApqMoBQAAAAAAANNRlAIAAAAAAIDpKEoBAAAAAADAdBSlAAAAAAAAYDqKUgAAAAAAADAdRSkAAAAAAACYjqIUAAAAAAAATEdRCgAAAAAAAKajKAUAAAAAAADTUZQCAAAAAACA6ShKAQAAAAAAwHQUpQAAAAAAAGA6hxaltmzZoi5dusjf318Wi0WrV6++Zv+EhAQ9+uijqlOnjpycnDRq1KgcfaKjo2WxWOw2Nzc3uz6GYWjs2LHy8/OTu7u7QkND9dtvvxXiyAAAAAAAAHAtDi1KpaenKygoSLNmzcpX/4yMDHl7e2vMmDEKCgrKs5+np6cSEhJs29GjR+2OT548We+8847mzJmj7du3q3Tp0goLC9OlS5duajwAAAAAAADIn1KOvHl4eLjCw8Pz3b9atWqaMWOGJGn+/Pl59rNYLPL19c31mGEYmj59usaMGaOuXbtKkhYuXCgfHx+tXr1avXv3voERAAAAAAAAoCBuyzWl0tLSFBgYqICAAHXt2lX79u2zHYuPj1diYqJCQ0NtbV5eXgoODlZsbKwjwgUAAAAAAChxbruiVN26dTV//nx9/vnnWrRokbKzs9W6dWudOHFCkpSYmChJ8vHxsTvPx8fHdiw3GRkZSk1NtdsAAAAAAABQMLddUSokJET9+vVT06ZN1bZtW61cuVLe3t6aO3fuTV130qRJ8vLysm0BAQGFFDEAAAAAAEDJc9sVpf7JxcVFzZo106FDhyTJttZUUlKSXb+kpKQ816GSpKioKKWkpNi248ePF13QAAAAAAAAt7nbviiVlZWlvXv3ys/PT5JUvXp1+fr6KiYmxtYnNTVV27dvV0hISJ7XsVqt8vT0tNsAAAAAAABQMA59+15aWprtCSbpyiLkcXFxqlChgqpWraqoqCidPHlSCxcutPWJi4uznXvmzBnFxcXJ1dVVDRo0kCRNnDhRd911l2rVqqXk5GRNmTJFR48e1aBBgyRdeTPfqFGj9Nprr6l27dqqXr26XnnlFfn7+6tbt26mjR0AAAAAAKAkc2hRaufOnWrfvr1tPzIyUpIUERGh6OhoJSQk6NixY3bnNGvWzPbnXbt2afHixQoMDNSRI0ckSX/88YcGDx6sxMRElS9fXs2bN9e2bdtsRStJev7555Wenq4hQ4YoOTlZ99xzj9auXSs3N7ciHC0AAAAAAACushiGYTg6iOIoNTVVXl5eSklJ4at8AACUIOQA+cdcAQBQMuU3B7jt15QCAAAAAADArYeiFAAAAAAAAExHUQoAAAAAAACmoygFAAAAAAAA01GUAgAAAAAAgOkoSgEAAAAAAMB0FKUAAABuA7NmzVK1atXk5uam4OBg7dixI8++0dHRslgsdpubm5tdn38ev7pNmTKlqIcCAABKCIpSAAAAxdyyZcsUGRmpcePG6aefflJQUJDCwsJ0+vTpPM/x9PRUQkKCbTt69Kjd8b8fS0hI0Pz582WxWNSzZ8+iHg4AACghKEoBAAAUc2+99ZYGDx6sAQMGqEGDBpozZ448PDw0f/78PM+xWCzy9fW1bT4+PnbH/37M19dXn3/+udq3b68aNWoU9XAAAEAJQVEKAACgGMvMzNSuXbsUGhpqa3NyclJoaKhiY2PzPC8tLU2BgYEKCAhQ165dtW/fvjz7JiUlac2aNRo4cGChxg4AAEo2ilIAAADF2NmzZ5WVlZXjSScfHx8lJibmek7dunU1f/58ff7551q0aJGys7PVunVrnThxItf+H330kcqWLasePXpcM5aMjAylpqbabQAAAHmhKAUAAFDChISEqF+/fmratKnatm2rlStXytvbW3Pnzs21//z589W3b98ci6H/06RJk+Tl5WXbAgICiiJ8AABwm6AoBQAAUIxVqlRJzs7OSkpKsmtPSkqSr69vvq7h4uKiZs2a6dChQzmOfffddzp48KAGDRp03etERUUpJSXFth0/fjx/gwAAACUSRSkAAIBizNXVVc2bN1dMTIytLTs7WzExMQoJCcnXNbKysrR37175+fnlODZv3jw1b95cQUFB172O1WqVp6en3QYAAJCXUo4OAAAAADcnMjJSERERatGihVq1aqXp06crPT1dAwYMkCT169dPd9xxhyZNmiRJmjhxou666y7VqlVLycnJmjJlio4ePZrjaajU1FQtX75c06ZNM31MAADg9kdRCgAAoJjr1auXzpw5o7FjxyoxMVFNmzbV2rVrbYufHzt2TE5O//eA/B9//KHBgwcrMTFR5cuXV/PmzbVt2zY1aNDA7rpLly6VYRjq06ePqeMBAAAlg8UwDMPRQRRHqamp8vLyUkpKCo+mAwBQgpAD5B9zBQBAyZTfHIA1pQAAAAAAAGA6ilIAAAAAAAAwHUUpAAAAAAAAmI6iFAAAAAAAAExHUQoAAAAAAACmoygFAAAAAAAA01GUAgAAAAAAgOkoSgEAAAAAAMB0FKUAAAAAAABgOopSAAAAAAAAMB1FKQAAAAAAAJiOohQAAAAAAABMR1EKAAAAAAAApqMoBQAAAAAAANNRlAIAAAAAAIDpKEoBAAAAAADAdBSlAAAAAAAAYDqKUgAAAAAAADAdRSkAAAAAAACYzqFFqS1btqhLly7y9/eXxWLR6tWrr9k/ISFBjz76qOrUqSMnJyeNGjUqR58PPvhA9957r8qXL6/y5csrNDRUO3bssOvTv39/WSwWu61jx46FODIAAAAAAABci0OLUunp6QoKCtKsWbPy1T8jI0Pe3t4aM2aMgoKCcu2zefNm9enTR998841iY2MVEBCg+++/XydPnrTr17FjRyUkJNi2JUuW3PR4AAAAAAAAkD+lHHnz8PBwhYeH57t/tWrVNGPGDEnS/Pnzc+3zySef2O1/+OGH+uyzzxQTE6N+/frZ2q1Wq3x9fQsQNQAAAAAAAG7Wbb+m1J9//qnLly+rQoUKdu2bN29W5cqVVbduXT355JM6d+6cgyIEAAAAAAAoeRz6pJQZXnjhBfn7+ys0NNTW1rFjR/Xo0UPVq1fX4cOH9dJLLyk8PFyxsbFydnbO9ToZGRnKyMiw7aemphZ57AAAAAAAALer27oo9cYbb2jp0qXavHmz3NzcbO29e/e2/blx48Zq0qSJatasqc2bN6tDhw65XmvSpEmaMGFCkccMAAAAAABQEty2X9+bOnWq3njjDa1fv15NmjS5Zt8aNWqoUqVKOnToUJ59oqKilJKSYtuOHz9e2CEDAAAAAACUGLflk1KTJ0/Wf/7zH61bt04tWrS4bv8TJ07o3Llz8vPzy7OP1WqV1WotzDABAAAAAABKLIcWpdLS0uyeToqPj1dcXJwqVKigqlWrKioqSidPntTChQttfeLi4mznnjlzRnFxcXJ1dVWDBg0kSW+++abGjh2rxYsXq1q1akpMTJQklSlTRmXKlFFaWpomTJignj17ytfXV4cPH9bzzz+vWrVqKSwszLzBAwAAAAAAlGAWwzAMR9188+bNat++fY72iIgIRUdHq3///jpy5Ig2b95sO2axWHL0DwwM1JEjRyRJ1apV09GjR3P0GTdunMaPH6+LFy+qW7du+vnnn5WcnCx/f3/df//9evXVV+Xj45Pv2FNTU+Xl5aWUlBR5enrm+zwAAFC8kQPkH3MFAEDJlN8cwKFFqeKMJAsAgJKJHCD/mCsAAEqm/OYAt+1C5wAAAAAAALh1UZQCAAAAAACA6ShKAQAAAAAAwHQUpQAAAAAAAGA6ilIAAAAAAAAwHUUpAAAAAAAAmI6iFAAAAAAAAExHUQoAAAAAAACmoygFAAAAAAAA01GUAgAAAAAAgOkoSgEAAAAAAMB0FKUAAAAAAABgOopSAAAAAAAAMB1FKQAAAAAAAJiOohQAAAAAAABMR1EKAADAAapVq6aJEyfq2LFjjg4FAADAIShKAQAAOMCoUaO0cuVK1ahRQ/fdd5+WLl2qjIwMR4cFAABgGopSAAAADjBq1CjFxcVpx44dql+/vkaMGCE/Pz8NHz5cP/30k6PDAwAAKHIUpQAAABzozjvv1DvvvKNTp05p3Lhx+vDDD9WyZUs1bdpU8+fPl2EYjg4RAACgSJRydAAAAAAl2eXLl7Vq1SotWLBAGzZs0F133aWBAwfqxIkTeumll7Rx40YtXrzY0WECAAAUOopSAAAADvDTTz9pwYIFWrJkiZycnNSvXz+9/fbbqlevnq1P9+7d1bJlSwdGCQAAUHQoSgEAADhAy5Ytdd9992n27Nnq1q2bXFxccvSpXr26evfu7YDoAAAAih5FKQAAAAf4/fffFRgYeM0+pUuX1oIFC0yKCAAAwFwsdA4AAOAAp0+f1vbt23O0b9++XTt37nRARAAAAOaiKAUAAOAAw4YN0/Hjx3O0nzx5UsOGDXNARAAAAOaiKAUAAOAA+/fv15133pmjvVmzZtq/f78DIgIAADAXRSkAAAAHsFqtSkpKytGekJCgUqVY9hMAANz+KEoBAAA4wP3336+oqCilpKTY2pKTk/XSSy/pvvvuc2BkAAAA5uBjOAAAAAeYOnWq2rRpo8DAQDVr1kySFBcXJx8fH3388ccOjg4AAKDoUZQCAABwgDvuuEN79uzRJ598ot27d8vd3V0DBgxQnz595OLi4ujwAAAAihxFKQAAAAcpXbq0hgwZ4ugwAAAAHIKiFAAAgAPt379fx44dU2Zmpl37gw8+6KCIAAAAzEFRCgAAwAF+//13de/eXXv37pXFYpFhGJIki8UiScrKynJkeAAAAEWuQG/fO378uE6cOGHb37Fjh0aNGqX333+/0AIDAAC4nT399NOqXr26Tp8+LQ8PD+3bt09btmxRixYttHnzZkeHBwAAUOQKVJR69NFH9c0330iSEhMTdd9992nHjh16+eWXNXHixEINEAAA4HYUGxuriRMnqlKlSnJycpKTk5PuueceTZo0SSNHjnR0eAAAAEWuQEWpX375Ra1atZIkffrpp2rUqJG2bdumTz75RNHR0YUZHwAAwG0pKytLZcuWlSRVqlRJp06dkiQFBgbq4MGDjgwNAADAFAUqSl2+fFlWq1WStHHjRttCnPXq1VNCQkK+r7NlyxZ16dJF/v7+slgsWr169TX7JyQk6NFHH1WdOnXk5OSkUaNG5dpv+fLlqlevntzc3NS4cWN99dVXdscNw9DYsWPl5+cnd3d3hYaG6rfffst33AAAADerUaNG2r17tyQpODhYkydP1tatWzVx4kTVqFHDwdEBAAAUvQIVpRo2bKg5c+bou+++04YNG9SxY0dJ0qlTp1SxYsV8Xyc9PV1BQUGaNWtWvvpnZGTI29tbY8aMUVBQUK59tm3bpj59+mjgwIH6+eef1a1bN3Xr1k2//PKLrc/kyZP1zjvvaM6cOdq+fbtKly6tsLAwXbp0Kd+xAwAA3IwxY8YoOztbkjRx4kTFx8fr3nvv1VdffaV33nnHwdEBAAAUPYtx9VUvN2Dz5s3q3r27UlNTFRERofnz50uSXnrpJR04cEArV6688UAsFq1atUrdunXLV/927dqpadOmmj59ul17r169lJ6erv/+97+2trvuuktNmzbVnDlzZBiG/P39NXr0aD377LOSpJSUFPn4+Cg6Olq9e/fO1/1TU1Pl5eWllJQUeXp65uscAABQ/BVlDnD+/HmVL1/e9ga+4o58CQCAkim/OUCBnpRq166dzp49q7Nnz9oKUpI0ZMgQzZkzpyCXLDSxsbEKDQ21awsLC1NsbKwkKT4+XomJiXZ9vLy8FBwcbOuTm4yMDKWmptptAAAABXH58mWVKlXK7kluSapQoUKBC1KzZs1StWrV5ObmpuDgYO3YsSPPvtHR0bJYLHabm5tbjn6//vqrHnzwQXl5eal06dJq2bKljh07VqD4AAAA/qlARamLFy8qIyND5cuXlyQdPXpU06dP18GDB1W5cuVCDfBGJSYmysfHx67Nx8dHiYmJtuNX2/Lqk5tJkybJy8vLtgUEBBRy5AAAoKRwcXFR1apVlZWVVSjXW7ZsmSIjIzVu3Dj99NNPCgoKUlhYmE6fPp3nOZ6enkpISLBtR48etTt++PBh3XPPPapXr542b96sPXv26JVXXsm1eAUAAFAQBSpKde3aVQsXLpQkJScnKzg4WNOmTVO3bt00e/bsQg3wVhEVFaWUlBTbdvz4cUeHBAAAirGXX35ZL730ks6fP3/T13rrrbc0ePBgDRgwQA0aNNCcOXPk4eFh90T7P1ksFvn6+tq2f35g9/LLL6tTp06aPHmymjVrppo1a+rBBx90+AeQAADg9lGgotRPP/2ke++9V5K0YsUK+fj46OjRo1q4cKHDF+b09fVVUlKSXVtSUpJ8fX1tx6+25dUnN1arVZ6ennYbAABAQb377rvasmWL/P39VbduXd155512W35lZmZq165ddksTODk5KTQ09JpLE6SlpSkwMFABAQHq2rWr9u3bZzuWnZ2tNWvWqE6dOgoLC1PlypUVHBx83TclAwAA3IhSBTnpzz//VNmyZSVJ69evV48ePeTk5KS77rorx6PfZgsJCVFMTIxGjRpla9uwYYNCQkIkSdWrV5evr69iYmLUtGlTSVcW4Nq+fbuefPJJB0QMAABKovy+3OV6zp49q6ysrFyXJjhw4ECu59StW1fz589XkyZNlJKSoqlTp6p169bat2+fqlSpotOnTystLU1vvPGGXnvtNb355ptau3atevTooW+++UZt27bN9boZGRnKyMiw7bMGJwAAuJYCFaVq1aql1atXq3v37lq3bp2eeeYZSdLp06dv6AmitLQ0HTp0yLYfHx+vuLg4VahQQVWrVlVUVJROnjxp+6qgJMXFxdnOPXPmjOLi4uTq6qoGDRpIkp5++mm1bdtW06ZNU+fOnbV06VLt3LlT77//vqQrj6qPGjVKr732mmrXrq3q1avrlVdekb+/f6ElhwAAANczbtw4h907JCTE9oGdJLVu3Vr169fX3Llz9eqrryo7O1vSlSUbruZ5TZs21bZt2zRnzpw8i1KTJk3ShAkTin4AAADgtlCgr++NHTtWzz77rKpVq6ZWrVrZkpr169erWbNm+b7Ozp071axZM9s5kZGRatasmcaOHStJSkhIyPGGl6v9d+3apcWLF6tZs2bq1KmT7Xjr1q21ePFivf/++woKCtKKFSu0evVqNWrUyNbn+eef14gRIzRkyBC1bNlSaWlpWrt2LQt3AgCAYqdSpUpydna+4aUJ/s7FxUXNmjWzfVhYqVIllSpVyvah31X169e/5tv3WIMTAADcCIthGEZBTkxMTFRCQoKCgoLk5HSltrVjxw55enqqXr16hRrkrSg1NVVeXl5KSUlhfSkAAEqQwsoBnJycZLFY8jx+I2/mCw4OVqtWrTRz5kxJV9aEqlq1qoYPH64XX3zxuudnZWWpYcOG6tSpk9566y1JVz7oq1mzpj7++GNbv+7du8vd3V2LFy/OV1zkSwAAlEz5zQEK9PU9SbY3tZw4cUKSVKVKFbVq1aqglwMAAChRVq1aZbd/+fJl/fzzz/roo49u+CtwkZGRioiIUIsWLdSqVStNnz5d6enpGjBggCSpX79+uuOOOzRp0iRJ0sSJE3XXXXepVq1aSk5O1pQpU3T06FENGjTIds3nnntOvXr1Ups2bdS+fXutXbtWX375pTZv3nxzAwcAAPj/ClSUys7O1muvvaZp06YpLS1NklS2bFmNHj1aL7/8su3JKQAAAOSua9euOdoeeughNWzYUMuWLdPAgQPzfa1evXrpzJkzGjt2rBITE9W0aVOtXbvWtvj5sWPH7PKzP/74Q4MHD1ZiYqLKly+v5s2ba9u2bXZf1+vevbvmzJmjSZMmaeTIkapbt64+++wz3XPPPTcxagAAgP9ToK/vRUVFad68eZowYYLuvvtuSdL333+v8ePHa/DgwfrPf/5T6IHeangcHQCAkqmoc4Dff/9dTZo0sX3wV5yRLwEAUDIV6df3PvroI3344Yd68MEHbW1NmjTRHXfcoaeeeqpEFKUAAAAK28WLF/XOO+/ojjvucHQoAAAARa5ARanz58/nuph5vXr1dP78+ZsOCgAA4HZXvnx5u4XODcPQhQsX5OHhoUWLFjkwMgAAAHMUqCgVFBSkd999V++8845d+7vvvqsmTZoUSmAAAAC3s7ffftuuKOXk5CRvb28FBwerfPnyDowMAADAHAUqSk2ePFmdO3fWxo0bFRISIkmKjY3V8ePH9dVXXxVqgAAAALej/v37OzoEAAAAhyrQa/Latm2r//3vf+revbuSk5OVnJysHj16aN++ffr4448LO0YAAIDbzoIFC7R8+fIc7cuXL9dHH33kgIgAAADMVaC37+Vl9+7duvPOO5WVlVVYl7xl8TYZAABKpsLKAerUqaO5c+eqffv2du3ffvuthgwZooMHD95sqA5HvgQAQMmU3xygQE9KAQAA4OYcO3ZM1atXz9EeGBioY8eOOSAiAAAAc1GUAgAAcIDKlStrz549Odp3796tihUrOiAiAAAAc1GUAgAAcIA+ffpo5MiR+uabb5SVlaWsrCxt2rRJTz/9tHr37u3o8AAAAIrcDb19r0ePHtc8npycfDOxAAAAlBivvvqqjhw5og4dOqhUqSspWXZ2tvr166fXX3/dwdEBAAAUvRsqSnl5eV33eL9+/W4qIAAAgJLA1dVVy5Yt02uvvaa4uDi5u7urcePGCgwMdHRoAAAAprihotSCBQuKKg4AAIASqXbt2qpdu7ajwwAAADAda0oBAAA4QM+ePfXmm2/maJ88ebIefvhhB0QEAABgLopSAAAADrBlyxZ16tQpR3t4eLi2bNnigIgAAADMRVEKAADAAdLS0uTq6pqj3cXFRampqQ6ICAAAwFwUpQAAABygcePGWrZsWY72pUuXqkGDBg6ICAAAwFw3tNA5AAAACscrr7yiHj166PDhw/rXv/4lSYqJidHixYu1YsUKB0cHAABQ9ChKAQAAOECXLl20evVqvf7661qxYoXc3d0VFBSkTZs2qUKFCo4ODwAAoMhRlAIAAHCQzp07q3PnzpKk1NRULVmyRM8++6x27dqlrKwsB0cHAABQtFhTCgAAwIG2bNmiiIgI+fv7a9q0afrXv/6lH374wdFhAQAAFDmelAIAADBZYmKioqOjNW/ePKWmpuqRRx5RRkaGVq9ezSLnAACgxOBJKQAAABN16dJFdevW1Z49ezR9+nSdOnVKM2fOdHRYAAAApuNJKQAAABN9/fXXGjlypJ588knVrl3b0eEAAAA4DE9KAQAAmOj777/XhQsX1Lx5cwUHB+vdd9/V2bNnHR0WAACA6ShKAQAAmOiuu+7SBx98oISEBP373//W0qVL5e/vr+zsbG3YsEEXLlxwdIgAAACmoCgFAADgAKVLl9YTTzyh77//Xnv37tXo0aP1xhtvqHLlynrwwQcdHR4AAECRoygFAADgYHXr1tXkyZN14sQJLVmyxNHhAAAAmIKiFAAAwC3C2dlZ3bp10xdffOHoUAAAAIocRSkAAAAAAACYjqIUAAAAAAAATEdRCgAAAAAAAKajKAUAAAAAAADTUZQCAAAAAACA6RxalNqyZYu6dOkif39/WSwWrV69+rrnbN68WXfeeaesVqtq1aql6Ohou+PVqlWTxWLJsQ0bNszWp127djmODx06tJBHBwAAAAAAgLw4tCiVnp6uoKAgzZo1K1/94+Pj1blzZ7Vv315xcXEaNWqUBg0apHXr1tn6/Pjjj0pISLBtGzZskCQ9/PDDdtcaPHiwXb/JkycX3sAAAAAAAABwTaUcefPw8HCFh4fnu/+cOXNUvXp1TZs2TZJUv359ff/993r77bcVFhYmSfL29rY754033lDNmjXVtm1bu3YPDw/5+vre5AgAAAAAAABQEMVqTanY2FiFhobatYWFhSk2NjbX/pmZmVq0aJGeeOIJWSwWu2OffPKJKlWqpEaNGikqKkp//vnnNe+dkZGh1NRUuw0AAAAAAAAF49AnpW5UYmKifHx87Np8fHyUmpqqixcvyt3d3e7Y6tWrlZycrP79+9u1P/roowoMDJS/v7/27NmjF154QQcPHtTKlSvzvPekSZM0YcKEQhsLAAAAAABASVasilI3at68eQoPD5e/v79d+5AhQ2x/bty4sfz8/NShQwcdPnxYNWvWzPVaUVFRioyMtO2npqYqICCgaAIHAAAAAAC4zRWropSvr6+SkpLs2pKSkuTp6ZnjKamjR49q48aN13z66arg4GBJ0qFDh/IsSlmtVlmt1gJGDgAAAAAAgL8rVmtKhYSEKCYmxq5tw4YNCgkJydF3wYIFqly5sjp37nzd68bFxUmS/Pz8CiVOAAAAAAAAXJtDi1JpaWmKi4uzFYXi4+MVFxenY8eOSbrylbl+/frZ+g8dOlS///67nn/+eR04cEDvvfeePv30Uz3zzDN2183OztaCBQsUERGhUqXsHwY7fPiwXn31Ve3atUtHjhzRF198oX79+qlNmzZq0qRJ0Q4YAAAAAAAAkhz89b2dO3eqffv2tv2razZFREQoOjpaCQkJtgKVJFWvXl1r1qzRM888oxkzZqhKlSr68MMPFRYWZnfdjRs36tixY3riiSdy3NPV1VUbN27U9OnTlZ6eroCAAPXs2VNjxowpolECAAAAAADgnyyGYRiODqI4Sk1NlZeXl1JSUuTp6enocAAAgEnIAfKPuQIAoGTKbw5QrNaUAgAAAAAAwO2BohQAAAAAAABMR1EKAAAAAAAApqMoBQAAAAAAANNRlAIAAAAAAIDpKEoBAAAAAADAdBSlAAAAAAAAYDqKUgAAAAAAADAdRSkAAAAAAACYjqIUAAAAAAAATEdRCgAAAAAAAKajKAUAAAAAAADTUZQCAAAAAACA6ShKAQAAAAAAwHQUpQAAAAAAAGA6ilIAAAAAAAAwHUUpAAAAAAAAmI6iFAAAAAAAAExHUQoAAAAAAACmoygFAAAAAAAA01GUAgAAAAAAgOkoSgEAAAAAAMB0FKUAAAAAAABgOopSAAAAAAAAMB1FKQAAAAAAAJiOohQAAAAAAABMR1EKAADgNjBr1ixVq1ZNbm5uCg4O1o4dO/LsGx0dLYvFYre5ubnZ9enfv3+OPh07dizqYQAAgBKklKMDAAAAwM1ZtmyZIiMjNWfOHAUHB2v69OkKCwvTwYMHVbly5VzP8fT01MGDB237FoslR5+OHTtqwYIFtn2r1Vr4wQMAgBKLJ6UAAACKubfeekuDBw/WgAED1KBBA82ZM0ceHh6aP39+nudYLBb5+vraNh8fnxx9rFarXZ/y5csX5TAAAEAJQ1EKAACgGMvMzNSuXbsUGhpqa3NyclJoaKhiY2PzPC8tLU2BgYEKCAhQ165dtW/fvhx9Nm/erMqVK6tu3bp68sknde7cuWvGkpGRodTUVLsNAAAgLxSlAAAAirGzZ88qKysrx5NOPj4+SkxMzPWcunXrav78+fr888+1aNEiZWdnq3Xr1jpx4oStT8eOHbVw4ULFxMTozTff1Lfffqvw8HBlZWXlGcukSZPk5eVl2wICAgpnkAAA4LbEmlIAAAAlTEhIiEJCQmz7rVu3Vv369TV37ly9+uqrkqTevXvbjjdu3FhNmjRRzZo1tXnzZnXo0CHX60ZFRSkyMtK2n5qaSmEKAADkiSelAAAAirFKlSrJ2dlZSUlJdu1JSUny9fXN1zVcXFzUrFkzHTp0KM8+NWrUUKVKla7Zx2q1ytPT024DAADIC0UpAACAYszV1VXNmzdXTEyMrS07O1sxMTF2T0NdS1ZWlvbu3Ss/P788+5w4cULnzp27Zh8AAIAbQVEKAACgmIuMjNQHH3ygjz76SL/++quefPJJpaena8CAAZKkfv36KSoqytZ/4sSJWr9+vX7//Xf99NNPeuyxx3T06FENGjRI0pVF0J977jn98MMPOnLkiGJiYtS1a1fVqlVLYWFhDhkjAAC4/Ti0KLVlyxZ16dJF/v7+slgsWr169XXP2bx5s+68805ZrVbVqlVL0dHRdsfHjx8vi8Vit9WrV8+uz6VLlzRs2DBVrFhRZcqUUc+ePXM88g4AAFBc9OrVS1OnTtXYsWPVtGlTxcXFae3atbbFz48dO6aEhARb/z/++EODBw9W/fr11alTJ6Wmpmrbtm1q0KCBJMnZ2Vl79uzRgw8+qDp16mjgwIFq3ry5vvvuO1mtVoeMEQAA3H4shmEYjrr5119/ra1bt6p58+bq0aOHVq1apW7duuXZPz4+Xo0aNdLQoUM1aNAgxcTEaNSoUVqzZo3tU7vx48drxYoV2rhxo+28UqVKqVKlSrb9J598UmvWrFF0dLS8vLw0fPhwOTk5aevWrfmOPTU1VV5eXkpJSWG9BAAAShBygPxjrgAAKJnymwM49O174eHhCg8Pz3f/OXPmqHr16po2bZokqX79+vr+++/19ttv2z1KXqpUqTwX9kxJSdG8efO0ePFi/etf/5IkLViwQPXr19cPP/ygu+666yZGBAAAAAAAgPwoVmtKxcbGKjQ01K4tLCxMsbGxdm2//fab/P39VaNGDfXt21fHjh2zHdu1a5cuX75sd5169eqpatWqOa4DAAAAAACAouHQJ6VuVGJiom1thKt8fHyUmpqqixcvyt3dXcHBwYqOjlbdunWVkJCgCRMm6N5779Uvv/yismXLKjExUa6uripXrlyO6yQmJuZ574yMDGVkZNj2U1NTC3VsAAAAAAAAJUmxKkrlx9+/DtikSRMFBwcrMDBQn376qQYOHFjg606aNEkTJkwojBABAAAAAABKvGL19T1fX98cb8lLSkqSp6en3N3dcz2nXLlyqlOnjg4dOmS7RmZmppKTk3NcJ691qCQpKipKKSkptu348eM3NxgAAAAAAIASrFgVpUJCQhQTE2PXtmHDBoWEhOR5Tlpamg4fPiw/Pz9JUvPmzeXi4mJ3nYMHD+rYsWPXvI7VapWnp6fdBgAAAAAAgIJx6Nf30tLSbE8wSVJ8fLzi4uJUoUIFVa1aVVFRUTp58qQWLlwoSRo6dKjeffddPf/883riiSe0adMmffrpp1qzZo3tGs8++6y6dOmiwMBAnTp1SuPGjZOzs7P69OkjSfLy8tLAgQMVGRmpChUqyNPTUyNGjFBISAhv3gMAAAAAADCJQ4tSO3fuVPv27W37kZGRkqSIiAhFR0crISHB7s151atX15o1a/TMM89oxowZqlKlij788EOFhYXZ+pw4cUJ9+vTRuXPn5O3trXvuuUc//PCDvL29bX3efvttOTk5qWfPnsrIyFBYWJjee+89E0YMAAAAAAAASbIYhmE4OojiKDU1VV5eXkpJSeGrfAAAlCDkAPnHXAEAUDLlNwcoVmtKAQAAAAAA4PZAUQoAAAAAAACmoygFAAAAAAAA01GUAgAAAAAAgOkoSgEAAAAAAMB0FKUAAAAAAABgOopSAAAAAAAAMB1FKQAAAAAAAJiOohQAAAAAAABMR1EKAAAAAAAApqMoBQAAAAAAANNRlAIAAAAAAIDpKEoBAAAAAADAdBSlAAAAAAAAYDqKUgAAAAAAADAdRSkAAAAAAACYjqIUAAAAAAAATEdRCgAAAAAAAKajKAUAAAAAAADTUZQCAAAAAACA6ShKAQAAAAAAwHQUpQAAAAAAAGA6ilIAAAAAAAAwHUUpAAAAAAAAmI6iFAAAAAAAAExHUQoAAAAAAACmoygFAAAAAAAA01GUAgAAAAAAgOkoSgEAAAAAAMB0FKUAAAAAAABgOopSAAAAAAAAMB1FKQAAAAAAAJiOohQAAAAAAABMR1EKAAAAAAAApqMoBQAAAAAAANNRlAIAAAAAAIDpHFqU2rJli7p06SJ/f39ZLBatXr36uuds3rxZd955p6xWq2rVqqXo6Gi745MmTVLLli1VtmxZVa5cWd26ddPBgwft+rRr104Wi8VuGzp0aCGODAAAAAAAANfi0KJUenq6goKCNGvWrHz1j4+PV+fOndW+fXvFxcVp1KhRGjRokNatW2fr8+2332rYsGH64YcftGHDBl2+fFn333+/0tPT7a41ePBgJSQk2LbJkycX6tgAAAAAAACQt1KOvHl4eLjCw8Pz3X/OnDmqXr26pk2bJkmqX7++vv/+e7399tsKCwuTJK1du9bunOjoaFWuXFm7du1SmzZtbO0eHh7y9fUthFEAAAAAAADgRhWrNaViY2MVGhpq1xYWFqbY2Ng8z0lJSZEkVahQwa79k08+UaVKldSoUSNFRUXpzz//LPyAAQAAAAAAkCuHPil1oxITE+Xj42PX5uPjo9TUVF28eFHu7u52x7KzszVq1CjdfffdatSoka390UcfVWBgoPz9/bVnzx698MILOnjwoFauXJnnvTMyMpSRkWHbT01NLaRRAQAAAAAAlDzFqih1o4YNG6ZffvlF33//vV37kCFDbH9u3Lix/Pz81KFDBx0+fFg1a9bM9VqTJk3ShAkTijReAAAAAACAkqJYfX3P19dXSUlJdm1JSUny9PTM8ZTU8OHD9d///lfffPONqlSpcs3rBgcHS5IOHTqUZ5+oqCilpKTYtuPHjxdwFAAAAAAAAChWT0qFhIToq6++smvbsGGDQkJCbPuGYWjEiBFatWqVNm/erOrVq1/3unFxcZIkPz+/PPtYrVZZrdaCBQ4AAAAAAAA7Di1KpaWl2T2dFB8fr7i4OFWoUEFVq1ZVVFSUTp48qYULF0qShg4dqnfffVfPP/+8nnjiCW3atEmffvqp1qxZY7vGsGHDtHjxYn3++ecqW7asEhMTJUleXl5yd3fX4cOHtXjxYnXq1EkVK1bUnj179Mwzz6hNmzZq0qSJuRMAAAAAAABQQjm0KLVz5061b9/eth8ZGSlJioiIUHR0tBISEnTs2DHb8erVq2vNmjV65plnNGPGDFWpUkUffvihwsLCbH1mz54tSWrXrp3dvRYsWKD+/fvL1dVVGzdu1PTp05Wenq6AgAD17NlTY8aMKcKRAgAAAAAA4O8shmEYjg6iOEpNTZWXl5dSUlLk6enp6HAAAIBJyAHyj7kCAKBkym8OUKwWOgcAAAAAAMDtgaIUAAAAAAAATEdRCgAAAAAAAKajKAUAAAAAAADTUZQCAAAAAACA6ShKAQAAAAAAwHQUpQAAAAAAAGA6ilIAAAAAAAAwHUUpAAAAAAAAmI6iFAAAAAAAAExHUQoAAAAAAACmoygFAAAAAAAA01GUAgAAAAAAgOkoSgEAANwGZs2apWrVqsnNzU3BwcHasWNHnn2jo6NlsVjsNjc3tzz7Dx06VBaLRdOnTy+CyAEAQElFUQoAAKCYW7ZsmSIjIzVu3Dj99NNPCgoKUlhYmE6fPp3nOZ6enkpISLBtR48ezbXfqlWr9MMPP8jf37+owgcAACUURSkAAIBi7q233tLgwYM1YMAANWjQQHPmzJGHh4fmz5+f5zkWi0W+vr62zcfHJ0efkydPasSIEfrkk0/k4uJSlEMAAAAlEEUpAACAYiwzM1O7du1SaGiorc3JyUmhoaGKjY3N87y0tDQFBgYqICBAXbt21b59++yOZ2dn6/HHH9dzzz2nhg0b5iuWjIwMpaam2m0AAAB5oSgFAABQjJ09e1ZZWVk5nnTy8fFRYmJirufUrVtX8+fP1+eff65FixYpOztbrVu31okTJ2x93nzzTZUqVUojR47MdyyTJk2Sl5eXbQsICCjYoAAAQIlAUQoAAKCECQkJUb9+/dS0aVO1bdtWK1eulLe3t+bOnStJ2rVrl2bMmGFbED2/oqKilJKSYtuOHz9eVEMAAAC3AYpSAAAAxVilSpXk7OyspKQku/akpCT5+vrm6xouLi5q1qyZDh06JEn67rvvdPr0aVWtWlWlSpVSqVKldPToUY0ePVrVqlXL8zpWq1Wenp52GwAAQF4oSgEAABRjrq6uat68uWJiYmxt2dnZiomJUUhISL6ukZWVpb1798rPz0+S9Pjjj2vPnj2Ki4uzbf7+/nruuee0bt26IhkHAAAoeUo5OgAAAADcnMjISEVERKhFixZq1aqVpk+frvT0dA0YMECS1K9fP91xxx2aNGmSJGnixIm66667VKtWLSUnJ2vKlCk6evSoBg0aJEmqWLGiKlasaHcPFxcX+fr6qm7duuYODgAA3LYoSgEAABRzvXr10pkzZzR27FglJiaqadOmWrt2rW3x82PHjsnJ6f8ekP/jjz80ePBgJSYmqnz58mrevLm2bdumBg0aOGoIAACgBLIYhmE4OojiKDU1VV5eXkpJSWG9BAAAShBygPxjrgAAKJnymwOwphQAAAAAAABMR1EKAAAAAAAApqMoBQAAAAAAANNRlAIAAAAAAIDpKEoBAAAAAADAdBSlAAAAAAAAYDqKUgAAAAAAADAdRSkAAAAAAACYjqIUAAAAAAAATEdRCgAAAAAAAKajKAUAAAAAAADTUZQCAAAAAACA6RxalNqyZYu6dOkif39/WSwWrV69+rrnbN68WXfeeaesVqtq1aql6OjoHH1mzZqlatWqyc3NTcHBwdqxY4fd8UuXLmnYsGGqWLGiypQpo549eyopKamQRgUAAAAAAIDrcWhRKj09XUFBQZo1a1a++sfHx6tz585q37694uLiNGrUKA0aNEjr1q2z9Vm2bJkiIyM1btw4/fTTTwoKClJYWJhOnz5t6/PMM8/oyy+/1PLly/Xtt9/q1KlT6tGjR6GPDwAAAAAAALmzGIZhODoISbJYLFq1apW6deuWZ58XXnhBa9as0S+//GJr6927t5KTk7V27VpJUnBwsFq2bKl3331XkpSdna2AgACNGDFCL774olJSUuTt7a3FixfroYcekiQdOHBA9evXV2xsrO666658xZuamiovLy+lpKTI09OzgKMGAADFDTlA/jFXAACUTPnNAYrVmlKxsbEKDQ21awsLC1NsbKwkKTMzU7t27bLr4+TkpNDQUFufXbt26fLly3Z96tWrp6pVq9r65CYjI0Opqal2GwAAAAAAAAqmWBWlEhMT5ePjY9fm4+Oj1NRUXbx4UWfPnlVWVlaufRITE23XcHV1Vbly5fLsk5tJkybJy8vLtgUEBBTOoAAAAAAAAEqgYlWUcqSoqCilpKTYtuPHjzs6JAAAAAAAgGKrlKMDuBG+vr453pKXlJQkT09Pubu7y9nZWc7Ozrn28fX1tV0jMzNTycnJdk9L/b1PbqxWq6xWa+ENBgAAAAAAoAQrVk9KhYSEKCYmxq5tw4YNCgkJkSS5urqqefPmdn2ys7MVExNj69O8eXO5uLjY9Tl48KCOHTtm6wMAAAAAAICi5dAnpdLS0nTo0CHbfnx8vOLi4lShQgVVrVpVUVFROnnypBYuXChJGjp0qN599109//zzeuKJJ7Rp0yZ9+umnWrNmje0akZGRioiIUIsWLdSqVStNnz5d6enpGjBggCTJy8tLAwcOVGRkpCpUqCBPT0+NGDFCISEh+X7zHgAAAAAAAG6OQ4tSO3fuVPv27W37kZGRkqSIiAhFR0crISFBx44dsx2vXr261qxZo2eeeUYzZsxQlSpV9OGHHyosLMzWp1evXjpz5ozGjh2rxMRENW3aVGvXrrVb/Pztt9+Wk5OTevbsqYyMDIWFhem9994zYcQAAAAAAACQJIthGIajgyiOUlNT5eXlpZSUFHl6ejo6HAAAYBJygPxjrgAAKJnymwMUqzWlAAAAAAAAcHugKAUAAAAAAADTUZQCAAAAAACA6ShKAQAAAAAAwHQUpQAAAAAAAGA6ilIAAAAAAAAwHUUpAAAAAAAAmI6iFAAAAAAAAExHUQoAAAAAAACmoygFAAAAAAAA01GUAgAAAAAAgOkoSgEAAAAAAMB0pRwdQHFlGIYkKTU11cGRAAAAM139t/9qLoC8kS8BAFAy5TdfoihVQBcuXJAkBQQEODgSAADgCBcuXJCXl5ejw7ilkS8BAFCyXS9fshh8zFcg2dnZOnXqlMqWLSuLxeLocG4ZqampCggI0PHjx+Xp6enocEoE5tx8zLljMO/mY85zZxiGLly4IH9/fzk5sRLCtZAv5Y6/W+Zjzs3HnDsG824+5jx3+c2XeFKqgJycnFSlShVHh3HL8vT05C+kyZhz8zHnjsG8m485z4knpPKHfOna+LtlPubcfMy5YzDv5mPOc8pPvsTHewAAAAAAADAdRSkAAAAAAACYjqIUCpXVatW4ceNktVodHUqJwZybjzl3DObdfMw5UDT4u2U+5tx8zLljMO/mY85vDgudAwAAAAAAwHQ8KQUAAAAAAADTUZQCAAAAAACA6ShKAQAAAAAAwHQUpXBDzp8/r759+8rT01PlypXTwIEDlZaWds1zLl26pGHDhqlixYoqU6aMevbsqaSkpFz7njt3TlWqVJHFYlFycnIRjKD4KYo53717t/r06aOAgAC5u7urfv36mjFjRlEP5ZY2a9YsVatWTW5ubgoODtaOHTuu2X/58uWqV6+e3Nzc1LhxY3311Vd2xw3D0NixY+Xn5yd3d3eFhobqt99+K8ohFDuFOeeXL1/WCy+8oMaNG6t06dLy9/dXv379dOrUqaIeRrFT2L/rfzd06FBZLBZNnz69kKMGihfyJccgZyp65EvmI19yDPIlExnADejYsaMRFBRk/PDDD8Z3331n1KpVy+jTp881zxk6dKgREBBgxMTEGDt37jTuuusuo3Xr1rn27dq1qxEeHm5IMv74448iGEHxUxRzPm/ePGPkyJHG5s2bjcOHDxsff/yx4e7ubsycObOoh3NLWrp0qeHq6mrMnz/f2LdvnzF48GCjXLlyRlJSUq79t27dajg7OxuTJ0829u/fb4wZM8ZwcXEx9u7da+vzxhtvGF5eXsbq1auN3bt3Gw8++KBRvXp14+LFi2YN65ZW2HOenJxshIaGGsuWLTMOHDhgxMbGGq1atTKaN29u5rBueUXxu37VypUrjaCgIMPf3994++23i3gkwK2NfMkxyJmKFvmS+ciXHIN8yVwUpZBv+/fvNyQZP/74o63t66+/NiwWi3Hy5Mlcz0lOTjZcXFyM5cuX29p+/fVXQ5IRGxtr1/e9994z2rZta8TExJBk/X9FPed/99RTTxnt27cvvOCLkVatWhnDhg2z7WdlZRn+/v7GpEmTcu3/yCOPGJ07d7ZrCw4ONv79738bhmEY2dnZhq+vrzFlyhTb8eTkZMNqtRpLliwpghEUP4U957nZsWOHIck4evRo4QR9GyiqeT9x4oRxxx13GL/88osRGBhIkoUSjXzJMciZih75kvnIlxyDfMlcfH0P+RYbG6ty5cqpRYsWtrbQ0FA5OTlp+/btuZ6za9cuXb58WaGhoba2evXqqWrVqoqNjbW17d+/XxMnTtTChQvl5MSv5VVFOef/lJKSogoVKhRe8MVEZmamdu3aZTdfTk5OCg0NzXO+YmNj7fpLUlhYmK1/fHy8EhMT7fp4eXkpODj4mj+DkqIo5jw3KSkpslgsKleuXKHEXdwV1bxnZ2fr8ccf13PPPaeGDRsWTfBAMUK+5BjkTEWLfMl85EuOQb5kPv41Q74lJiaqcuXKdm2lSpVShQoVlJiYmOc5rq6uOf4n5+PjYzsnIyNDffr00ZQpU1S1atUiib24Kqo5/6dt27Zp2bJlGjJkSKHEXZycPXtWWVlZ8vHxsWu/1nwlJiZes//V/97INUuSopjzf7p06ZJeeOEF9enTR56enoUTeDFXVPP+5ptvqlSpUho5cmThBw0UQ+RLjkHOVLTIl8xHvuQY5EvmoygFvfjii7JYLNfcDhw4UGT3j4qKUv369fXYY48V2T1uNY6e87/75Zdf1LVrV40bN07333+/KfcEitLly5f1yCOPyDAMzZ4929Hh3NZ27dqlGTNmKDo6WhaLxdHhAEXK0f92l8R8SXL8vP8dORNuJ+RL5iFfurZSjg4Ajjd69Gj179//mn1q1KghX19fnT592q79r7/+0vnz5+Xr65vreb6+vsrMzFRycrLdp1BJSUm2czZt2qS9e/dqxYoVkq68hUOSKlWqpJdfflkTJkwo4MhuXY6e86v279+vDh06aMiQIRozZkyBxlLcVapUSc7OzjnecJTbfF3l6+t7zf5X/5uUlCQ/Pz+7Pk2bNi3E6Iunopjzq64mWEePHtWmTZv41O9vimLev/vuO50+fdruqY2srCyNHj1a06dP15EjRwp3EIADOfrf7pKYL0mOn/erSnrORL5kPvIlxyBfcgDHLmmF4uTqApI7d+60ta1bty5fC0iuWLHC1nbgwAG7BSQPHTpk7N2717bNnz/fkGRs27YtzzcclBRFNeeGYRi//PKLUblyZeO5554rugEUE61atTKGDx9u28/KyjLuuOOOay5m+MADD9i1hYSE5Fi4c+rUqbbjKSkpLNz5N4U954ZhGJmZmUa3bt2Mhg0bGqdPny6awIu5wp73s2fP2v3/e+/evYa/v7/xwgsvGAcOHCi6gQC3MPIlxyBnKnrkS+YjX3IM8iVzUZTCDenYsaPRrFkzY/v27cb3339v1K5d2+5VuydOnDDq1q1rbN++3dY2dOhQo2rVqsamTZuMnTt3GiEhIUZISEie9/jmm294m8zfFMWc79271/D29jYee+wxIyEhwbaV1H+Yli5dalitViM6OtrYv3+/MWTIEKNcuXJGYmKiYRiG8fjjjxsvvviirf/WrVuNUqVKGVOnTjV+/fVXY9y4cbm+4rhcuXLG559/buzZs8fo2rUrrzj+m8Ke88zMTOPBBx80qlSpYsTFxdn9XmdkZDhkjLeiovhd/yfeJgOQLzkKOVPRIl8yH/mSY5AvmYuiFG7IuXPnjD59+hhlypQxPD09jQEDBhgXLlywHY+PjzckGd98842t7eLFi8ZTTz1llC9f3vDw8DC6d+9uJCQk5HkPkix7RTHn48aNMyTl2AIDA00c2a1l5syZRtWqVQ1XV1ejVatWxg8//GA71rZtWyMiIsKu/6effmrUqVPHcHV1NRo2bGisWbPG7nh2drbxyiuvGD4+PobVajU6dOhgHDx40IyhFBuFOedX/x7ktv397wYK/3f9n0iyAPIlRyFnKnrkS+YjX3IM8iXzWAzj/38hHQAAAAAAADAJb98DAAAAAACA6ShKAQAAAAAAwHQUpQAAAAAAAGA6ilIAAAAAAAAwHUUpAAAAAAAAmI6iFAAAAAAAAExHUQoAAAAAAACmoygFAAAAAAAA01GUAgATWSwWrV692tFhAAAA3LLIl4CSg6IUgBKjf//+slgsObaOHTs6OjQAAIBbAvkSADOVcnQAAGCmjh07asGCBXZtVqvVQdEAAADcesiXAJiFJ6UAlChWq1W+vr52W/ny5SVdeVR89uzZCg8Pl7u7u2rUqKEVK1bYnb93717961//kru7uypWrKghQ4YoLS3Nrs/8+fPVsGFDWa1W+fn5afjw4XbHz549q+7du8vDw0O1a9fWF198UbSDBgAAuAHkSwDMQlEKAP7mlVdeUc+ePbV792717dtXvXv31q+//ipJSk9PV1hYmMqXL68ff/xRy5cv18aNG+2SqNmzZ2vYsGEaMmSI9u7dqy+++EK1atWyu8eECRP0yCOPaM+ePerUqZP69u2r8+fPmzpOAACAgiJfAlBoDAAoISIiIgxnZ2ejdOnSdtt//vMfwzAMQ5IxdOhQu3OCg4ONJ5980jAMw3j//feN8uXLG2lpabbja9asMZycnIzExETDMAzD39/fePnll/OMQZIxZswY235aWpohyfj6668LbZwAAAAFRb4EwEysKQWgRGnfvr1mz55t11ahQgXbn0NCQuyOhYSEKC4uTpL066+/KigoSKVLl7Ydv/vuu5Wdna2DBw/KYrHo1KlT6tChwzVjaNKkie3PpUuXlqenp06fPl3QIQEAABQq8iUAZqEoBaBEKV26dI7HwwuLu7t7vvq5uLjY7VssFmVnZxdFSAAAADeMfAmAWVhTCgD+5ocffsixX79+fUlS/fr1tXv3bqWnp9uOb926VU5OTqpbt67Kli2ratWqKSYmxtSYAQAAzES+BKCw8KQUgBIlIyNDiYmJdm2lSpVSpUqVJEnLly9XixYtdM899+iTTz7Rjh07NG/ePElS3759NW7cOEVERGj8+PE6c+aMRowYoccff1w+Pj6SpPHjx2vo0KGqXLmywsPDdeHCBW3dulUjRowwd6AAAAAFRL4EwCwUpQCUKGvXrpWfn59dW926dXXgwAFJV970snTpUj311FPy8/PTkiVL1KBBA0mSh4eH1q1bp6efflotW7aUh4eHevbsqbfeest2rYiICF26dElvv/22nn32WVWqVEkPPfSQeQMEAAC4SeRLAMxiMQzDcHQQAHArsFgsWrVqlbp16+boUAAAAG5J5EsAChNrSgEAAAAAAMB0FKUAAAAAAABgOr6+BwAAAAAAANPxpBQAAAAAAABMR1EKAAAAAAAApqMoBQAAAAAAANNRlAIAAAAAAIDpKEoBAAAAAADAdBSlAAAAAAAAYDqKUgAAAAAAADAdRSkAAAAAAACYjqIUAAAAAAAATPf/AJCZXS4AzWAzAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import spacy\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "import os  # Import os module\n",
        "import shutil # Import shutil for removing directory\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from captum.attr import LayerIntegratedGradients\n",
        "\n",
        "# Initialize device\n",
        "device = torch.device('cuda')\n",
        "\n",
        "# Initialize models\n",
        "nlp = spacy.load('en_core_web_sm', disable=['ner', 'parser', 'lemmatizer'])\n",
        "\n",
        "# Move nlp to GPU (optional but recommended)\n",
        "# nlp.to(device)\n",
        "\n",
        "# Use a BERT model fine-tuned on Amazon reviews\n",
        "model_name = 'nlptown/bert-base-multilingual-uncased-sentiment'\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "bert_model = BertModel.from_pretrained(model_name).to(device)\n",
        "\n",
        "class RegularizedBERT(nn.Module):\n",
        "    def __init__(self, num_labels, feature_dim, hyperparams):\n",
        "        super().__init__()\n",
        "        self.bert = bert_model\n",
        "        self.dropout = nn.Dropout(hyperparams[\"Dropout\"])\n",
        "        self.feature_dim = feature_dim\n",
        "        self.bert_projection = nn.Linear(768, 384)\n",
        "        self.feature_projection = nn.Linear(feature_dim, 384) if feature_dim > 0 else None\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(384, 384),\n",
        "            nn.LayerNorm(384),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(hyperparams[\"Dropout\"]),\n",
        "            nn.Linear(384, num_labels)\n",
        "        )\n",
        "        self.all_preds = []\n",
        "        self.all_labels = []\n",
        "        self.all_texts = []\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, features=None):\n",
        "        bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = bert_output.last_hidden_state[:, 0, :]\n",
        "        bert_projected = self.bert_projection(pooled_output)\n",
        "\n",
        "        if features is not None and self.feature_dim > 0:\n",
        "            feature_projected = self.feature_projection(features)\n",
        "            combined_features = bert_projected + feature_projected\n",
        "        else:\n",
        "            combined_features = bert_projected\n",
        "\n",
        "        output = self.classifier(combined_features)\n",
        "        return output\n",
        "\n",
        "class GPUOptimizedTrainer:\n",
        "    def __init__(self, df, text_column, labels, hyperparams, embedding_dir=\"embeddings\"):\n",
        "        # Validate hyperparameters\n",
        "        required_params = [\"Epochs\", \"Batch Size\", \"Learning Rate\", \"Dropout\", \"Weight Decay\",\n",
        "                         \"Label Smoothing\", \"Early Stopping Patience\", \"Gradient Accumulation Steps\"]\n",
        "        for param in required_params:\n",
        "            if param not in hyperparams:\n",
        "                raise ValueError(f\"Missing required hyperparameter: {param}\")\n",
        "\n",
        "        if hyperparams[\"Batch Size\"] <= 0:\n",
        "            raise ValueError(\"Batch Size must be positive\")\n",
        "        if not 0 <= hyperparams[\"Dropout\"] <= 1:\n",
        "            raise ValueError(\"Dropout must be between 0 and 1\")\n",
        "\n",
        "        self.device = device\n",
        "        self.hyperparams = hyperparams\n",
        "        self.batch_size = hyperparams[\"Batch Size\"]\n",
        "        self.embedding_dir = embedding_dir\n",
        "        self.text_column = text_column\n",
        "\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "        torch.backends.cuda.matmul.allow_tf32 = True\n",
        "        torch.backends.cudnn.allow_tf32 = True\n",
        "\n",
        "        # Initialize feature_dim first\n",
        "        sample_features = self.extract_features(df[text_column].head(1).tolist())\n",
        "        self.feature_dim = sample_features.shape[1]\n",
        "\n",
        "        # Create model with correct feature_dim\n",
        "        self.model = RegularizedBERT(\n",
        "            num_labels=5,\n",
        "            feature_dim=self.feature_dim,\n",
        "            hyperparams=hyperparams\n",
        "        ).to(self.device)\n",
        "\n",
        "        self.scaler = GradScaler()\n",
        "        self.prepare_data(df, labels)\n",
        "        self.setup_training()\n",
        "\n",
        "    def extract_features(self, texts):\n",
        "        print(\"Extracting features...\")\n",
        "        os.makedirs(self.embedding_dir, exist_ok=True) # Ensure embedding directory exists\n",
        "\n",
        "        bert_embedding_file = os.path.join(self.embedding_dir, \"bert_embeddings.npy\")\n",
        "        syntactic_feature_file = os.path.join(self.embedding_dir, \"syntactic_features.npy\")\n",
        "\n",
        "        if os.path.exists(bert_embedding_file) and os.path.exists(syntactic_feature_file):\n",
        "            print(\"Loading embeddings from disk...\")\n",
        "            contextual_features = np.load(bert_embedding_file)\n",
        "            syntactic_features = np.load(syntactic_feature_file)\n",
        "            print(\"Embeddings loaded.\")\n",
        "            return np.hstack([contextual_features, syntactic_features])\n",
        "        else:\n",
        "            print(\"Calculating and saving embeddings...\")\n",
        "\n",
        "            def extract_contextual(texts, batch_size=128):\n",
        "                features = []\n",
        "                for i in range(0, len(texts), batch_size):\n",
        "                    batch = texts[i:i + batch_size]\n",
        "                    # Ensure each text is a string before tokenizing\n",
        "                    batch = [str(text) for text in batch] # <--- ENSURE STRING\n",
        "                    inputs = tokenizer(batch, padding=True, truncation=True, return_tensors=\"pt\").to(self.device)\n",
        "                    with torch.no_grad():\n",
        "                        outputs = bert_model(**inputs)\n",
        "                        embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
        "                    features.extend(embeddings)\n",
        "                return np.array(features)\n",
        "\n",
        "            def extract_syntactic(texts):\n",
        "                features = []\n",
        "                for text in texts:\n",
        "                    # Ensure each text is a string before passing to nlp\n",
        "                    text = str(text) # <--- ENSURE STRING\n",
        "                    doc = nlp(text)\n",
        "                    pos_tags = [token.pos_ for token in doc]\n",
        "                    features.append([\n",
        "                        len(doc),\n",
        "                        len(set(pos_tags)) / len(pos_tags),\n",
        "                        pos_tags.count('NOUN') / len(pos_tags),\n",
        "                        pos_tags.count('VERB') / len(pos_tags),\n",
        "                    ])\n",
        "                return np.array(features)\n",
        "\n",
        "            contextual_features = extract_contextual(texts)\n",
        "            syntactic_features = extract_syntactic(texts)\n",
        "\n",
        "            np.save(bert_embedding_file, contextual_features) # Save BERT embeddings\n",
        "            np.save(syntactic_feature_file, syntactic_features) # Save syntactic features\n",
        "            print(\"Embeddings calculated and saved.\")\n",
        "            return np.hstack([contextual_features, syntactic_features])\n",
        "\n",
        "    def prepare_data(self, df, labels, val_split=0.2): # Takes dataFrame\n",
        "        print(\"Preparing data...\")\n",
        "\n",
        "        # Extract the data\n",
        "        texts = df[self.text_column].tolist()\n",
        "\n",
        "        # Wrap the text and label processing in a tqdm progress bar\n",
        "        encodings = tokenizer(texts, truncation=True, padding=True, return_tensors='pt')\n",
        "        input_ids = encodings['input_ids']\n",
        "        attention_mask = encodings['attention_mask']\n",
        "        features = self.extract_features(texts) # Features are extracted here\n",
        "        if self.feature_dim is None: # Update feature_dim only once, after extracting features\n",
        "            self.feature_dim = features.shape[1]\n",
        "            self.model.classifier[0] = nn.Linear(768 + self.feature_dim, 384) # Update the first linear layer with correct feature_dim\n",
        "            self.model = self.model.to(self.device) # Move model to device again after changing the layer\n",
        "        scaler = StandardScaler()\n",
        "        features = scaler.fit_transform(features)\n",
        "\n",
        "        split_idx = int(len(input_ids) * (1 - val_split))\n",
        "        indices = np.random.permutation(len(input_ids))\n",
        "\n",
        "        train_idx = indices[:split_idx]\n",
        "        val_idx = indices[split_idx:]\n",
        "\n",
        "        self.train_input_ids = input_ids[train_idx]\n",
        "        self.train_attention_mask = attention_mask[train_idx]\n",
        "        self.train_features = torch.tensor(features[train_idx], dtype=torch.float32)\n",
        "        self.train_labels = torch.tensor(labels[train_idx], dtype=torch.long)\n",
        "        self.train_texts = [texts[i] for i in train_idx] # Store training texts\n",
        "\n",
        "        self.val_input_ids = input_ids[val_idx]\n",
        "        self.val_attention_mask = attention_mask[val_idx]\n",
        "        self.val_features = torch.tensor(features[val_idx], dtype=torch.float32)\n",
        "        self.val_labels = torch.tensor(labels[val_idx], dtype=torch.long)\n",
        "        self.val_texts = [texts[i] for i in val_idx] # Store validation texts\n",
        "\n",
        "\n",
        "        self.create_dataloaders()\n",
        "\n",
        "    def create_dataloaders(self):\n",
        "        train_dataset = TensorDataset(self.train_input_ids, self.train_attention_mask, self.train_features, self.train_labels)\n",
        "        val_dataset = TensorDataset(self.val_input_ids, self.val_attention_mask, self.val_features, self.val_labels)\n",
        "\n",
        "        self.train_loader = DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=True,\n",
        "            pin_memory=True,\n",
        "            num_workers=4,\n",
        "            prefetch_factor=3,\n",
        "            persistent_workers=True\n",
        "        )\n",
        "\n",
        "        self.val_loader = DataLoader(\n",
        "            val_dataset,\n",
        "            batch_size=self.batch_size * 2,  # Validation batch size can be larger\n",
        "            pin_memory=True,\n",
        "            num_workers=4,\n",
        "            persistent_workers=True\n",
        "        )\n",
        "\n",
        "    def setup_training(self):\n",
        "        self.optimizer = torch.optim.AdamW(\n",
        "            self.model.parameters(),\n",
        "            lr=self.hyperparams[\"Learning Rate\"],\n",
        "            weight_decay=self.hyperparams[\"Weight Decay\"],\n",
        "            betas=(0.9, 0.999)\n",
        "        )\n",
        "\n",
        "        # Total steps for OneCycleLR\n",
        "        total_steps = (len(self.train_loader) // self.hyperparams[\"Gradient Accumulation Steps\"]) * self.hyperparams[\"Epochs\"]\n",
        "\n",
        "        self.scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "            self.optimizer,\n",
        "            max_lr=self.hyperparams[\"Learning Rate\"] * 10,  # Usually a good practice to have a higher max_lr\n",
        "            steps_per_epoch=len(self.train_loader) // self.hyperparams[\"Gradient Accumulation Steps\"],\n",
        "            epochs=self.hyperparams[\"Epochs\"],\n",
        "            pct_start=0.1\n",
        "        )\n",
        "\n",
        "        self.early_stopping = EarlyStopping(patience=self.hyperparams[\"Early Stopping Patience\"])\n",
        "\n",
        "    def train(self):\n",
        "        epochs = self.hyperparams[\"Epochs\"]\n",
        "        accumulation_steps = self.hyperparams[\"Gradient Accumulation Steps\"]\n",
        "\n",
        "        # Clear previous predictions\n",
        "        self.model.all_preds = []\n",
        "        self.model.all_labels = []\n",
        "        self.model.all_texts = []\n",
        "\n",
        "        best_val_loss = float('inf')\n",
        "        train_losses, val_losses = [], []\n",
        "        train_accs, val_accs = [], []\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            train_metrics = self.train_epoch(accumulation_steps)\n",
        "            val_metrics = self.validate()\n",
        "\n",
        "            train_losses.append(train_metrics['loss'])\n",
        "            val_losses.append(val_metrics['loss'])\n",
        "            train_accs.append(train_metrics['acc'])\n",
        "            val_accs.append(val_metrics['acc'])\n",
        "\n",
        "            print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "            print(f\"Train Loss: {train_metrics['loss']:.4f}, Acc: {train_metrics['acc']:.4f}\")\n",
        "            print(f\"Val Loss: {val_metrics['loss']:.4f}, Acc: {val_metrics['acc']:.4f}\")\n",
        "\n",
        "            if val_metrics['loss'] < best_val_loss:\n",
        "                best_val_loss = val_metrics['loss']\n",
        "                torch.save(self.model.state_dict(), 'best_model.pt')\n",
        "\n",
        "            if self.early_stopping(val_metrics['loss']):\n",
        "                print(\"Early stopping triggered\")\n",
        "                break\n",
        "\n",
        "        self.perform_error_analysis() #Moved to the very end of train\n",
        "        return {\n",
        "            'train_loss': train_losses,\n",
        "            'val_loss': val_losses,\n",
        "            'train_acc': train_accs,\n",
        "            'val_acc': val_accs\n",
        "        }\n",
        "\n",
        "    def train_epoch(self, accumulation_steps):\n",
        "        torch.cuda.empty_cache()\n",
        "        self.model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for batch_idx, (input_ids, attention_mask, features, target) in enumerate(tqdm(self.train_loader, desc=\"Training\", leave=False, dynamic_ncols=True, position=0)): # Explicit position=0\n",
        "            torch.cuda.empty_cache() # Empty cache after every batch\n",
        "            input_ids = input_ids.to(self.device, non_blocking=True)\n",
        "            attention_mask = attention_mask.to(self.device, non_blocking=True)\n",
        "            features = features.to(self.device, non_blocking=True)\n",
        "            target = target.to(self.device, non_blocking=True)\n",
        "\n",
        "            with autocast():\n",
        "                output = self.model(input_ids=input_ids, attention_mask=attention_mask, features=features)\n",
        "                loss = F.cross_entropy(output, target, label_smoothing=self.hyperparams[\"Label Smoothing\"])\n",
        "                loss = loss / accumulation_steps  # Normalize loss for accumulation\n",
        "\n",
        "            self.scaler.scale(loss).backward()\n",
        "\n",
        "            if (batch_idx + 1) % accumulation_steps == 0 or (batch_idx + 1) == len(self.train_loader):\n",
        "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
        "                self.scaler.step(self.optimizer)\n",
        "                self.scaler.update()\n",
        "                self.optimizer.zero_grad(set_to_none=True)\n",
        "                self.scheduler.step()\n",
        "\n",
        "            total_loss += loss.item() * accumulation_steps  # Scale back for correct averaging\n",
        "            pred = output.argmax(dim=1)\n",
        "            correct += pred.eq(target).sum().item()\n",
        "            total += target.size(0)\n",
        "\n",
        "        return {'loss': total_loss / len(self.train_loader), 'acc': correct / total}\n",
        "\n",
        "    def validate(self):\n",
        "        torch.cuda.empty_cache()\n",
        "        self.model.eval()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (input_ids, attention_mask, features, target) in enumerate(tqdm(self.val_loader, desc=\"Validating\", leave=False, dynamic_ncols=True, position=0)): # Explicit position=0\n",
        "                torch.cuda.empty_cache() # Empty cache after every batch\n",
        "                input_ids = input_ids.to(self.device, non_blocking=True)\n",
        "                attention_mask = attention_mask.to(self.device, non_blocking=True)\n",
        "                features = features.to(self.device, non_blocking=True)\n",
        "                target = target.to(self.device, non_blocking=True)\n",
        "\n",
        "                with autocast():\n",
        "                    output = self.model(input_ids=input_ids, attention_mask=attention_mask, features=features)\n",
        "                    loss = F.cross_entropy(output, target)\n",
        "\n",
        "                total_loss += loss.item()\n",
        "                pred = output.argmax(dim=1)\n",
        "                correct += pred.eq(target).sum().item()\n",
        "                total += target.size(0)\n",
        "\n",
        "                # Get the text for the current batch\n",
        "                start_index = batch_idx * self.batch_size * 2 #validation batch_size 2x the training\n",
        "                end_index = start_index + target.size(0)\n",
        "                batch_texts = self.val_texts[start_index:end_index]\n",
        "\n",
        "\n",
        "                # Store predictions and labels for error analysis\n",
        "                self.model.all_preds.extend(pred.cpu().numpy())\n",
        "                self.model.all_labels.extend(target.cpu().numpy())\n",
        "                self.model.all_texts.extend(batch_texts) # Store the corresponding texts\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        return {'loss': total_loss / len(self.val_loader), 'acc': correct / total}\n",
        "    def perform_error_analysis(self):\n",
        "        # Generate classification report\n",
        "        report = classification_report(self.model.all_labels, self.model.all_preds, digits=4) #4 for a more detailed overview\n",
        "        print(\"Classification Report:\\n\", report)\n",
        "\n",
        "        # Generate confusion matrix\n",
        "        cm = confusion_matrix(self.model.all_labels, self.model.all_preds)\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "        plt.xlabel('Predicted Labels')\n",
        "        plt.ylabel('True Labels')\n",
        "        plt.title('Confusion Matrix')\n",
        "        plt.show()\n",
        "\n",
        "        # Find misclassified texts\n",
        "        misclassified_indices = np.where(np.array(self.model.all_preds) != np.array(self.model.all_labels))[0]\n",
        "\n",
        "        print(\"\\nMisclassified Text Examples:\")\n",
        "        for idx in misclassified_indices[:5]:  # Display up to 5 examples\n",
        "            print(f\"True Label: {self.model.all_labels[idx]}, Predicted Label: {self.model.all_preds[idx]}\")\n",
        "            print(f\"Text: {self.model.all_texts[idx]}\\n\")\n",
        "\n",
        "        # Explain the predictions using Captum\n",
        "        #print(\"\\nAttribution Analysis for Misclassified Examples:\")\n",
        "        #for idx in misclassified_indices[:5]:  # Display up to 5 examples\n",
        "        #    self.explain_instance(self.model.all_texts[idx], self.model.all_labels[idx], self.model) # Changed all_preds[idx] to all_labels[idx]\n",
        "\n",
        "    def explain_instance(self, text, true_label, model):\n",
        "       #Explain instance no longer prints so is left empty\n",
        "       pass\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=3, min_delta=0):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.best_loss = None\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, val_loss):\n",
        "        if self.best_loss is None:\n",
        "            self.best_loss = val_loss\n",
        "        elif val_loss > self.best_loss - self.min_delta:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                return True\n",
        "        else:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n",
        "        return False\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Load your DataFrame\n",
        "    df = pd.read_csv(\"/content/modified_df_11.csv\")\n",
        "\n",
        "    # Ensure 'text' column is string\n",
        "    df['text'] = df['text'].astype(str)\n",
        "\n",
        "    #Set name of text column\n",
        "    text_column = 'text'\n",
        "\n",
        "    # Extract labels\n",
        "    labels = np.array(df[\"rating\"].tolist()) - 1  # Adjust as needed\n",
        "\n",
        "    # Define hyperparameters\n",
        "    hyperparams = {\n",
        "        \"Epochs\": 1, #Reduced for faster example\n",
        "        \"Batch Size\": 70,\n",
        "        \"Learning Rate\": 1e-5,\n",
        "        \"Dropout\": 0.3,\n",
        "        \"Weight Decay\": 0.1,\n",
        "        \"Label Smoothing\": 0.1,\n",
        "        \"Early Stopping Patience\": 3,\n",
        "        \"Gradient Accumulation Steps\": 4,\n",
        "        \"Optimizer\": \"AdamW\",\n",
        "        \"Scheduler\": \"OneCycleLR\",\n",
        "        \"Feature Dimension\": 0,\n",
        "        \"Model\": \"BERT with Multiple Embeddings\"\n",
        "    }\n",
        "\n",
        "    embedding_dir = \"my_embeddings\"\n",
        "\n",
        "    # Clear embedding directory\n",
        "    #if os.path.exists(embedding_dir):\n",
        "    #    shutil.rmtree(embedding_dir)\n",
        "\n",
        "    # Instantiate Trainer  Pass the DataFrame, text column name, and TextProcessor\n",
        "    trainer = GPUOptimizedTrainer(df, text_column, labels, hyperparams, embedding_dir=embedding_dir)\n",
        "    metrics = trainer.train()\n",
        "\n",
        "    # Print Dataframe\n",
        "    print(df)\n",
        "\n",
        "    # Plot results\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(metrics['train_loss'], label='Train Loss')\n",
        "    plt.plot(metrics['val_loss'], label='Val Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(metrics['train_acc'], label='Train Acc')\n",
        "    plt.plot(metrics['val_acc'], label='Val Acc')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kTjKGYEuuIUi",
        "outputId": "78846058-0c80-4bc4-992a-55712ff7601a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "  warnings.warn(Warnings.W111)\n",
            "<ipython-input-4-f2f9a089f8d9>:94: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = GradScaler()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preparing data...\n",
            "Extracting features...\n",
            "Loading embeddings from disk...\n",
            "Embeddings loaded.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:   0%|          | 0/2435 [00:00<?, ?it/s]<ipython-input-4-f2f9a089f8d9>:311: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Validating:   0%|          | 0/305 [00:00<?, ?it/s]<ipython-input-4-f2f9a089f8d9>:347: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "Train Loss: 1.2426, Acc: 0.5098\n",
            "Val Loss: 1.0286, Acc: 0.5678\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6000    1.0000    0.7500         3\n",
            "           1     1.0000    0.3333    0.5000         6\n",
            "           2     0.4000    0.6667    0.5000         3\n",
            "           3     0.0000    0.0000    0.0000         3\n",
            "           4     0.0000    0.0000    0.0000         0\n",
            "\n",
            "    accuracy                         0.4667        15\n",
            "   macro avg     0.4000    0.4000    0.3500        15\n",
            "weighted avg     0.6000    0.4667    0.4500        15\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Misclassified Text Examples:\n",
            "True Label: 1, Predicted Label: 3\n",
            "Text: North is better than South\n",
            "\n",
            "True Label: 1, Predicted Label: 0\n",
            "Text: had modern urns that did not see on any other sites . originally ordered a white Lucy and it was too white for my liking so reordered in red because discovered my love of in the meantime . They made the return easy . Thanks for being great in this difficult time .\n",
            "\n",
            "True Label: 3, Predicted Label: 2\n",
            "Text: Shipping was quick . have previously purchased this item on Groupon for much less . Product is excellent however cost will me from making future purchases .\n",
            "\n",
            "True Label: 1, Predicted Label: 0\n",
            "Text: was knowledgeable polite and helpful . Dave was excellent to work with and help hunt down the package when it got held up .\n",
            "\n",
            "True Label: 1, Predicted Label: 2\n",
            "Text: Absolutely horrible customer service . contacted them several times received very similar responses with promises that the issue would be resolved and it never is They offer a free time for life . was able to add that several times until it just disappeared as an option . contacted them a total of times to get the stupid item added back on and they never did . The last representative that chatted with was very rude and disconnected . After contact them times and they still cannot resolve it who wants to spend so much time on a basis just for a stupid free add on .\n",
            "\n",
            "\n",
            "Attribution Analysis for Misclassified Examples:\n",
            "\n",
            "Text: North is better than South\n",
            "True Label: 1\n",
            "\n",
            "Token Attribution Scores:\n",
            "[CLS]: 0.2015\n",
            "north: -0.6343\n",
            "is: 0.3450\n",
            "better: -0.5422\n",
            "than: -0.2051\n",
            "south: -0.1998\n",
            "[SEP]: -0.2491\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Text: had modern urns that did not see on any other sites . originally ordered a white Lucy and it was too white for my liking so reordered in red because discovered my love of in the meantime . They made the return easy . Thanks for being great in this difficult time .\n",
            "True Label: 1\n",
            "\n",
            "Token Attribution Scores:\n",
            "[CLS]: 0.0462\n",
            "had: -0.0009\n",
            "modern: -0.0798\n",
            "ur: -0.0360\n",
            "##ns: -0.0324\n",
            "that: -0.0040\n",
            "did: -0.1068\n",
            "not: 0.0436\n",
            "see: -0.0224\n",
            "on: -0.0416\n",
            "any: -0.0310\n",
            "other: 0.0462\n",
            "sites: 0.0086\n",
            ".: -0.1044\n",
            "originally: -0.0619\n",
            "ordered: -0.0108\n",
            "a: -0.0512\n",
            "white: -0.0126\n",
            "lucy: -0.0371\n",
            "and: 0.0147\n",
            "it: 0.0134\n",
            "was: -0.0038\n",
            "too: -0.0207\n",
            "white: -0.0608\n",
            "for: 0.0160\n",
            "my: 0.0166\n",
            "lik: -0.0193\n",
            "##ing: -0.0013\n",
            "so: -0.1659\n",
            "re: -0.0256\n",
            "##orde: 0.0151\n",
            "##red: 0.0020\n",
            "in: -0.0722\n",
            "red: -0.0437\n",
            "because: 0.0673\n",
            "discovered: 0.0185\n",
            "my: 0.0423\n",
            "love: 0.0095\n",
            "of: 0.0318\n",
            "in: -0.0330\n",
            "the: -0.0072\n",
            "meant: 0.0012\n",
            "##ime: -0.0467\n",
            ".: -0.2858\n",
            "they: -0.0665\n",
            "made: -0.0016\n",
            "the: -0.0971\n",
            "return: 0.0464\n",
            "easy: -0.1806\n",
            ".: -0.3125\n",
            "thanks: 0.0170\n",
            "for: 0.1560\n",
            "being: 0.1383\n",
            "great: -0.1324\n",
            "in: -0.0607\n",
            "this: -0.1283\n",
            "difficult: 0.0480\n",
            "time: -0.0828\n",
            ".: -0.1123\n",
            "[SEP]: 0.7538\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Text: Shipping was quick . have previously purchased this item on Groupon for much less . Product is excellent however cost will me from making future purchases .\n",
            "True Label: 3\n",
            "\n",
            "Token Attribution Scores:\n",
            "[CLS]: 0.5719\n",
            "shipping: -0.0699\n",
            "was: 0.0061\n",
            "quick: 0.1749\n",
            ".: 0.2111\n",
            "have: 0.0214\n",
            "previously: 0.1720\n",
            "purchased: -0.0301\n",
            "this: 0.0258\n",
            "item: 0.0178\n",
            "on: -0.0517\n",
            "group: -0.0770\n",
            "##on: 0.0853\n",
            "for: 0.2391\n",
            "much: -0.0028\n",
            "less: 0.0239\n",
            ".: 0.1785\n",
            "product: -0.0995\n",
            "is: 0.1084\n",
            "excellent: 0.3017\n",
            "however: -0.2392\n",
            "cost: 0.1415\n",
            "will: 0.2371\n",
            "me: 0.1444\n",
            "from: 0.0204\n",
            "making: 0.0379\n",
            "future: 0.0434\n",
            "purchase: -0.0119\n",
            "##s: 0.0467\n",
            ".: 0.0248\n",
            "[SEP]: -0.4264\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Text: was knowledgeable polite and helpful . Dave was excellent to work with and help hunt down the package when it got held up .\n",
            "True Label: 1\n",
            "\n",
            "Token Attribution Scores:\n",
            "[CLS]: -0.0206\n",
            "was: -0.0986\n",
            "knowledge: -0.1233\n",
            "##able: -0.2732\n",
            "poli: -0.1930\n",
            "##te: -0.1781\n",
            "and: -0.1454\n",
            "help: -0.1060\n",
            "##ful: -0.5520\n",
            ".: -0.0938\n",
            "dave: 0.0760\n",
            "was: 0.0623\n",
            "excellent: -0.4480\n",
            "to: 0.0662\n",
            "work: 0.0204\n",
            "with: 0.0473\n",
            "and: -0.1384\n",
            "help: -0.1023\n",
            "hunt: -0.2973\n",
            "down: -0.1848\n",
            "the: -0.0493\n",
            "package: 0.1632\n",
            "when: -0.0853\n",
            "it: -0.0141\n",
            "got: -0.1921\n",
            "held: -0.0971\n",
            "up: -0.1007\n",
            ".: -0.1130\n",
            "[SEP]: -0.0989\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Text: Absolutely horrible customer service . contacted them several times received very similar responses with promises that the issue would be resolved and it never is They offer a free time for life . was able to add that several times until it just disappeared as an option . contacted them a total of times to get the stupid item added back on and they never did . The last representative that chatted with was very rude and disconnected . After contact them times and they still cannot resolve it who wants to spend so much time on a basis just for a stupid free add on .\n",
            "True Label: 1\n",
            "\n",
            "Token Attribution Scores:\n",
            "[CLS]: 0.1918\n",
            "absolute: -0.0721\n",
            "##ly: -0.0147\n",
            "hor: -0.0736\n",
            "##rib: -0.0381\n",
            "##le: -0.0392\n",
            "customer: -0.0129\n",
            "service: 0.0148\n",
            ".: -0.0596\n",
            "contacte: -0.0163\n",
            "##d: 0.0064\n",
            "them: 0.0274\n",
            "several: 0.0097\n",
            "times: 0.0089\n",
            "received: 0.0031\n",
            "very: 0.0058\n",
            "similar: 0.0078\n",
            "responses: 0.0028\n",
            "with: 0.0044\n",
            "promises: -0.0205\n",
            "that: 0.0056\n",
            "the: 0.0061\n",
            "issue: 0.0074\n",
            "would: -0.0062\n",
            "be: -0.0024\n",
            "resolved: -0.0032\n",
            "and: -0.0056\n",
            "it: -0.0044\n",
            "never: 0.0020\n",
            "is: -0.0220\n",
            "they: 0.0076\n",
            "offer: -0.0089\n",
            "a: -0.0017\n",
            "free: -0.0052\n",
            "time: -0.0041\n",
            "for: -0.0057\n",
            "life: -0.0021\n",
            ".: -0.0183\n",
            "was: 0.0028\n",
            "able: 0.0019\n",
            "to: 0.0050\n",
            "add: -0.0167\n",
            "that: 0.0015\n",
            "several: -0.0043\n",
            "times: -0.0031\n",
            "until: -0.0121\n",
            "it: 0.0036\n",
            "just: 0.0118\n",
            "disappeared: -0.0184\n",
            "as: 0.0051\n",
            "an: -0.0097\n",
            "option: 0.0030\n",
            ".: -0.0035\n",
            "contacte: -0.0154\n",
            "##d: -0.0128\n",
            "them: 0.0017\n",
            "a: -0.0009\n",
            "total: -0.0195\n",
            "of: -0.0098\n",
            "times: -0.0088\n",
            "to: -0.0067\n",
            "get: -0.0171\n",
            "the: 0.0081\n",
            "stu: 0.0036\n",
            "##pid: 0.0029\n",
            "item: 0.0019\n",
            "added: -0.0024\n",
            "back: 0.0039\n",
            "on: -0.0160\n",
            "and: -0.0044\n",
            "they: -0.0160\n",
            "never: 0.0058\n",
            "did: -0.0212\n",
            ".: -0.0232\n",
            "the: 0.0049\n",
            "last: -0.0133\n",
            "representative: -0.0227\n",
            "that: 0.0021\n",
            "chat: -0.0124\n",
            "##ted: 0.0018\n",
            "with: -0.0235\n",
            "was: 0.0138\n",
            "very: -0.0009\n",
            "rude: 0.0094\n",
            "and: 0.0004\n",
            "disco: -0.0009\n",
            "##nne: -0.0015\n",
            "##cted: -0.0114\n",
            ".: -0.0111\n",
            "after: 0.0038\n",
            "contact: -0.0037\n",
            "them: -0.0035\n",
            "times: -0.0008\n",
            "and: -0.0032\n",
            "they: -0.0072\n",
            "still: -0.0029\n",
            "cannot: 0.0056\n",
            "resolve: -0.0031\n",
            "it: 0.0036\n",
            "who: 0.0198\n",
            "wants: -0.0044\n",
            "to: 0.0088\n",
            "spend: -0.0016\n",
            "so: 0.0016\n",
            "much: -0.0059\n",
            "time: -0.0069\n",
            "on: -0.0037\n",
            "a: -0.0099\n",
            "basis: -0.0104\n",
            "just: 0.0113\n",
            "for: 0.0059\n",
            "a: 0.0099\n",
            "stu: 0.0062\n",
            "##pid: 0.0096\n",
            "free: -0.0036\n",
            "add: -0.0148\n",
            "on: 0.0151\n",
            ".: 0.0119\n",
            "[SEP]: 0.9666\n",
            "--------------------------------------------------------------------------------\n",
            "       rating                                               text\n",
            "0           1  it is extremely pricey so specifically asked i...\n",
            "1           1  Wrong part ordered at first by the salesman . ...\n",
            "2           1  My order was canceled without explanation . Re...\n",
            "3           1  The review . com is connected with the review ...\n",
            "4           1  Put a away into a bank account do not touch it...\n",
            "...       ...                                                ...\n",
            "60870       5  our driver was great . He even participated in...\n",
            "60871       5  The Notary was very patient and . There were s...\n",
            "60872       5  traffic initial service but J directed me and ...\n",
            "60873       5  Green City Pros delivered exceptional AC repla...\n",
            "60874       5  The understanding of what was looking for and ...\n",
            "\n",
            "[60875 rows x 2 columns]\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import spacy\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import shutil\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from captum.attr import LayerIntegratedGradients\n",
        "\n",
        "# Initialize device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Initialize models\n",
        "nlp = spacy.load('en_core_web_sm', disable=['ner', 'parser', 'lemmatizer'])\n",
        "\n",
        "# Use a BERT model fine-tuned on Amazon reviews\n",
        "model_name = 'nlptown/bert-base-multilingual-uncased-sentiment'\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "bert_model = BertModel.from_pretrained(model_name).to(device)\n",
        "\n",
        "class RegularizedBERT(nn.Module):\n",
        "    def __init__(self, num_labels, feature_dim, hyperparams):\n",
        "        super().__init__()\n",
        "        self.bert = bert_model\n",
        "        self.dropout = nn.Dropout(hyperparams[\"Dropout\"])\n",
        "        self.feature_dim = feature_dim\n",
        "        self.bert_projection = nn.Linear(768, 384)\n",
        "        self.feature_projection = nn.Linear(feature_dim, 384) if feature_dim > 0 else None\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(384, 384),\n",
        "            nn.LayerNorm(384),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(hyperparams[\"Dropout\"]),\n",
        "            nn.Linear(384, num_labels)\n",
        "        )\n",
        "        self.all_preds = []\n",
        "        self.all_labels = []\n",
        "        self.all_texts = []\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, features=None):\n",
        "        bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = bert_output.last_hidden_state[:, 0, :]\n",
        "        bert_projected = self.bert_projection(pooled_output)\n",
        "\n",
        "        if features is not None and self.feature_dim > 0:\n",
        "            feature_projected = self.feature_projection(features)\n",
        "            combined_features = bert_projected + feature_projected\n",
        "        else:\n",
        "            combined_features = bert_projected\n",
        "\n",
        "        output = self.classifier(combined_features)\n",
        "        return output\n",
        "\n",
        "class GPUOptimizedTrainer:\n",
        "    def __init__(self, df, text_column, labels, hyperparams, embedding_dir=\"embeddings\"):\n",
        "        # Validate hyperparameters\n",
        "        required_params = [\"Epochs\", \"Batch Size\", \"Learning Rate\", \"Dropout\", \"Weight Decay\",\n",
        "                         \"Label Smoothing\", \"Early Stopping Patience\", \"Gradient Accumulation Steps\"]\n",
        "        for param in required_params:\n",
        "            if param not in hyperparams:\n",
        "                raise ValueError(f\"Missing required hyperparameter: {param}\")\n",
        "\n",
        "        if hyperparams[\"Batch Size\"] <= 0:\n",
        "            raise ValueError(\"Batch Size must be positive\")\n",
        "        if not 0 <= hyperparams[\"Dropout\"] <= 1:\n",
        "            raise ValueError(f\"Dropout must be between 0 and 1\")\n",
        "\n",
        "        self.device = device\n",
        "        self.hyperparams = hyperparams\n",
        "        self.batch_size = hyperparams[\"Batch Size\"]\n",
        "        self.embedding_dir = embedding_dir\n",
        "        self.text_column = text_column\n",
        "\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "        torch.backends.cuda.matmul.allow_tf32 = True\n",
        "        torch.backends.cudnn.allow_tf32 = True\n",
        "\n",
        "        self.model = RegularizedBERT(\n",
        "            num_labels=5,\n",
        "            feature_dim=0,\n",
        "            hyperparams=hyperparams\n",
        "        ).to(self.device)\n",
        "\n",
        "        self.scaler = GradScaler()\n",
        "        self.prepare_data(df, labels)\n",
        "        self.setup_training()\n",
        "\n",
        "    def extract_features(self, texts):\n",
        "        print(\"Extracting features...\")\n",
        "        os.makedirs(self.embedding_dir, exist_ok=True)  # Ensure embedding directory exists\n",
        "\n",
        "        bert_embedding_file = os.path.join(self.embedding_dir, \"bert_embeddings.npy\")\n",
        "        syntactic_feature_file = os.path.join(self.embedding_dir, \"syntactic_features.npy\")\n",
        "\n",
        "        if os.path.exists(bert_embedding_file) and os.path.exists(syntactic_feature_file):\n",
        "            print(\"Loading embeddings from disk...\")\n",
        "            contextual_features = np.load(bert_embedding_file)\n",
        "            syntactic_features = np.load(syntactic_feature_file)\n",
        "            print(\"Embeddings loaded.\")\n",
        "            return np.hstack([contextual_features, syntactic_features])\n",
        "        else:\n",
        "            print(\"Calculating and saving embeddings...\")\n",
        "\n",
        "            def extract_contextual(texts, batch_size=128):\n",
        "                features = []\n",
        "                for i in range(0, len(texts), batch_size):\n",
        "                    batch = [str(text).strip() for text in texts[i:i + batch_size] if pd.notna(text) and str(text).strip()]\n",
        "                    inputs = tokenizer(batch, padding=True, truncation=True, return_tensors=\"pt\").to(self.device)\n",
        "                    with torch.no_grad():\n",
        "                        outputs = bert_model(**inputs)\n",
        "                        embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
        "                    features.extend(embeddings)\n",
        "                return np.array(features)\n",
        "\n",
        "            def extract_syntactic(texts):\n",
        "                features = []\n",
        "                for text in texts:\n",
        "                    text = str(text).strip()\n",
        "                    if not text:\n",
        "                        features.append([0, 0, 0, 0])  # Handle empty strings\n",
        "                        continue\n",
        "                    doc = nlp(text)\n",
        "                    pos_tags = [token.pos_ for token in doc]\n",
        "                    features.append([\n",
        "                        len(doc),\n",
        "                        len(set(pos_tags)) / max(len(pos_tags), 1),\n",
        "                        pos_tags.count('NOUN') / max(len(pos_tags), 1),\n",
        "                        pos_tags.count('VERB') / max(len(pos_tags), 1),\n",
        "                    ])\n",
        "                return np.array(features)\n",
        "\n",
        "            contextual_features = extract_contextual(texts)\n",
        "            syntactic_features = extract_syntactic(texts)\n",
        "\n",
        "            np.save(bert_embedding_file, contextual_features)  # Save BERT embeddings\n",
        "            np.save(syntactic_feature_file, syntactic_features)  # Save syntactic features\n",
        "            print(\"Embeddings calculated and saved.\")\n",
        "            return np.array(np.hstack([contextual_features, syntactic_features]))\n",
        "\n",
        "    def prepare_data(self, df, labels, val_split=0.2):\n",
        "        print(\"Preparing data...\")\n",
        "\n",
        "        # Extract the data\n",
        "        texts = df[self.text_column].tolist()\n",
        "        valid_labels = []\n",
        "        valid_texts = []\n",
        "        valid_indices = []\n",
        "        for i, text in enumerate(texts):\n",
        "            text = str(text).strip()\n",
        "            if pd.notna(text) and text:\n",
        "                valid_texts.append(text)\n",
        "                valid_labels.append(labels[i])\n",
        "                valid_indices.append(i)\n",
        "\n",
        "        if len(valid_texts) < 2:\n",
        "            raise ValueError(\"Insufficient data for training. At least two valid texts are required.\")\n",
        "\n",
        "        encodings = tokenizer(\n",
        "            valid_texts,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=512,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        input_ids = encodings['input_ids']\n",
        "        attention_mask = encodings['attention_mask']\n",
        "\n",
        "        # Extract features\n",
        "        features = self.extract_features(valid_texts)  # Get all features\n",
        "\n",
        "        # Check if features array is empty or has insufficient rows\n",
        "        if features.shape[0] != len(valid_texts):\n",
        "            raise ValueError(f\"Feature extraction failed: Expected {len(valid_texts)} rows, but got {features.shape[0]} rows.\")\n",
        "        if features.shape[0] < 2:\n",
        "            raise ValueError(\"Insufficient data for training. At least two valid texts are required.\")\n",
        "\n",
        "        # Split data\n",
        "        split_idx = int(len(input_ids) * (1 - val_split))\n",
        "        indices = np.random.permutation(len(input_ids))\n",
        "        train_idx = indices[:split_idx]\n",
        "        val_idx = indices[split_idx:]\n",
        "\n",
        "        # Scale features (fit only on training data)\n",
        "        scaler = StandardScaler()\n",
        "        train_features = scaler.fit_transform(features[train_idx])\n",
        "        val_features = scaler.transform(features[val_idx])\n",
        "\n",
        "        self.train_input_ids = input_ids[train_idx]\n",
        "        self.train_attention_mask = attention_mask[train_idx]\n",
        "        self.train_features = torch.tensor(train_features, dtype=torch.float32)\n",
        "        self.train_labels = torch.tensor([valid_labels[i] for i in train_idx], dtype=torch.long)\n",
        "        self.train_texts = [valid_texts[i] for i in train_idx]\n",
        "\n",
        "        self.val_input_ids = input_ids[val_idx]\n",
        "        self.val_attention_mask = attention_mask[val_idx]\n",
        "        self.val_features = torch.tensor(val_features, dtype=torch.float32)\n",
        "        self.val_labels = torch.tensor([valid_labels[i] for i in val_idx], dtype=torch.long)\n",
        "        self.val_texts = [valid_texts[i] for i in val_idx]\n",
        "\n",
        "        self.create_dataloaders()\n",
        "\n",
        "    def create_dataloaders(self):\n",
        "        train_dataset = TensorDataset(self.train_input_ids, self.train_attention_mask, self.train_features, self.train_labels)\n",
        "        val_dataset = TensorDataset(self.val_input_ids, self.val_attention_mask, self.val_features, self.val_labels)\n",
        "\n",
        "        self.train_loader = DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=True,\n",
        "            pin_memory=True,\n",
        "            num_workers=4,\n",
        "            prefetch_factor=3,\n",
        "            persistent_workers=True\n",
        "        )\n",
        "\n",
        "        val_batch_size = min(self.batch_size * 2, len(val_dataset))\n",
        "        self.val_loader = DataLoader(\n",
        "            val_dataset,\n",
        "            batch_size=val_batch_size,\n",
        "            pin_memory=True,\n",
        "            num_workers=4,\n",
        "            persistent_workers=True\n",
        "        )\n",
        "\n",
        "    def setup_training(self):\n",
        "        self.optimizer = torch.optim.AdamW(\n",
        "            self.model.parameters(),\n",
        "            lr=self.hyperparams[\"Learning Rate\"],\n",
        "            weight_decay=self.hyperparams[\"Weight Decay\"],\n",
        "            betas=(0.9, 0.999)\n",
        "        )\n",
        "\n",
        "        total_steps = (len(self.train_loader) // self.hyperparams[\"Gradient Accumulation Steps\"]) * self.hyperparams[\"Epochs\"]\n",
        "\n",
        "        self.scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "            self.optimizer,\n",
        "            max_lr=self.hyperparams[\"Learning Rate\"] * 10,\n",
        "            steps_per_epoch=len(self.train_loader) // self.hyperparams[\"Gradient Accumulation Steps\"],\n",
        "            epochs=self.hyperparams[\"Epochs\"],\n",
        "            pct_start=0.1\n",
        "        )\n",
        "\n",
        "        self.early_stopping = EarlyStopping(patience=self.hyperparams[\"Early Stopping Patience\"])\n",
        "\n",
        "    def train(self):\n",
        "        epochs = self.hyperparams[\"Epochs\"]\n",
        "        accumulation_steps = self.hyperparams[\"Gradient Accumulation Steps\"]\n",
        "\n",
        "        # Clear previous predictions\n",
        "        self.model.all_preds = []\n",
        "        self.model.all_labels = []\n",
        "        self.model.all_texts = []\n",
        "\n",
        "        best_val_loss = float('inf')\n",
        "        train_losses, val_losses = [], []\n",
        "        train_accs, val_accs = [], []\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            train_metrics = self.train_epoch(accumulation_steps)\n",
        "            val_metrics = self.validate()\n",
        "\n",
        "            train_losses.append(train_metrics['loss'])\n",
        "            val_losses.append(val_metrics['loss'])\n",
        "            train_accs.append(train_metrics['acc'])\n",
        "            val_accs.append(val_metrics['acc'])\n",
        "\n",
        "            print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "            print(f\"Train Loss: {train_metrics['loss']:.4f}, Acc: {train_metrics['acc']:.4f}\")\n",
        "            print(f\"Val Loss: {val_metrics['loss']:.4f}, Acc: {val_metrics['acc']:.4f}\")\n",
        "\n",
        "            if val_metrics['loss'] < best_val_loss:\n",
        "                best_val_loss = val_metrics['loss']\n",
        "                torch.save(self.model.state_dict(), 'best_model.pt')\n",
        "\n",
        "            if self.early_stopping(val_metrics['loss']):\n",
        "                print(\"Early stopping triggered\")\n",
        "                break\n",
        "\n",
        "        self.perform_error_analysis()\n",
        "        return {\n",
        "            'train_loss': train_losses,\n",
        "            'val_loss': val_losses,\n",
        "            'train_acc': train_accs,\n",
        "            'val_acc': val_accs\n",
        "        }\n",
        "\n",
        "    def train_epoch(self, accumulation_steps):\n",
        "        torch.cuda.empty_cache()\n",
        "        self.model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for batch_idx, (input_ids, attention_mask, features, target) in enumerate(tqdm(self.train_loader, desc=\"Training\", leave=False)):\n",
        "            torch.cuda.empty_cache()\n",
        "            input_ids = input_ids.to(self.device, non_blocking=True)\n",
        "            attention_mask = attention_mask.to(self.device, non_blocking=True)\n",
        "            features = features.to(self.device, non_blocking=True)\n",
        "            target = target.to(self.device, non_blocking=True)\n",
        "\n",
        "            with autocast():\n",
        "                output = self.model(input_ids=input_ids, attention_mask=attention_mask, features=features)\n",
        "                loss = F.cross_entropy(output, target, label_smoothing=self.hyperparams[\"Label Smoothing\"])\n",
        "                loss = loss / accumulation_steps\n",
        "\n",
        "            self.scaler.scale(loss).backward()\n",
        "\n",
        "            if (batch_idx + 1) % accumulation_steps == 0 or (batch_idx + 1) == len(self.train_loader):\n",
        "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
        "                self.scaler.step(self.optimizer)\n",
        "                self.scaler.update()\n",
        "                self.optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "            total_loss += loss.item() * accumulation_steps\n",
        "            pred = output.argmax(dim=1)\n",
        "            correct += pred.eq(target).sum().item()\n",
        "            total += target.size(0)\n",
        "\n",
        "        self.scheduler.step()  # Moved scheduler step here\n",
        "        return {'loss': total_loss / len(self.train_loader), 'acc': correct / total}\n",
        "\n",
        "    def validate(self):\n",
        "        torch.cuda.empty_cache()\n",
        "        self.model.eval()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (input_ids, attention_mask, features, target) in enumerate(tqdm(self.val_loader, desc=\"Validating\", leave=False)):\n",
        "                torch.cuda.empty_cache() # Empty cache after every batch\n",
        "                input_ids = input_ids.to(self.device, non_blocking=True)\n",
        "                attention_mask = attention_mask.to(self.device, non_blocking=True)\n",
        "                features = features.to(self.device, non_blocking=True)\n",
        "                target = target.to(self.device, non_blocking=True)\n",
        "\n",
        "                with autocast():\n",
        "                    output = self.model(input_ids=input_ids, attention_mask=attention_mask, features=features)\n",
        "                    loss = F.cross_entropy(output, target)\n",
        "\n",
        "                total_loss += loss.item()\n",
        "                pred = output.argmax(dim=1)\n",
        "                correct += pred.eq(target).sum().item()\n",
        "                total += target.size(0)\n",
        "\n",
        "            #Moved the start idx before as it was causing memory errors:\n",
        "            start_index = 0 #batch_idx * self.val_loader.batch_size\n",
        "            batch_size = self.val_loader.batch_size\n",
        "\n",
        "            end_index = len(self.val_texts)\n",
        "                # Get the text for the current batch\n",
        "\n",
        "            self.model.all_preds.extend(pred[:batch_size].cpu().numpy())\n",
        "            self.model.all_labels.extend(target[:batch_size].cpu().numpy())\n",
        "            self.model.all_texts.extend(self.val_texts[start_index:min(end_index, start_index + batch_size)])\n",
        "\n",
        "        return {'loss': total_loss / len(self.val_loader), 'acc': correct / total}\n",
        "\n",
        "    def perform_error_analysis(self):\n",
        "        # Generate classification report\n",
        "        report = classification_report(self.model.all_labels, self.model.all_preds, digits=4)\n",
        "        print(\"Classification Report:\\n\", report)\n",
        "\n",
        "        # Generate confusion matrix\n",
        "        cm = confusion_matrix(self.model.all_labels, self.model.all_preds)\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "        plt.xlabel('Predicted Labels')\n",
        "        plt.ylabel('True Labels')\n",
        "        plt.title('Confusion Matrix')\n",
        "        plt.show()\n",
        "\n",
        "        # Find misclassified texts\n",
        "        misclassified_indices = np.where(np.array(self.model.all_preds) != np.array(self.model.all_labels))[0]\n",
        "\n",
        "        print(\"\\nMisclassified Text Examples:\")\n",
        "        for idx in misclassified_indices[:5]:\n",
        "            print(f\"True Label: {self.model.all_labels[idx]}, Predicted Label: {self.model.all_preds[idx]}\")\n",
        "            print(f\"Text: {self.model.all_texts[idx]}\\n\")\n",
        "\n",
        "        # Explain the predictions using Captum\n",
        "        print(\"\\nAttribution Analysis for Misclassified Examples:\")\n",
        "        for idx in misclassified_indices[:5]:\n",
        "            self.explain_instance(self.model.all_texts[idx], self.model.all_labels[idx])\n",
        "\n",
        "    def explain_instance(self, text, true_label):\n",
        "        self.model.bert.eval()\n",
        "        self.model.bert.zero_grad()\n",
        "\n",
        "        encoding = tokenizer(text, add_special_tokens=True, return_tensors='pt')\n",
        "        input_ids = encoding.input_ids.to(self.device)\n",
        "        attention_mask = encoding.attention_mask.to(self.device)\n",
        "\n",
        "        def forward_func(input_ids, attention_mask):\n",
        "            bert_output = self.model.bert(input_ids, attention_mask)\n",
        "            pooled_output = bert_output.last_hidden_state[:, 0, :]\n",
        "            bert_projected = self.model.bert_projection(pooled_output)\n",
        "            return self.model.classifier(bert_projected)\n",
        "\n",
        "        lig = LayerIntegratedGradients(forward_func, self.model.bert.embeddings)\n",
        "        try:\n",
        "            attributions, delta = lig.attribute(\n",
        "                input_ids,\n",
        "                additional_forward_args=(attention_mask,),\n",
        "                target=int(true_label),  # Ensure target is an int\n",
        "                return_convergence_delta=True\n",
        "            )\n",
        "\n",
        "            attributions = attributions.sum(dim=-1).squeeze(0)\n",
        "            attributions = attributions / torch.norm(attributions)\n",
        "            attributions = attributions.cpu().detach().numpy()\n",
        "\n",
        "            tokens = tokenizer.convert_ids_to_tokens(input_ids[0].cpu().numpy())\n",
        "\n",
        "            print(f\"\\nText: {text}\")\n",
        "            print(f\"True Label: {true_label}\")\n",
        "            print(\"\\nToken Attribution Scores:\")\n",
        "            for token, attribution in zip(tokens, attributions):\n",
        "                if attribution != 0:  # Only show non-zero attributions\n",
        "                    print(f\"{token}: {attribution:.4f}\")\n",
        "            print(\"-\" * 80)\n",
        "        except Exception as e:\n",
        "             print(f\"Captum Explanations error {e}. Check model setup with dimensions. Skipping explanation! {e}\")\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=3, min_delta=0):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.best_loss = None\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, val_loss):\n",
        "        epsilon = 1e-6\n",
        "        if self.best_loss is None:\n",
        "            self.best_loss = val_loss\n",
        "        elif val_loss > self.best_loss - self.min_delta + epsilon:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                return True\n",
        "        else:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n",
        "        return False\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Load your DataFrame\n",
        "    df = pd.read_csv(\"/content/modified_df_11.csv\")\n",
        "\n",
        "    # Ensure 'text' column is string\n",
        "    df['text'] = df['text'].astype(str)\n",
        "\n",
        "    # Set name of text column\n",
        "    text_column = 'text'\n",
        "\n",
        "    # Extract labels\n",
        "    labels = np.array(df[\"rating\"].tolist()) - 1  # Adjust as needed\n",
        "\n",
        "    # Define hyperparameters\n",
        "    hyperparams = {\n",
        "        \"Epochs\": 1,  # Reduced for faster example\n",
        "        \"Batch Size\": 20,  # Reduced for faster example\n",
        "        \"Learning Rate\": 1e-5,\n",
        "        \"Dropout\": 0.3,\n",
        "        \"Weight Decay\": 0.1,\n",
        "        \"Label Smoothing\": 0.1,\n",
        "        \"Early Stopping Patience\": 3,\n",
        "        \"Gradient Accumulation Steps\": 4,\n",
        "        \"Optimizer\": \"AdamW\",\n",
        "        \"Scheduler\": \"OneCycleLR\",\n",
        "        \"Feature Dimension\": 0,\n",
        "        \"Model\": \"BERT with Multiple Embeddings\"\n",
        "    }\n",
        "\n",
        "    embedding_dir = \"my_embeddings\"\n",
        "\n",
        "    # Clear embedding directory\n",
        "    #if os.path.exists(embedding_dir):\n",
        "    #    shutil.rmtree(embedding_dir)\n",
        "\n",
        "    # Instantiate Trainer\n",
        "    trainer = GPUOptimizedTrainer(df, text_column, labels, hyperparams, embedding_dir=embedding_dir)\n",
        "    metrics = trainer.train()\n",
        "\n",
        "    # Print DataFrame\n",
        "    print(df)\n",
        "\n",
        "    # Plot results\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(metrics['train_loss'], label='Train Loss')\n",
        "    plt.plot(metrics['val_loss'], label='Val Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(metrics['train_acc'], label='Train Acc')\n",
        "    plt.plot(metrics['val_acc'], label='Val Acc')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BEUAM4TtuIWy",
        "outputId": "d5202617-7df6-41ae-b514-80526e3da3cb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "  warnings.warn(Warnings.W111)\n",
            "<ipython-input-5-ebfa3d45bf12>:94: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = GradScaler()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preparing data...\n",
            "Extracting features...\n",
            "Loading embeddings from disk...\n",
            "Embeddings loaded.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:   0%|          | 0/2435 [00:00<?, ?it/s]<ipython-input-5-ebfa3d45bf12>:311: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Validating:   0%|          | 0/305 [00:00<?, ?it/s]<ipython-input-5-ebfa3d45bf12>:347: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "Train Loss: 1.2496, Acc: 0.5044\n",
            "Val Loss: 1.0230, Acc: 0.5654\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     1.0000    0.7500    0.8571         8\n",
            "           1     0.5000    0.6667    0.5714         3\n",
            "           2     0.5000    0.6667    0.5714         3\n",
            "           4     1.0000    1.0000    1.0000         1\n",
            "\n",
            "    accuracy                         0.7333        15\n",
            "   macro avg     0.7500    0.7708    0.7500        15\n",
            "weighted avg     0.8000    0.7333    0.7524        15\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Misclassified Text Examples:\n",
            "True Label: 0, Predicted Label: 2\n",
            "Text: Have used them twice and would highly recommend . Very easy process overall\n",
            "\n",
            "True Label: 2, Predicted Label: 1\n",
            "Text: My cat does not like it . She would eating it even when completely stopped feeding her dry food she would and not eat it . paid too much just to see the food dry out in the bowl and have to throw the dried leftover away after my cat never got even close to the bowl .\n",
            "\n",
            "True Label: 0, Predicted Label: 1\n",
            "Text: Picked these up less than a and up until was completely with the purchase . The lenses are excellent and the frames have been comfortable to wear all . However put them on and noticed some in the right . Looking closer could not believe the frames are attached to the lenses by a clear plastic wire that loops under the lens from the end piece to the bridge . And it is loose ! My previous frame glasses were mounted directly to the lens by screws drilled in ! For this price that is an poor means of attachment that has already given out .\n",
            "\n",
            "True Label: 1, Predicted Label: 2\n",
            "Text: Misleading when sending promotions for off . You have to read fine print . Disappointed\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAHqCAYAAADVi/1VAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAaWZJREFUeJzt3Xt8z/X///H7e7O9Z2MzzGaZOZ8ZOcyU8DHNSEg5JEbooxwS+pSPcqpPKh2UhApLcohEfZTTSsRKaMjpg5jTNsdttth47/X7w8/727ttbGyvt3G7Xi6vS17P1/P1ej9ez73XHpfH+/l+viyGYRgCAAAAAAAATOTi7AAAAAAAAABw96EoBQAAAAAAANNRlAIAAAAAAIDpKEoBAAAAAADAdBSlAAAAAAAAYDqKUgAAAAAAADAdRSkAAAAAAACYjqIUAAAAAAAATEdRCgAAAAAAAKajKAUUUf369VOlSpVu6twJEybIYrEUbEC3mSNHjshisSg6Otr017ZYLJowYYJ9Pzo6WhaLRUeOHLnhuZUqVVK/fv0KNJ5bea8AAOBs5DzXR87zf8h5gKKHohRQwCwWS5629evXOzvUu97w4cNlsVh08ODBXPuMHTtWFotFO3fuNDGy/Dt58qQmTJiguLg4Z4didy1Jfuutt5wdCgCgEJDzFB3kPObZu3evLBaLPDw8lJyc7OxwgNteMWcHANxpPvvsM4f9efPmae3atdnaa9eufUuv8/HHHysrK+umzn3ppZf04osv3tLr3wl69+6tadOmacGCBRo3blyOfRYuXKj69eurQYMGN/06ffr0Uc+ePWW1Wm/6Gjdy8uRJTZw4UZUqVVLDhg0djt3KewUAgNyQ8xQd5DzmmT9/vgICAnT+/HktXbpUAwcOdGo8wO2OohRQwJ544gmH/Z9//llr167N1v53f/75pzw9PfP8Om5ubjcVnyQVK1ZMxYrx6x8aGqpq1app4cKFOSZosbGxOnz4sF5//fVbeh1XV1e5urre0jVuxa28VwAAyA05T9FBzmMOwzC0YMECPf744zp8+LA+//zz27YolZ6eLi8vL2eHAfD1PcAZWrdurXr16mnbtm164IEH5OnpqX//+9+SpBUrVqhjx44KDAyU1WpV1apV9corr8hmszlc4+/fmf/rV6U++ugjVa1aVVarVU2bNtWvv/7qcG5O6ytYLBYNHTpUy5cvV7169WS1WlW3bl2tWrUqW/zr169XkyZN5OHhoapVq2rWrFl5XrNh48aNeuyxx1SxYkVZrVYFBQXpueee08WLF7PdX4kSJXTixAl16dJFJUqUkJ+fn0aPHp1tLJKTk9WvXz/5+PioVKlSioqKyvN06d69e2vfvn3avn17tmMLFiyQxWJRr169lJmZqXHjxqlx48by8fGRl5eXWrZsqR9++OGGr5HT+gqGYejVV19VhQoV5OnpqTZt2mj37t3Zzj137pxGjx6t+vXrq0SJEvL29lZkZKR27Nhh77N+/Xo1bdpUktS/f3/71yWurS2R0/oK6enpGjVqlIKCgmS1WlWzZk299dZbMgzDoV9+3hc369SpUxowYID8/f3l4eGhkJAQffrpp9n6LVq0SI0bN1bJkiXl7e2t+vXr67333rMfv3z5siZOnKjq1avLw8NDZcqU0f3336+1a9cWWKwAgPwh5yHnuZtynk2bNunIkSPq2bOnevbsqQ0bNuj48ePZ+mVlZem9995T/fr15eHhIT8/P7Vv315bt2516Dd//nw1a9ZMnp6e8vX11QMPPKA1a9Y4xPzXNb2u+ft6Xdd+Lj/++KOeeeYZlStXThUqVJAkxcfH65lnnlHNmjVVvHhxlSlTRo899liO64IlJyfrueeeU6VKlWS1WlWhQgX17dtXZ86cUVpamry8vPTss89mO+/48eNydXXV5MmT8ziSuJvwsQHgJGfPnlVkZKR69uypJ554Qv7+/pKu/tEoUaKERo4cqRIlSuj777/XuHHjlJqaqilTptzwugsWLNCFCxf0z3/+UxaLRW+++aYeeeQR/fHHHzf89Oinn37SsmXL9Mwzz6hkyZJ6//331a1bNx09elRlypSRJP32229q3769ypcvr4kTJ8pms2nSpEny8/PL030vWbJEf/75p55++mmVKVNGW7Zs0bRp03T8+HEtWbLEoa/NZlNERIRCQ0P11ltvad26dXr77bdVtWpVPf3005KuJjqdO3fWTz/9pMGDB6t27dr66quvFBUVlad4evfurYkTJ2rBggW69957HV77iy++UMuWLVWxYkWdOXNGn3zyiXr16qVBgwbpwoULmj17tiIiIrRly5Zs08dvZNy4cXr11VfVoUMHdejQQdu3b9eDDz6ozMxMh35//PGHli9frscee0yVK1dWUlKSZs2apVatWmnPnj0KDAxU7dq1NWnSJI0bN05PPfWUWrZsKUlq0aJFjq9tGIYefvhh/fDDDxowYIAaNmyo1atX6/nnn9eJEyf07rvvOvTPy/viZl28eFGtW7fWwYMHNXToUFWuXFlLlixRv379lJycbE9s1q5dq169eqlt27Z64403JF1ds2HTpk32PhMmTNDkyZM1cOBANWvWTKmpqdq6dau2b9+udu3a3VKcAICbR85DznO35Dyff/65qlatqqZNm6pevXry9PTUwoUL9fzzzzv0GzBggKKjoxUZGamBAwfqypUr2rhxo37++Wc1adJEkjRx4kRNmDBBLVq00KRJk+Tu7q5ffvlF33//vR588ME8j/9fPfPMM/Lz89O4ceOUnp4uSfr111+1efNm9ezZUxUqVNCRI0c0Y8YMtW7dWnv27LHPakxLS1PLli21d+9ePfnkk7r33nt15swZff311zp+/LgaNmyorl27avHixXrnnXccZswtXLhQhmGod+/eNxU37nAGgEI1ZMgQ4++/aq1atTIkGTNnzszW/88//8zW9s9//tPw9PQ0Ll26ZG+LiooygoOD7fuHDx82JBllypQxzp07Z29fsWKFIcn45ptv7G3jx4/PFpMkw93d3Th48KC9bceOHYYkY9q0afa2Tp06GZ6ensaJEyfsbQcOHDCKFSuW7Zo5yen+Jk+ebFgsFiM+Pt7h/iQZkyZNcujbqFEjo3Hjxvb95cuXG5KMN99809525coVo2XLloYkY+7cuTeMqWnTpkaFChUMm81mb1u1apUhyZg1a5b9mhkZGQ7nnT9/3vD39zeefPJJh3ZJxvjx4+37c+fONSQZhw8fNgzDME6dOmW4u7sbHTt2NLKysuz9/v3vfxuSjKioKHvbpUuXHOIyjKs/a6vV6jA2v/76a673+/f3yrUxe/XVVx36Pfroo4bFYnF4D+T1fZGTa+/JKVOm5Npn6tSphiRj/vz59rbMzEwjLCzMKFGihJGammoYhmE8++yzhre3t3HlypVcrxUSEmJ07NjxujEBAAoPOc+N74+c56o7LecxjKv5S5kyZYyxY8fa2x5//HEjJCTEod/3339vSDKGDx+e7RrXxujAgQOGi4uL0bVr12xj8tdx/Pv4XxMcHOwwttd+Lvfff3+2XCqn92lsbKwhyZg3b569bdy4cYYkY9myZbnGvXr1akOS8d133zkcb9CggdGqVats5wGGYRh8fQ9wEqvVqv79+2drL168uP3fFy5c0JkzZ9SyZUv9+eef2rdv3w2v26NHD/n6+tr3r32C9Mcff9zw3PDwcFWtWtW+36BBA3l7e9vPtdlsWrdunbp06aLAwEB7v2rVqikyMvKG15cc7y89PV1nzpxRixYtZBiGfvvtt2z9Bw8e7LDfsmVLh3v59ttvVaxYMfuniNLV9QyGDRuWp3ikq2tiHD9+XBs2bLC3LViwQO7u7nrsscfs13R3d5d0dcr1uXPndOXKFTVp0iTHafDXs27dOmVmZmrYsGEO0/9HjBiRra/VapWLy9X/VdtsNp09e1YlSpRQzZo18/2613z77bdydXXV8OHDHdpHjRolwzD03XffObTf6H1xK7799lsFBASoV69e9jY3NzcNHz5caWlp+vHHHyVJpUqVUnp6+nW/ileqVCnt3r1bBw4cuOW4AAAFh5yHnOduyHm+++47nT171iGn6dWrl3bs2OHwdcUvv/xSFotF48ePz3aNa2O0fPlyZWVlady4cfYx+XufmzFo0KBsa3799X16+fJlnT17VtWqVVOpUqUcxv3LL79USEiIunbtmmvc4eHhCgwM1Oeff24/9vvvv2vnzp03XGsOdy+KUoCT3HPPPfY/+H+1e/dude3aVT4+PvL29pafn5/9f+IpKSk3vG7FihUd9q8la+fPn8/3udfOv3buqVOndPHiRVWrVi1bv5zacnL06FH169dPpUuXtq+Z0KpVK0nZ7+/ad+xzi0e6+j348uXLq0SJEg79atasmad4JKlnz55ydXXVggULJEmXLl3SV199pcjISIdk99NPP1WDBg3s6xX5+flp5cqVefq5/FV8fLwkqXr16g7tfn5+Dq8nXU0G3333XVWvXl1Wq1Vly5aVn5+fdu7cme/X/evrBwYGqmTJkg7t156OdC2+a270vrgV8fHxql69eraE6++xPPPMM6pRo4YiIyNVoUIFPfnkk9nWeJg0aZKSk5NVo0YN1a9fX88///xt/1hrALgbkPOQ89wNOc/8+fNVuXJlWa1WHTx4UAcPHlTVqlXl6enpUKQ5dOiQAgMDVbp06VyvdejQIbm4uKhOnTo3fN38qFy5cra2ixcvaty4cfY1t66Ne3JyssO4Hzp0SPXq1bvu9V1cXNS7d28tX75cf/75p6SrX2n08PCwFz2Bv6MoBTjJXz+VuCY5OVmtWrXSjh07NGnSJH3zzTdau3atfQ2dvDziNrcnnhh/W8yxoM/NC5vNpnbt2mnlypV64YUXtHz5cq1du9a+OOXf78+sp7eUK1dO7dq105dffqnLly/rm2++0YULFxy+9z5//nz169dPVatW1ezZs7Vq1SqtXbtW//jHPwr10cOvvfaaRo4cqQceeEDz58/X6tWrtXbtWtWtW9e0Rx4X9vsiL8qVK6e4uDh9/fXX9rUhIiMjHdbReOCBB3To0CHNmTNH9erV0yeffKJ7771Xn3zyiWlxAgCyI+ch58mLopzzpKam6ptvvtHhw4dVvXp1+1anTh39+eefWrBggal5098XyL8mp9/FYcOG6T//+Y+6d++uL774QmvWrNHatWtVpkyZmxr3vn37Ki0tTcuXL7c/jfChhx6Sj49Pvq+FuwMLnQO3kfXr1+vs2bNatmyZHnjgAXv74cOHnRjV/ylXrpw8PDx08ODBbMdyavu7Xbt26X//+58+/fRT9e3b195+K09HCw4OVkxMjNLS0hw+Ody/f3++rtO7d2+tWrVK3333nRYsWCBvb2916tTJfnzp0qWqUqWKli1b5jBtOqep13mJWZIOHDigKlWq2NtPnz6d7ZO4pUuXqk2bNpo9e7ZDe3JyssqWLWvfz89U7uDgYK1bt04XLlxw+OTw2lclrsVnhuDgYO3cuVNZWVkOs6VyisXd3V2dOnVSp06dlJWVpWeeeUazZs3Syy+/bP/UunTp0urfv7/69++vtLQ0PfDAA5owYcJt+zhmALhbkfPkHznPVbdjzrNs2TJdunRJM2bMcIhVuvrzeemll7Rp0ybdf//9qlq1qlavXq1z587lOluqatWqysrK0p49e667sLyvr2+2py9mZmYqISEhz7EvXbpUUVFRevvtt+1tly5dynbdqlWr6vfff7/h9erVq6dGjRrp888/V4UKFXT06FFNmzYtz/Hg7sNMKeA2cu3Tmb9+kpKZmakPP/zQWSE5cHV1VXh4uJYvX66TJ0/a2w8ePJjtO/m5nS853p9hGHrvvfduOqYOHTroypUrmjFjhr3NZrPl+49fly5d5OnpqQ8//FDfffedHnnkEXl4eFw39l9++UWxsbH5jjk8PFxubm6aNm2aw/WmTp2ara+rq2u2T9aWLFmiEydOOLR5eXlJUp4eC92hQwfZbDZ98MEHDu3vvvuuLBZLntfKKAgdOnRQYmKiFi9ebG+7cuWKpk2bphIlSti/5nD27FmH81xcXNSgQQNJUkZGRo59SpQooWrVqtmPAwBuH+Q8+UfOc9XtmPPMnz9fVapU0eDBg/Xoo486bKNHj1aJEiXsX+Hr1q2bDMPQxIkTs13n2v136dJFLi4umjRpUrbZSn8do6pVqzqsDyZJH330Ua4zpXKS07hPmzYt2zW6deumHTt26Kuvvso17mv69OmjNWvWaOrUqSpTpoypuSWKHmZKAbeRFi1ayNfXV1FRURo+fLgsFos+++wzU6f73siECRO0Zs0a3XfffXr66aftf+jr1aunuLi4655bq1YtVa1aVaNHj9aJEyfk7e2tL7/88pbWJurUqZPuu+8+vfjiizpy5Ijq1KmjZcuW5XvtgRIlSqhLly72NRb+/sjahx56SMuWLVPXrl3VsWNHHT58WDNnzlSdOnWUlpaWr9fy8/PT6NGjNXnyZD300EPq0KGDfvvtN3333XfZPl176KGHNGnSJPXv318tWrTQrl279Pnnnzt82ihdTUpKlSqlmTNnqmTJkvLy8lJoaGiOawd06tRJbdq00dixY3XkyBGFhIRozZo1WrFihUaMGOGwwGdBiImJ0aVLl7K1d+nSRU899ZRmzZqlfv36adu2bapUqZKWLl2qTZs2aerUqfZPNQcOHKhz587pH//4hypUqKD4+HhNmzZNDRs2tK8LUadOHbVu3VqNGzdW6dKltXXrVi1dulRDhw4t0PsBANw6cp78I+e56nbLeU6ePKkffvgh22Lq11itVkVERGjJkiV6//331aZNG/Xp00fvv/++Dhw4oPbt2ysrK0sbN25UmzZtNHToUFWrVk1jx47VK6+8opYtW+qRRx6R1WrVr7/+qsDAQE2ePFnS1fxo8ODB6tatm9q1a6cdO3Zo9erV2cb2eh566CF99tln8vHxUZ06dRQbG6t169apTJkyDv2ef/55LV26VI899piefPJJNW7cWOfOndPXX3+tmTNnKiQkxN738ccf17/+9S999dVXevrpp+Xm5nYTI4u7hglP+APuark9Hrlu3bo59t+0aZPRvHlzo3jx4kZgYKDxr3/9y/541R9++MHeL7fHI0+ZMiXbNfW3x8Xm9njkIUOGZDv374+UNQzDiImJMRo1amS4u7sbVatWNT755BNj1KhRhoeHRy6j8H/27NljhIeHGyVKlDDKli1rDBo0yP643b8+2jcqKsrw8vLKdn5OsZ89e9bo06eP4e3tbfj4+Bh9+vQxfvvttzw/HvmalStXGpKM8uXL5/j43ddee80IDg42rFar0ahRI+O///1vtp+DYdz48ciGYRg2m82YOHGiUb58eaN48eJG69atjd9//z3beF+6dMkYNWqUvd99991nxMbGGq1atcr2aN0VK1YYderUsT+q+tq95xTjhQsXjOeee84IDAw03NzcjOrVqxtTpkxxeMzwtXvJ6/vi7669J3PbPvvsM8MwDCMpKcno37+/UbZsWcPd3d2oX79+tp/b0qVLjQcffNAoV66c4e7ublSsWNH45z//aSQkJNj7vPrqq0azZs2MUqVKGcWLFzdq1apl/Oc//zEyMzOvGycAoGCQ8zgi57nqTs953n77bUOSERMTk2uf6OhoQ5KxYsUKwzAM48qVK8aUKVOMWrVqGe7u7oafn58RGRlpbNu2zeG8OXPmGI0aNTKsVqvh6+trtGrVyli7dq39uM1mM1544QWjbNmyhqenpxEREWEcPHgwW8zXfi6//vprttjOnz9vz8NKlChhREREGPv27cvxvs+ePWsMHTrUuOeeewx3d3ejQoUKRlRUlHHmzJls1+3QoYMhydi8eXOu4wIYhmFYDOM2+jgCQJHVpUsX7d69WwcOHHB2KAAAAIWGnAe4sa5du2rXrl15WoMNdzfWlAKQbxcvXnTYP3DggL799lu1bt3aOQEBAAAUAnIeIP8SEhK0cuVK9enTx9mhoAhgphSAfCtfvrz69eunKlWqKD4+XjNmzFBGRoZ+++03Va9e3dnhAQAAFAhyHiDvDh8+rE2bNumTTz7Rr7/+qkOHDikgIMDZYeE2x0LnAPKtffv2WrhwoRITE2W1WhUWFqbXXnuN5AwAANxRyHmAvPvxxx/Vv39/VaxYUZ9++ikFKeQJM6UAAAAAAABgOtaUAgAAAAAAgOkoSgEAAAAAAMB0rCmVg6ysLJ08eVIlS5aUxWJxdjgAAMCJDMPQhQsXFBgYKBcXPs+7HnIoAAAg5T1/oiiVg5MnTyooKMjZYQAAgNvIsWPHVKFCBWeHcVsjhwIAAH91o/yJolQOSpYsKenq4Hl7ezs5GgAA4EypqakKCgqy5wfIHTkUAACQ8p4/UZTKwbXp5t7e3iRUAABAkvg6Wh6QQwEAgL+6Uf7EwggAAAAAAAAwHUUpAAAAAAAAmI6iFAAAAAAAAEzHmlIAANwEm82my5cvOzsMFAA3Nze5uro6OwwAAO5aWVlZyszMdHYYyIeCyp8oSgEAkA+GYSgxMVHJycnODgUFqFSpUgoICGAxcwAATJaZmanDhw8rKyvL2aEgnwoif6IoBQBAPlwrSJUrV06enp4UMYo4wzD0559/6tSpU5Kk8uXLOzkiAADuHoZhKCEhQa6urgoKCpKLCysMFQUFmT9RlAIAII9sNpu9IFWmTBlnh4MCUrx4cUnSqVOnVK5cOb7KBwCASa5cuaI///xTgYGB8vT0dHY4yIeCyp8oQwIAkEfX1pAiabrzXPuZsk4YAADmsdlskiR3d3cnR4KbURD5E0UpAADyia/s3Xn4mQIA4Dz8HS6aCuLnRlEKAAAAAAAApnNqUWrDhg3q1KmTAgMDZbFYtHz58uv2X7Zsmdq1ayc/Pz95e3srLCxMq1evdugzYcIEWSwWh61WrVqFeBcAANydKlWqpKlTpzo7DAAAgCLvbs2rnFqUSk9PV0hIiKZPn56n/hs2bFC7du307bffatu2bWrTpo06deqk3377zaFf3bp1lZCQYN9++umnwggfAIAi4e8f1vx9mzBhwk1d99dff9VTTz11S7G1bt1aI0aMuKVrAAAAmOV2zquuWbhwoVxdXTVkyJACuV5hcurT9yIjIxUZGZnn/n+vGr722mtasWKFvvnmGzVq1MjeXqxYMQUEBBRUmAAAFGkJCQn2fy9evFjjxo3T/v377W0lSpSw/9swDNlsNhUrduMUwc/Pr2ADBQAAuM0Vhbxq9uzZ+te//qVZs2bp7bffloeHR4Fdu6AV6TWlsrKydOHCBZUuXdqh/cCBAwoMDFSVKlXUu3dvHT161EkRAgDgfAEBAfbNx8dHFovFvr9v3z6VLFlS3333nRo3biyr1aqffvpJhw4dUufOneXv768SJUqoadOmWrduncN1/z7N3GKx6JNPPlHXrl3l6emp6tWr6+uvv76l2L/88kvVrVtXVqtVlSpV0ttvv+1w/MMPP1T16tXl4eEhf39/Pfroo/ZjS5cuVf369VW8eHGVKVNG4eHhSk9Pv6V4AADA3e12z6sOHz6szZs368UXX1SNGjW0bNmybH3mzJljz6/Kly+voUOH2o8lJyfrn//8p/z9/eXh4aF69erpv//9780P2A04dabUrXrrrbeUlpam7t2729tCQ0MVHR2tmjVrKiEhQRMnTlTLli31+++/q2TJkjleJyMjQxkZGfb91NTUQo8dAHBnMAxDFy/bnPLaxd1cC+xpNS+++KLeeustValSRb6+vjp27Jg6dOig//znP7JarZo3b546deqk/fv3q2LFirleZ+LEiXrzzTc1ZcoUTZs2Tb1791Z8fHy2D5DyYtu2berevbsmTJigHj16aPPmzXrmmWdUpkwZ9evXT1u3btXw4cP12WefqUWLFjp37pw2btwo6eqnmL169dKbb76prl276sKFC9q4caMMw7jpMQIAAIWLvMrRzeRVc+fOVceOHeXj46MnnnhCs2fP1uOPP24/PmPGDI0cOVKvv/66IiMjlZKSok2bNkm6OvEnMjJSFy5c0Pz581W1alXt2bNHrq6uBTIuOSmyRakFCxZo4sSJWrFihcqVK2dv/+vXARs0aKDQ0FAFBwfriy++0IABA3K81uTJkzVx4sRCjxkAcOe5eNmmOuNW37hjIdgzKUKe7gXzp3zSpElq166dfb906dIKCQmx77/yyiv66quv9PXXXzt8mvZ3/fr1U69evSRd/Zr9+++/ry1btqh9+/b5jumdd95R27Zt9fLLL0uSatSooT179mjKlCnq16+fjh49Ki8vLz300EMqWbKkgoOD7V/nT0hI0JUrV/TII48oODhYklS/fv18xwAAAMxDXuUov3lVVlaWoqOjNW3aNElSz549NWrUKB0+fFiVK1eWJL366qsaNWqUnn32Wft5TZs2lSStW7dOW7Zs0d69e1WjRg1JUpUqVW5mCPKsSH59b9GiRRo4cKC++OILhYeHX7dvqVKlVKNGDR08eDDXPmPGjFFKSop9O3bsWEGHDADAba1JkyYO+2lpaRo9erRq166tUqVKqUSJEtq7d+8NvxLfoEED+7+9vLzk7e2tU6dO3VRMe/fu1X333efQdt999+nAgQOy2Wxq166dgoODVaVKFfXp00eff/65/vzzT0lSSEiI2rZtq/r16+uxxx7Txx9/rPPnz99UHAAAAPnhrLxq7dq1Sk9PV4cOHSRJZcuWVbt27TRnzhxJ0qlTp3Ty5Em1bds2x/Pj4uJUoUIFe0HKDEVuptTChQv15JNPatGiRerYseMN+6elpenQoUPq06dPrn2sVqusVmtBhgkAuEsUd3PVnkkRTnvtguLl5eWwP3r0aK1du1ZvvfWWqlWrpuLFi+vRRx9VZmbmda/j5ubmsG+xWJSVlVVgcf5VyZIltX37dq1fv15r1qzRuHHjNGHCBP36668qVaqU1q5dq82bN2vNmjWaNm2axo4dq19++cX+SSEAALi9kFc5ym9eNXv2bJ07d07Fixe3t2VlZWnnzp2aOHGiQ3tObnS8MDi1KJWWluYwg+nw4cOKi4tT6dKlVbFiRY0ZM0YnTpzQvHnzJF39yl5UVJTee+89hYaGKjExUdLVgfPx8ZF09YfdqVMnBQcH6+TJkxo/frxcXV3tU94AAChIFoulwKZ63042bdqkfv36qWvXrpKu/s0+cuSIqTHUrl3bvsbBX+OqUaOGfW2DYsWKKTw8XOHh4Ro/frxKlSql77//Xo888ogsFovuu+8+3XfffRo3bpyCg4P11VdfaeTIkabeBwAAyBvyqpt39uxZrVixQosWLVLdunXt7TabTffff7/WrFmj9u3bq1KlSoqJiVGbNm2yXaNBgwY6fvy4/ve//5k2W8qpP+2tW7c6DMS1JDEqKkrR0dFKSEhwmM720Ucf6cqVKxoyZIiGDBlib7/WX5KOHz+uXr166ezZs/Lz89P999+vn3/+mcdWAwCQD9WrV9eyZcvUqVMnWSwWvfzyy4U24+n06dOKi4tzaCtfvrxGjRqlpk2b6pVXXlGPHj0UGxurDz74QB9++KEk6b///a/++OMPPfDAA/L19dW3336rrKws1axZU7/88otiYmL04IMPqly5cvrll190+vRp1a5du1DuAQAAIDdm5FWfffaZypQpo+7du2dbsL1Dhw6aPXu22rdvrwkTJmjw4MEqV66cfVHzTZs2adiwYWrVqpUeeOABdevWTe+8846qVaumffv2yWKx3NT6oHnh1KJU69atr/sUnGuFpmvWr19/w2suWrToFqMCAADvvPOOnnzySbVo0UJly5bVCy+8UGhPp12wYIEWLFjg0PbKK6/opZde0hdffKFx48bplVdeUfny5TVp0iT169dP0tV1I5ctW6YJEybo0qVLql69uhYuXKi6detq79692rBhg6ZOnarU1FQFBwfr7bffdnggCgAAgBnMyKvmzJmjrl275vgEwW7duqlPnz46c+aMoqKidOnSJb377rsaPXq0ypYtq0cffdTe98svv9To0aPVq1cvpaenq1q1anr99dcLNNa/shg8Gzmb1NRU+fj4KCUlRd7e3s4OBwBwm7h06ZL96SUeHh7ODgcF6Ho/W/KCvGOsAAD5QW5VtBVE/lQkn74HAAAAAACAoo2iFAAAAAAAAExHUQoAAAAAAACmoygFAAAAAAAA01GUAgAAAAAAgOkoSgEAAAAAAMB0FKUAAAAAAABgOopSAAAAAAAAMB1FKQAAAAAAAJiOohQAAMiT1q1ba8SIEc4OAwAAoMgjr7qKohQAAHe4Tp06qX379jke27hxoywWi3bu3HnLrxMdHa1SpUrd8nUAAABuV2blVddcvHhRpUuXVtmyZZWRkVFg171dUJQCAOAON2DAAK1du1bHjx/Pdmzu3Llq0qSJGjRo4ITIAAAAihaz86ovv/xSdevWVa1atbR8+fICu+7tgqIUAAB3uIceekh+fn6Kjo52aE9LS9OSJUs0YMAAnT17Vr169dI999wjT09P1a9fXwsXLizQOI4eParOnTurRIkS8vb2Vvfu3ZWUlGQ/vmPHDrVp00YlS5aUt7e3GjdurK1bt0qS4uPj1alTJ/n6+srLy0t169bVt99+W6DxAQAA3IjZedXs2bP1xBNP6IknntDs2bOzHd+9e7ceeugheXt7q2TJkmrZsqUOHTpkPz5nzhzVrVtXVqtV5cuX19ChQ28qjsJSzNkBAABQpBmGdPlP57y2m6dksdywW7FixdS3b19FR0dr7Nixsvz/c5YsWSKbzaZevXopLS1NjRs31gsvvCBvb2+tXLlSffr0UdWqVdWsWbNbDjUrK8tekPrxxx915coVDRkyRD169ND69eslSb1791ajRo00Y8YMubq6Ki4uTm5ubpKkIUOGKDMzUxs2bJCXl5f27NmjEiVK3HJcAADgNkJe5eDQoUOKjY3VsmXLZBiGnnvuOcXHxys4OFiSdOLECT3wwANq3bq1vv/+e3l7e2vTpk26cuWKJGnGjBkaOXKkXn/9dUVGRiolJUWbNm26icEpPBSlAAC4FZf/lF4LdM5r//uk5O6Vp65PPvmkpkyZoh9//FGtW7eWdHWKebdu3eTj4yMfHx+NHj3a3n/YsGFavXq1vvjiiwIpSsXExGjXrl06fPiwgoKCJEnz5s1T3bp19euvv6pp06Y6evSonn/+edWqVUuSVL16dfv5R48eVbdu3VS/fn1JUpUqVW45JgAAcJshr3IwZ84cRUZGytfXV5IUERGhuXPnasKECZKk6dOny8fHR4sWLbJ/kFejRg37+a+++qpGjRqlZ5991t7WtGnTPL++Gfj6HgAAd4FatWqpRYsWmjNnjiTp4MGD2rhxowYMGCBJstlseuWVV1S/fn2VLl1aJUqU0OrVq3X06NECef29e/cqKCjIXpCSpDp16qhUqVLau3evJGnkyJEaOHCgwsPD9frrrztMPR8+fLheffVV3XfffRo/fnyBLiAKAACQH2bkVTabTZ9++qmeeOIJe9sTTzyh6OhoZWVlSZLi4uLUsmVLe0Hqr06dOqWTJ0+qbdu2t3KrhY6ZUgAA3Ao3z6ufrDnrtfNhwIABGjZsmKZPn665c+eqatWqatWqlSRpypQpeu+99zR16lTVr19fXl5eGjFihDIzMwsj8hxNmDBBjz/+uFauXKnvvvtO48eP16JFi9S1a1cNHDhQERERWrlypdasWaPJkyfr7bff1rBhw0yLDwAAFDLyKrvVq1frxIkT6tGjh0O7zWZTTEyM2rVrp+LFi+d6/vWO3U6YKQUAwK2wWK5O9XbGlod1D/6qe/fucnFx0YIFCzRv3jw9+eST9nUQNm3apM6dO+uJJ55QSEiIqlSpov/9738FNky1a9fWsWPHdOzYMXvbnj17lJycrDp16tjbatSooeeee05r1qzRI488orlz59qPBQUFafDgwVq2bJlGjRqljz/+uMDiAwAAtwHyKrvZs2erZ8+eiouLc9h69uxpX/C8QYMG2rhxoy5fvpzt/JIlS6pSpUqKiYnJ1+uajZlSAADcJUqUKKEePXpozJgxSk1NVb9+/ezHqlevrqVLl2rz5s3y9fXVO++8o6SkJIeCUV7YbDbFxcU5tFmtVoWHh6t+/frq3bu3pk6dqitXruiZZ55Rq1at1KRJE128eFHPP/+8Hn30UVWuXFnHjx/Xr7/+qm7dukmSRowYocjISNWoUUPnz5/XDz/8oNq1a9/qkAAAANyUwsyrTp8+rW+++UZff/216tWr53Csb9++6tq1q86dO6ehQ4dq2rRp6tmzp8aMGSMfHx/9/PPPatasmWrWrKkJEyZo8ODBKleunCIjI3XhwgVt2rTptpppzkwpAADuIgMGDND58+cVERGhwMD/W0j0pZde0r333quIiAi1bt1aAQEB6tKlS76vn5aWpkaNGjlsnTp1ksVi0YoVK+Tr66sHHnhA4eHhqlKlihYvXixJcnV11dmzZ9W3b1/VqFFD3bt3V2RkpCZOnCjparFryJAhql27ttq3b68aNWroww8/LJAxAQAAuBmFlVfNmzdPXl5eOa4H1bZtWxUvXlzz589XmTJl9P333ystLU2tWrVS48aN9fHHH9vXmIqKitLUqVP14Ycfqm7dunrooYd04MCBW77vgmQxDMNwdhC3m9TUVPn4+CglJUXe3t7ODgcAcJu4dOmSDh8+rMqVK8vDw8PZ4aAAXe9nS16Qd4wVACA/yK2KtoLIn5gpBQAAAAAAANNRlAIAACiCpk+frkqVKsnDw0OhoaHasmVLrn2jo6NlsVgctpw+kd67d68efvhh+fj4yMvLS02bNs3X46sBAADyg6IUAABAEbN48WKNHDlS48eP1/bt2xUSEqKIiAidOnUq13O8vb2VkJBg3+Lj4x2OHzp0SPfff79q1aql9evXa+fOnXr55Zf5OgUAACg0PH0PAACgiHnnnXc0aNAg9e/fX5I0c+ZMrVy5UnPmzNGLL76Y4zkWi0UBAQG5XnPs2LHq0KGD3nzzTXtb1apVCzZwAACAv2CmFAAAQBGSmZmpbdu2KTw83N7m4uKi8PBwxcbG5npeWlqagoODFRQUpM6dO2v37t32Y1lZWVq5cqVq1KihiIgIlStXTqGhoVq+fPl1Y8nIyFBqaqrDBgAAkFcUpQAAyKesrCxnh4ACVpR+pmfOnJHNZpO/v79Du7+/vxITE3M8p2bNmpozZ45WrFih+fPnKysrSy1atNDx48clSadOnVJaWppef/11tW/fXmvWrFHXrl31yCOP6Mcff8w1lsmTJ8vHx8e+BQUFFdyNAgDuGoZhODsE3ISCyJ/4+h4AAHnk7u4uFxcXnTx5Un5+fnJ3d5fFYnF2WLgFhmEoMzNTp0+flouLi9zd3Z0dUqEICwtTWFiYfb9FixaqXbu2Zs2apVdeecWeVHbu3FnPPfecJKlhw4bavHmzZs6cqVatWuV43TFjxmjkyJH2/dTUVApTAIA8c3Nzk8Vi0enTp+Xn50deVUQUZP5EUQoAgDxycXFR5cqVlZCQoJMnTzo7HBQgT09PVaxYUS4ut/8k8rJly8rV1VVJSUkO7UlJSdddM+qv3Nzc1KhRIx08eNB+zWLFiqlOnToO/WrXrq2ffvop1+tYrVZZrdZ83gEAAFe5urqqQoUKOn78uI4cOeLscJBPBZE/UZQCACAf3N3dVbFiRV25ckU2m83Z4aAAuLq6qlixYkXm01l3d3c1btxYMTEx6tKli6Sr0+djYmI0dOjQPF3DZrNp165d6tChg/2aTZs21f79+x36/e9//1NwcHCBxg8AwF+VKFFC1atX1+XLl50dCvKhoPInilIAAOSTxWKRm5ub3NzcnB0K7lIjR45UVFSUmjRpombNmmnq1KlKT0+3P42vb9++uueeezR58mRJ0qRJk9S8eXNVq1ZNycnJmjJliuLj4zVw4ED7NZ9//nn16NFDDzzwgNq0aaNVq1bpm2++0fr1651xiwCAu4irq6tcXV2dHQacgKIUAABAEdOjRw+dPn1a48aNU2Jioho2bKhVq1bZFz8/evSow1T68+fPa9CgQUpMTJSvr68aN26szZs3O3xdr2vXrpo5c6YmT56s4cOHq2bNmvryyy91//33m35/AADg7mAxWOY+m9TUVPn4+CglJUXe3t7ODgcAADgReUHeMVYAAEDKe05w+6/mCQAAAAAAgDsORSkAAAAAAACYjqIUAAAAAAAATEdRCgAAAAAAAKajKAUAAAAAAADTUZQCAAAAAACA6ShKAQAAAAAAwHQUpQAAAAAAAGA6ilIAAAAAAAAwHUUpAAAAAAAAmI6iFAAAAAAAAExHUQoAAAAAAACmoygFAAAAAAAA01GUAgAAAAAAgOkoSgEAAAAAAMB0FKUAAAAAAABgOopSAAAAAAAAMB1FKQAAAAAAAJiOohQAAAAAAABMR1EKAAAAAAAApqMoBQAAAAAAANNRlAIAAAAAAIDpKEoBAAAAAADAdBSlAAAAAAAAYDqKUgAAAAAAADAdRSkAAAAAAACYjqIUAAAAAAAATEdRCgAAAAAAAKajKAUAAAAAAADTUZQCAAAAAACA6ShKAQAAAAAAwHQUpQAAAAAAAGA6ilIAAAAAAAAwHUUpAAAAAAAAmI6iFAAAAAAAAExHUQoAAAAAAACmoygFAAAAAAAA0zm1KLVhwwZ16tRJgYGBslgsWr58+XX7L1u2TO3atZOfn5+8vb0VFham1atXZ+s3ffp0VapUSR4eHgoNDdWWLVsK6Q4AAAAAAABwM5xalEpPT1dISIimT5+ep/4bNmxQu3bt9O2332rbtm1q06aNOnXqpN9++83eZ/HixRo5cqTGjx+v7du3KyQkRBERETp16lRh3QYAAAAAAADyyWIYhuHsICTJYrHoq6++UpcuXfJ1Xt26ddWjRw+NGzdOkhQaGqqmTZvqgw8+kCRlZWUpKChIw4YN04svvpina6ampsrHx0cpKSny9vbOVzwAAODOQl6Qd4wVAACQ8p4TFOk1pbKysnThwgWVLl1akpSZmalt27YpPDzc3sfFxUXh4eGKjY3N9ToZGRlKTU112AAAAAAAAFB4inRR6q233lJaWpq6d+8uSTpz5oxsNpv8/f0d+vn7+ysxMTHX60yePFk+Pj72LSgoqFDjBgAAAAAAuNsV2aLUggULNHHiRH3xxRcqV67cLV1rzJgxSklJsW/Hjh0roCgBAAAAAACQk2LODuBmLFq0SAMHDtSSJUscvqpXtmxZubq6KikpyaF/UlKSAgICcr2e1WqV1WottHgBAAAAAADgqMjNlFq4cKH69++vhQsXqmPHjg7H3N3d1bhxY8XExNjbsrKyFBMTo7CwMLNDBQAAAAAAQC6cOlMqLS1NBw8etO8fPnxYcXFxKl26tCpWrKgxY8boxIkTmjdvnqSrX9mLiorSe++9p9DQUPs6UcWLF5ePj48kaeTIkYqKilKTJk3UrFkzTZ06Venp6erfv7/5NwgAAAAAAIAcObUotXXrVrVp08a+P3LkSElSVFSUoqOjlZCQoKNHj9qPf/TRR7py5YqGDBmiIUOG2Nuv9ZekHj166PTp0xo3bpwSExPVsGFDrVq1Ktvi5wAAAAAAAHAei2EYhrODuN2kpqbKx8dHKSkp8vb2dnY4AADAicgL8o6xAgAAUt5zgiK3phQAAAAAAACKPopSAAAARdD06dNVqVIleXh4KDQ0VFu2bMm1b3R0tCwWi8Pm4eHh0Kdfv37Z+rRv376wbwMAANzFnLqmFAAAAPJv8eLFGjlypGbOnKnQ0FBNnTpVERER2r9/v8qVK5fjOd7e3tq/f79932KxZOvTvn17zZ07175vtVoLPngAAID/j5lSAAAARcw777yjQYMGqX///qpTp45mzpwpT09PzZkzJ9dzLBaLAgIC7FtOD4GxWq0OfXx9fQvzNgAAwF2OohQAAEARkpmZqW3btik8PNze5uLiovDwcMXGxuZ6XlpamoKDgxUUFKTOnTtr9+7d2fqsX79e5cqVU82aNfX000/r7NmzhXIPAAAAEkUpAACAIuXMmTOy2WzZZjr5+/srMTExx3Nq1qypOXPmaMWKFZo/f76ysrLUokULHT9+3N6nffv2mjdvnmJiYvTGG2/oxx9/VGRkpGw2W66xZGRkKDU11WEDAADIK9aUAgAAuMOFhYUpLCzMvt+iRQvVrl1bs2bN0iuvvCJJ6tmzp/14/fr11aBBA1WtWlXr169X27Ztc7zu5MmTNXHixMINHgAA3LGYKQUAAFCElC1bVq6urkpKSnJoT0pKUkBAQJ6u4ebmpkaNGungwYO59qlSpYrKli173T5jxoxRSkqKfTt27FjebgIAAEAUpQAAAIoUd3d3NW7cWDExMfa2rKwsxcTEOMyGuh6bzaZdu3apfPnyufY5fvy4zp49e90+VqtV3t7eDhsAAEBeUZQCAAAoYkaOHKmPP/5Yn376qfbu3aunn35a6enp6t+/vySpb9++GjNmjL3/pEmTtGbNGv3xxx/avn27nnjiCcXHx2vgwIGSri6C/vzzz+vnn3/WkSNHFBMTo86dO6tatWqKiIhwyj0CAIA7H2tKAQAAFDE9evTQ6dOnNW7cOCUmJqphw4ZatWqVffHzo0ePysXl/z57PH/+vAYNGqTExET5+vqqcePG2rx5s+rUqSNJcnV11c6dO/Xpp58qOTlZgYGBevDBB/XKK6/IarU65R4BAMCdz2IYhuHsIG43qamp8vHxUUpKCtPQAQC4y5EX5B1jBQAApLznBHx9DwAAAAAAAKajKAUAAAAAAADTUZQCAAAAAACA6ShKAQAAAAAAwHQUpQAAAAAAAGA6ilIAAAAAAAAwHUUpAAAAAAAAmI6iFAAAAAAAAExHUQoAAAAAAACmoygFAAAAAAAA01GUAgAAAAAAgOkoSgEAAAAAAMB0FKUAAAAAAABgOopSAAAAAAAAMB1FKQAAAAAAAJiOohQAAAAAAABMR1EKAAAAAAAApqMoBQAAAAAAANNRlAIAAAAAAIDpKEoBAAAAAADAdBSlAAAAAAAAYDqKUgAAAAAAADAdRSkAAAAAAACYjqIUAAAAAAAATEdRCgAAAAAAAKajKAUAAAAAAADTUZQCAAAAAACA6ShKAQAAAAAAwHQUpQAAAAAAAGA6ilIAAAAAAAAwHUUpAAAAAAAAmI6iFAAAAAAAAExHUQoAAAAAAACmoygFAAAAAAAA01GUAgAAAAAAgOkoSgEAAAAAAMB0FKUAAAAAAABgOopSAAAAAAAAMB1FKQAAAAAAAJiOohQAAAAAAABMR1EKAAAAAAAApqMoBQAAAAAAANNRlAIAAAAAAIDpKEoBAAAAAADAdBSlAAAAAAAAYDqKUgAAAAAAADAdRSkAAAAAAACYjqIUAAAAAAAATEdRCgAAAAAAAKajKAUAAFAETZ8+XZUqVZKHh4dCQ0O1ZcuWXPtGR0fLYrE4bB4eHrn2Hzx4sCwWi6ZOnVoIkQMAAFxFUQoAAKCIWbx4sUaOHKnx48dr+/btCgkJUUREhE6dOpXrOd7e3kpISLBv8fHxOfb76quv9PPPPyswMLCwwgcAAJBEUQoAAKDIeeeddzRo0CD1799fderU0cyZM+Xp6ak5c+bkeo7FYlFAQIB98/f3z9bnxIkTGjZsmD7//HO5ubkV5i0AAABQlAIAAChKMjMztW3bNoWHh9vbXFxcFB4ertjY2FzPS0tLU3BwsIKCgtS5c2ft3r3b4XhWVpb69Omj559/XnXr1i20+AEAAK6hKAUAAFCEnDlzRjabLdtMJ39/fyUmJuZ4Ts2aNTVnzhytWLFC8+fPV1ZWllq0aKHjx4/b+7zxxhsqVqyYhg8fnudYMjIylJqa6rABAADkVTFnBwAAAIDCFRYWprCwMPt+ixYtVLt2bc2aNUuvvPKKtm3bpvfee0/bt2+XxWLJ83UnT56siRMnFkbIAADgLsBMKQAAABNUqlRJkyZN0tGjR2/pOmXLlpWrq6uSkpIc2pOSkhQQEJCna7i5ualRo0Y6ePCgJGnjxo06deqUKlasqGLFiqlYsWKKj4/XqFGjVKlSpVyvM2bMGKWkpNi3Y8eO3fR9AQCAuw9FKQAAABOMGDFCy5YtU5UqVdSuXTstWrRIGRkZ+b6Ou7u7GjdurJiYGHtbVlaWYmJiHGZDXY/NZtOuXbtUvnx5SVKfPn20c+dOxcXF2bfAwEA9//zzWr16da7XsVqt8vb2dtgAAADyiqIUAACACUaMGKG4uDht2bJFtWvX1rBhw1S+fHkNHTpU27dvz9e1Ro4cqY8//liffvqp9u7dq6efflrp6enq37+/JKlv374aM2aMvf+kSZO0Zs0a/fHHH9q+fbueeOIJxcfHa+DAgZKkMmXKqF69eg6bm5ubAgICVLNmzYIbBAAAgL9walFqw4YN6tSpkwIDA2WxWLR8+fLr9k9ISNDjjz+uGjVqyMXFRSNGjMjWJzo6WhaLxWHz8PAonBsAAADIp3vvvVfvv/++Tp48qfHjx+uTTz5R06ZN1bBhQ82ZM0eGYdzwGj169NBbb72lcePGqWHDhoqLi9OqVavsi58fPXpUCQkJ9v7nz5/XoEGDVLt2bXXo0EGpqanavHmz6tSpU2j3CQAAcCNOXeg8PT1dISEhevLJJ/XII4/csH9GRob8/Pz00ksv6d133821n7e3t/bv32/fz8+CnQAAAIXp8uXL+uqrrzR37lytXbtWzZs314ABA3T8+HH9+9//1rp167RgwYIbXmfo0KEaOnRojsfWr1/vsP/uu+9eN3fKyZEjR/LVHwAAIL+cWpSKjIxUZGRknvtXqlRJ7733niRpzpw5ufazWCx5XugTAADADNu3b9fcuXO1cOFCubi4qG/fvnr33XdVq1Yte5+uXbuqadOmTowSAADAPE4tShWWtLQ0BQcHKysrS/fee69ee+011a1bN9f+GRkZDguNpqammhEmAAC4izRt2lTt2rXTjBkz1KVLF7m5uWXrU7lyZfXs2dMJ0QEAAJjvjitK1axZU3PmzFGDBg2UkpKit956Sy1atNDu3btVoUKFHM+ZPHmyJk6caHKkAADgbvLHH38oODj4un28vLw0d+5ckyICAABwrjvu6XthYWHq27evGjZsqFatWmnZsmXy8/PTrFmzcj1nzJgxSklJsW/Hjh0zMWIAAHA3OHXqlH755Zds7b/88ou2bt3qhIgAAACc644rSv2dm5ubGjVqpIMHD+bax2q1ytvb22EDAAAoSEOGDMnxg68TJ05oyJAhTogIAADAue74opTNZtOuXbtUvnx5Z4cCAADuYnv27NG9996brb1Ro0bas2ePEyICAABwLqeuKZWWluYwg+nw4cOKi4tT6dKlVbFiRY0ZM0YnTpzQvHnz7H3i4uLs554+fVpxcXFyd3dXnTp1JEmTJk1S8+bNVa1aNSUnJ2vKlCmKj4/XwIEDTb03AACAv7JarUpKSlKVKlUc2hMSElSs2B23zCcAAMANOTUD2rp1q9q0aWPfHzlypCQpKipK0dHRSkhI0NGjRx3OadSokf3f27Zt04IFCxQcHKwjR45Iks6fP69BgwYpMTFRvr6+aty4sTZv3mwvWgEAADjDgw8+qDFjxmjFihXy8fGRJCUnJ+vf//632rVr5+ToAAAAzGcxDMNwdhC3m9TUVPn4+CglJYX1pQAAuMsVVF5w4sQJPfDAAzp79qz9Q7a4uDj5+/tr7dq1CgoKKqiQnYYcCgAASHnPCZgrDgAAYIJ77rlHO3fu1Oeff64dO3aoePHi6t+/v3r16iU3NzdnhwcAAGA6ilIAAAAm8fLy0lNPPeXsMAAAAG4LFKUAAABMtGfPHh09elSZmZkO7Q8//LCTIgIAAHAOilIAAAAm+OOPP9S1a1ft2rVLFotF15b1tFgskiSbzebM8AAAAEzncjMnHTt2TMePH7fvb9myRSNGjNBHH31UYIEBAADcSZ599llVrlxZp06dkqenp3bv3q0NGzaoSZMmWr9+vbPDAwAAMN1NFaUef/xx/fDDD5KkxMREtWvXTlu2bNHYsWM1adKkAg0QAADgThAbG6tJkyapbNmycnFxkYuLi+6//35NnjxZw4cPd3Z4AAAAprupotTvv/+uZs2aSZK++OIL1atXT5s3b9bnn3+u6OjogowPAADgjmCz2VSyZElJUtmyZXXy5ElJUnBwsPbv3+/M0AAAAJziptaUunz5sqxWqyRp3bp19oU5a9WqpYSEhIKLDgAA4A5Rr1497dixQ5UrV1ZoaKjefPNNubu766OPPlKVKlWcHR4AAIDpbmqmVN26dTVz5kxt3LhRa9euVfv27SVJJ0+eVJkyZQo0QAAAgDvBSy+9pKysLEnSpEmTdPjwYbVs2VLffvut3n//fSdHBwAAYL6bmin1xhtvqGvXrpoyZYqioqIUEhIiSfr666/tX+sDAADA/4mIiLD/u1q1atq3b5/OnTsnX19f+xP4AAAA7iY3VZRq3bq1zpw5o9TUVPn6+trbn3rqKXl6ehZYcAAAAHeCy5cvq3jx4oqLi1O9evXs7aVLl3ZiVAAAAM51U1/fu3jxojIyMuwFqfj4eE2dOlX79+9XuXLlCjRAAACAos7NzU0VK1aUzWZzdigAAAC3jZsqSnXu3Fnz5s2TJCUnJys0NFRvv/22unTpohkzZhRogAAAAHeCsWPH6t///rfOnTvn7FAAAABuCzdVlNq+fbtatmwpSVq6dKn8/f0VHx+vefPmsVAnAABADj744ANt2LBBgYGBqlmzpu69916HDQAA4G5zU2tK/fnnnypZsqQkac2aNXrkkUfk4uKi5s2bKz4+vkADBAAAuBN06dLF2SEAAADcVm6qKFWtWjUtX75cXbt21erVq/Xcc89Jkk6dOiVvb+8CDRAAAOBOMH78eGeHAAAAcFu5qa/vjRs3TqNHj1alSpXUrFkzhYWFSbo6a6pRo0YFGiAAAAAAAADuPDc1U+rRRx/V/fffr4SEBIWEhNjb27Ztq65duxZYcAAAAHcKFxcXWSyWXI/zZD4AAHC3uamilCQFBAQoICBAx48flyRVqFBBzZo1K7DAAAAA7iRfffWVw/7ly5f122+/6dNPP9XEiROdFBUAAIDz3FRRKisrS6+++qrefvttpaWlSZJKliypUaNGaezYsXJxualvBQIAANyxOnfunK3t0UcfVd26dbV48WINGDDACVEBAAA4z00VpcaOHavZs2fr9ddf13333SdJ+umnnzRhwgRdunRJ//nPfwo0SAAAgDtV8+bN9dRTTzk7DAAAANPdVFHq008/1SeffKKHH37Y3tagQQPdc889euaZZyhKAQAA5MHFixf1/vvv65577nF2KAAAAKa7qaLUuXPnVKtWrWzttWrV0rlz5245KAAAgDuNr6+vw0LnhmHowoUL8vT01Pz5850YGQAAgHPcVFEqJCREH3zwgd5//32H9g8++EANGjQokMAAAADuJO+++65DUcrFxUV+fn4KDQ2Vr6+vEyMDAABwjpsqSr355pvq2LGj1q1bp7CwMElSbGysjh07pm+//bZAAwQAALgT9OvXz9khAAAA3FZu6jF5rVq10v/+9z917dpVycnJSk5O1iOPPKLdu3frs88+K+gYAQAAiry5c+dqyZIl2dqXLFmiTz/91AkRAQAAOJfFMAyjoC62Y8cO3XvvvbLZbAV1SadITU2Vj4+PUlJS5O3t7exwAACAExVUXlCjRg3NmjVLbdq0cWj/8ccf9dRTT2n//v23GqrTkUMBAAAp7znBTc2UAgAAQP4cPXpUlStXztYeHByso0ePOiEiAAAA56IoBQAAYIJy5cpp586d2dp37NihMmXKOCEiAAAA56IoBQAAYIJevXpp+PDh+uGHH2Sz2WSz2fT999/r2WefVc+ePZ0dHgAAgOny9fS9Rx555LrHk5OTbyUWAACAO9Yrr7yiI0eOqG3btipW7GoKlpWVpb59++q1115zcnQAAADmy1dRysfH54bH+/bte0sBAQAA3Inc3d21ePFivfrqq4qLi1Px4sVVv359BQcHOzs0AAAAp8hXUWru3LmFFQcAAMBdoXr16qpevbqzwwAAAHA61pQCAAAwQbdu3fTGG29ka3/zzTf12GOPOSEiAAAA56IoBQAAYIINGzaoQ4cO2dojIyO1YcMGJ0QEAADgXBSlAAAATJCWliZ3d/ds7W5ubkpNTXVCRAAAAM5FUQoAAMAE9evX1+LFi7O1L1q0SHXq1HFCRAAAAM6Vr4XOAQAAcHNefvllPfLIIzp06JD+8Y9/SJJiYmK0YMECLV261MnRAQAAmI+iFAAAgAk6deqk5cuX67XXXtPSpUtVvHhxhYSE6Pvvv1fp0qWdHR4AAIDpKEoBAACYpGPHjurYsaMkKTU1VQsXLtTo0aO1bds22Ww2J0cHAABgLtaUAgAAMNGGDRsUFRWlwMBAvf322/rHP/6hn3/+2dlhAQAAmI6iFAAAQCFLTEzU66+/rurVq+uxxx6Tt7e3MjIytHz5cr3++utq2rRpvq85ffp0VapUSR4eHgoNDdWWLVty7RsdHS2LxeKweXh4OPSZMGGCatWqJS8vL/n6+io8PFy//PJLvuMCAADIK4pSAAAAhahTp06qWbOmdu7cqalTp+rkyZOaNm3aLV1z8eLFGjlypMaPH6/t27crJCREEREROnXqVK7neHt7KyEhwb7Fx8c7HK9Ro4Y++OAD7dq1Sz/99JMqVaqkBx98UKdPn76lWAEAAHJjMQzDcHYQt5vU1FT5+PgoJSVF3t7ezg4HAAA40a3mBcWKFdPw4cP19NNPq3r16vZ2Nzc37dixQ3Xq1Mn3NUNDQ9W0aVN98MEHkqSsrCwFBQVp2LBhevHFF7P1j46O1ogRI5ScnJzn17h23+vWrVPbtm3zdQ45FAAAd7e85gTMlAIAAChEP/30ky5cuKDGjRsrNDRUH3zwgc6cOXPT18vMzNS2bdsUHh5ub3NxcVF4eLhiY2NzPS8tLU3BwcEKCgpS586dtXv37uu+xkcffSQfHx+FhITk2i8jI0OpqakOGwAAQF5RlAIAAChEzZs318cff6yEhAT985//1KJFixQYGKisrCytXbtWFy5cyNf1zpw5I5vNJn9/f4d2f39/JSYm5nhOzZo1NWfOHK1YsULz589XVlaWWrRooePHjzv0++9//6sSJUrIw8ND7777rtauXauyZcvmGsvkyZPl4+Nj34KCgvJ1LwAA4O5GUQoAAMAEXl5eevLJJ/XTTz9p165dGjVqlF5//XWVK1dODz/8cKG+dlhYmPr27auGDRuqVatWWrZsmfz8/DRr1iyHfm3atFFcXJw2b96s9u3bq3v37tddp2rMmDFKSUmxb8eOHSvU+wAAAHcWilIAAAAmq1mzpt58800dP35cCxcuzNe5ZcuWlaurq5KSkhzak5KSFBAQkKdruLm5qVGjRjp48KBDu5eXl6pVq6bmzZtr9uzZKlasmGbPnp3rdaxWq7y9vR02AACAvKIoBQAA4CSurq7q0qWLvv766zyf4+7ursaNGysmJsbelpWVpZiYGIWFheXpGjabTbt27VL58uWv2y8rK0sZGRl5jg0AACA/ijk7AAAAAOTPyJEjFRUVpSZNmqhZs2aaOnWq0tPT1b9/f0lS3759dc8992jy5MmSpEmTJql58+aqVq2akpOTNWXKFMXHx2vgwIGSpPT0dP3nP//Rww8/rPLly+vMmTOaPn26Tpw4occee8xp9wkAAO5sFKUAAACKmB49euj06dMaN26cEhMT1bBhQ61atcq++PnRo0fl4vJ/E+LPnz+vQYMGKTExUb6+vmrcuLE2b96sOnXqSLo6Y2vfvn369NNPdebMGZUpU0ZNmzbVxo0bVbduXafcIwAAuPNZDMMwnB3E7SY1NVU+Pj5KSUlhbQQAAO5y5AV5x1gBAAAp7zkBa0oBAAAAAADAdBSlAAAAAAAAYDqKUgAAAAAAADAdRSkAAAAAAACYjqIUAAAAAAAATEdRCgAAAAAAAKajKAUAAAAAAADTUZQCAAAAAACA6ShKAQAAAAAAwHQUpQAAAAAAAGA6ilIAAAAAAAAwHUUpAAAAAAAAmI6iFAAAAAAAAExHUQoAAAAAAACmoygFAAAAAAAA01GUAgAAAAAAgOkoSgEAAAAAAMB0FKUAAAAAAABgOqcWpTZs2KBOnTopMDBQFotFy5cvv27/hIQEPf7446pRo4ZcXFw0YsSIHPstWbJEtWrVkoeHh+rXr69vv/224IMHAAAAAADATXNqUSo9PV0hISGaPn16nvpnZGTIz89PL730kkJCQnLss3nzZvXq1UsDBgzQb7/9pi5duqhLly76/fffCzJ0AAAAAAAA3AKLYRiGs4OQJIvFoq+++kpdunTJU//WrVurYcOGmjp1qkN7jx49lJ6erv/+97/2tubNm6thw4aaOXNmnq6dmpoqHx8fpaSkyNvbO6+3AAAA7kDkBXnHWAEAACnvOcEdt6ZUbGyswsPDHdoiIiIUGxub6zkZGRlKTU112AAAAAAAAFB47riiVGJiovz9/R3a/P39lZiYmOs5kydPlo+Pj30LCgoq7DABAAAAAADuandcUepmjBkzRikpKfbt2LFjzg4JAAAAAADgjlbM2QEUtICAACUlJTm0JSUlKSAgINdzrFarrFZrYYcGAAAAAACA/++OmykVFhammJgYh7a1a9cqLCzMSREBAAAAAADg75w6UyotLU0HDx607x8+fFhxcXEqXbq0KlasqDFjxujEiROaN2+evU9cXJz93NOnTysuLk7u7u6qU6eOJOnZZ59Vq1at9Pbbb6tjx45atGiRtm7dqo8++sjUewMAAAAAAEDuLIZhGM568fXr16tNmzbZ2qOiohQdHa1+/frpyJEjWr9+vf2YxWLJ1j84OFhHjhyx7y9ZskQvvfSSjhw5ourVq+vNN99Uhw4d8hwXjzMGAADXkBfkHWMFAACkvOcETi1K3a5IqAAAwDXkBXnHWAEAACnvOcEdt6YUAAAAAAAAbn8UpQAAAAAAAGA6ilIAAAAAAAAwHUUpAAAAAAAAmI6iFAAAAAAAAExHUQoAAAAAAACmoygFAAAAAAAA01GUAgAAAAAAgOkoSgEAAAAAAMB0FKUAAAAAAABgOopSAAAAAAAAMB1FKQAAAAAAAJiOohQAAAAAAABMR1EKAAAAAAAApqMoBQAAAAAAANNRlAIAAAAAAIDpKEoBAAAAAADAdBSlAAAAAAAAYDqKUgAAAAAAADAdRSkAAAAAAACYjqIUAABAETR9+nRVqlRJHh4eCg0N1ZYtW3LtGx0dLYvF4rB5eHjYj1++fFkvvPCC6tevLy8vLwUGBqpv3746efKkGbcCAADuUhSlAAAAipjFixdr5MiRGj9+vLZv366QkBBFRETo1KlTuZ7j7e2thIQE+xYfH28/9ueff2r79u16+eWXtX37di1btkz79+/Xww8/bMbtAACAu1QxZwcAAACA/HnnnXc0aNAg9e/fX5I0c+ZMrVy5UnPmzNGLL76Y4zkWi0UBAQE5HvPx8dHatWsd2j744AM1a9ZMR48eVcWKFQv2BgAAAMRMKQAAgCIlMzNT27ZtU3h4uL3NxcVF4eHhio2NzfW8tLQ0BQcHKygoSJ07d9bu3buv+zopKSmyWCwqVapUrn0yMjKUmprqsAEAAOQVRSkAAIAi5MyZM7LZbPL393do9/f3V2JiYo7n1KxZU3PmzNGKFSs0f/58ZWVlqUWLFjp+/HiO/S9duqQXXnhBvXr1kre3d66xTJ48WT4+PvYtKCjo5m8MAADcdShKAQAA3OHCwsLUt29fNWzYUK1atdKyZcvk5+enWbNmZet7+fJlde/eXYZhaMaMGde97pgxY5SSkmLfjh07Vli3AAAA7kCsKQUAAFCElC1bVq6urkpKSnJoT0pKynXNqL9zc3NTo0aNdPDgQYf2awWp+Ph4ff/999edJSVJVqtVVqs1fzcAAADw/zFTCgAAoAhxd3dX48aNFRMTY2/LyspSTEyMwsLC8nQNm82mXbt2qXz58va2awWpAwcOaN26dSpTpkyBxw4AAPBXzJQCAAAoYkaOHKmoqCg1adJEzZo109SpU5Wenm5/Gl/fvn11zz33aPLkyZKkSZMmqXnz5qpWrZqSk5M1ZcoUxcfHa+DAgZKuFqQeffRRbd++Xf/9739ls9ns61OVLl1a7u7uzrlRAABwR6MoBQAAUMT06NFDp0+f1rhx45SYmKiGDRtq1apV9sXPjx49KheX/5sQf/78eQ0aNEiJiYny9fVV48aNtXnzZtWpU0eSdOLECX399deSpIYNGzq81g8//KDWrVubcl8AAODuYjEMw3B2ELeb1NRU+fj4KCUl5YZrKQAAgDsbeUHeMVYAAEDKe07AmlIAAAAAAAAwHUUpAAAAAAAAmI6iFAAAAAAAAExHUQoAAAAAAACmoygFAAAAAAAA01GUAgAAAAAAgOkoSgEAAAAAAMB0FKUAAAAAAABgOopSAAAAAAAAMB1FKQAAAAAAAJiOohQAAAAAAABMR1EKAAAAAAAApqMoBQAAAAAAANNRlAIAAAAAAIDpKEoBAAAAAADAdBSlAAAAAAAAYDqKUgAAAAAAADAdRSkAAAAAAACYjqIUAAAAAAAATEdRCgAAAAAAAKajKAUAAAAAAADTUZQCAAAAAACA6ShKAQAAAAAAwHQUpQAAAAAAAGA6ilIAAAAAAAAwHUUpAAAAAAAAmI6iFAAAAAAAAExHUQoAAAAAAACmoygFAAAAAAAA01GUAgAAAAAAgOkoSgEAAAAAAMB0FKUAAAAAAABgOopSAAAAAAAAMB1FKQAAAAAAAJiOohQAAAAAAABMR1EKAAAAAAAApqMoBQAAAAAAANNRlAIAAAAAAIDpKEoBAAAAAADAdE4tSm3YsEGdOnVSYGCgLBaLli9ffsNz1q9fr3vvvVdWq1XVqlVTdHS0w/EJEybIYrE4bLVq1SqcGwAAAAAAAMBNcWpRKj09XSEhIZo+fXqe+h8+fFgdO3ZUmzZtFBcXpxEjRmjgwIFavXq1Q7+6desqISHBvv3000+FET4AAAAAAABuUjFnvnhkZKQiIyPz3H/mzJmqXLmy3n77bUlS7dq19dNPP+ndd99VRESEvV+xYsUUEBBQ4PECAAAAAACgYBSpNaViY2MVHh7u0BYREaHY2FiHtgMHDigwMFBVqlRR7969dfToUTPDBAAAAAAAwA04daZUfiUmJsrf39+hzd/fX6mpqbp48aKKFy+u0NBQRUdHq2bNmkpISNDEiRPVsmVL/f777ypZsmSO183IyFBGRoZ9PzU1tVDvAwAAAAAA4G5XpIpSefHXrwM2aNBAoaGhCg4O1hdffKEBAwbkeM7kyZM1ceJEs0IEAAAAAAC46xWpr+8FBAQoKSnJoS0pKUne3t4qXrx4jueUKlVKNWrU0MGDB3O97pgxY5SSkmLfjh07VqBxAwAAAAAAwFGRKkqFhYUpJibGoW3t2rUKCwvL9Zy0tDQdOnRI5cuXz7WP1WqVt7e3wwYAAAAAAIDC49SiVFpamuLi4hQXFydJOnz4sOLi4uwLk48ZM0Z9+/a19x88eLD++OMP/etf/9K+ffv04Ycf6osvvtBzzz1n7zN69Gj9+OOPOnLkiDZv3qyuXbvK1dVVvXr1MvXeAAAAAAAAkDunrim1detWtWnTxr4/cuRISVJUVJSio6OVkJDg8OS8ypUra+XKlXruuef03nvvqUKFCvrkk08UERFh73P8+HH16tVLZ8+elZ+fn+6//379/PPP8vPzM+/GAAAAAAAAcF0WwzAMZwdxu0lNTZWPj49SUlL4Kh8AAHe52zUvmD59uqZMmaLExESFhIRo2rRpatasWY59o6Oj1b9/f4c2q9WqS5cu2feXLVummTNnatu2bTp37px+++03NWzYMF8x3a5jBQAAzJXXnKBIrSkFAAAAafHixRo5cqTGjx+v7du3KyQkRBERETp16lSu53h7eyshIcG+xcfHOxxPT0/X/fffrzfeeKOwwwcAAJDk5K/vAQAAIP/eeecdDRo0yD77aebMmVq5cqXmzJmjF198McdzLBaLAgICcr1mnz59JElHjhwp8HgBAABywkwpAACAIiQzM1Pbtm1TeHi4vc3FxUXh4eGKjY3N9by0tDQFBwcrKChInTt31u7du80IFwAAIFcUpQAAAIqQM2fOyGazyd/f36Hd399fiYmJOZ5Ts2ZNzZkzRytWrND8+fOVlZWlFi1a6Pjx47cUS0ZGhlJTUx02AACAvKIoBQAAcIcLCwtT37591bBhQ7Vq1UrLli2Tn5+fZs2adUvXnTx5snx8fOxbUFBQAUUMAADuBhSlAAAAipCyZcvK1dVVSUlJDu1JSUnXXTPqr9zc3NSoUSMdPHjwlmIZM2aMUlJS7NuxY8du6XoAAODuQlEKAACgCHF3d1fjxo0VExNjb8vKylJMTIzCwsLydA2bzaZdu3apfPnytxSL1WqVt7e3wwYAAJBXPH0PAACgiBk5cqSioqLUpEkTNWvWTFOnTlV6err9aXx9+/bVPffco8mTJ0uSJk2apObNm6tatWpKTk7WlClTFB8fr4EDB9qvee7cOR09elQnT56UJO3fv1+SFBAQkOcZWAAAAPlBUQoAAKCI6dGjh06fPq1x48YpMTFRDRs21KpVq+yLnx89elQuLv83If78+fMaNGiQEhMT5evrq8aNG2vz5s2qU6eOvc/XX39tL2pJUs+ePSVJ48eP14QJE8y5MQAAcFexGIZhODuI201qaqp8fHyUkpLCNHQAAO5y5AV5x1gBAAAp7zkBa0oBAAAAAADAdBSlAAAAAAAAYDqKUgAAAAAAADAdRSkAAAAAAACYjqIUAAAAAAAATEdRCgAAAAAAAKajKAUAAAAAAADTUZQCAAAAAACA6ShKAQAAAAAAwHQUpQAAAAAAAGA6ilIAAAAAAAAwHUUpAAAAAAAAmI6iFAAAAAAAAExHUQoAAAAAAACmoygFAAAAAAAA01GUAgAAAAAAgOkoSgEAAAAAAMB0FKUAAAAAAABgOopSAAAAAAAAMB1FKQAAAAAAAJiOohQAAAAAAABMR1EKAAAAAAAApqMoBQAAAAAAANNRlAIAAAAAAIDpKEoBAAAAAADAdBSlAAAAAAAAYDqKUgAAAAAAADAdRSkAAAAAAACYjqIUAAAAAAAATEdRCgAAAAAAAKajKAUAAAAAAADTUZQCAAAAAACA6ShKAQAAAAAAwHQUpQAAAAAAAGA6ilIAAAAAAAAwHUUpAAAAAAAAmI6iFAAAAAAAAExHUQoAAAAAAACmoygFAAAAAAAA01GUAgAAAAAAgOkoSgEAAAAAAMB0FKUAAAAAAABgOopSAAAAAAAAMB1FKQAAAAAAAJiOohQAAAAAAABMV8zZAdyODMOQJKWmpjo5EgAA4GzX8oFr+QFyRw4FAACkvOdPFKVycOHCBUlSUFCQkyMBAAC3iwsXLsjHx8fZYdzWyKEAAMBf3Sh/shh87JdNVlaWTp48qZIlS8pisTg7nNtKamqqgoKCdOzYMXl7ezs7nLsG4+4cjLtzMO7OwbjnzjAMXbhwQYGBgXJxYeWD6yGHyhm/X87BuDsH4+4cjLtzMO65y2v+xEypHLi4uKhChQrODuO25u3tzS+dEzDuzsG4Owfj7hyMe86YIZU35FDXx++XczDuzsG4Owfj7hyMe87ykj/xcR8AAAAAAABMR1EKAAAAAAAApqMohXyxWq0aP368rFars0O5qzDuzsG4Owfj7hyMO1B4+P1yDsbdORh352DcnYNxv3UsdA4AAAAAAADTMVMKAAAAAAAApqMoBQAAAAAAANNRlAIAAAAAAIDpKErBwblz59S7d295e3urVKlSGjBggNLS0q57zqVLlzRkyBCVKVNGJUqUULdu3ZSUlJRj37Nnz6pChQqyWCxKTk4uhDsomgpj3Hfs2KFevXopKChIxYsXV+3atfXee+8V9q3c1qZPn65KlSrJw8NDoaGh2rJly3X7L1myRLVq1ZKHh4fq16+vb7/91uG4YRgaN26cypcvr+LFiys8PFwHDhwozFsokgpy3C9fvqwXXnhB9evXl5eXlwIDA9W3b1+dPHmysG+jSCro9/xfDR48WBaLRVOnTi3gqIGih/zJecihzEEO5RzkUM5B/mQyA/iL9u3bGyEhIcbPP/9sbNy40ahWrZrRq1ev654zePBgIygoyIiJiTG2bt1qNG/e3GjRokWOfTt37mxERkYakozz588Xwh0UTYUx7rNnzzaGDx9urF+/3jh06JDx2WefGcWLFzemTZtW2LdzW1q0aJHh7u5uzJkzx9i9e7cxaNAgo1SpUkZSUlKO/Tdt2mS4uroab775prFnzx7jpZdeMtzc3Ixdu3bZ+7z++uuGj4+PsXz5cmPHjh3Gww8/bFSuXNm4ePGiWbd12yvocU9OTjbCw8ONxYsXG/v27TNiY2ONZs2aGY0bNzbztoqEwnjPX7Ns2TIjJCTECAwMNN59991CvhPg9kf+5DzkUIWPHMo5yKGcg/zJfBSlYLdnzx5DkvHrr7/a27777jvDYrEYJ06cyPGc5ORkw83NzViyZIm9be/evYYkIzY21qHvhx9+aLRq1cqIiYkhqfqLwh73v3rmmWeMNm3aFFzwRUizZs2MIUOG2PdtNpsRGBhoTJ48Ocf+3bt3Nzp27OjQFhoaavzzn/80DMMwsrKyjICAAGPKlCn248nJyYbVajUWLlxYCHdQNBX0uOdky5YthiQjPj6+YIK+QxTW2B8/fty45557jN9//90IDg4mqcJdj/zJecihzEEO5RzkUM5B/mQ+vr4Hu9jYWJUqVUpNmjSxt4WHh8vFxUW//PJLjuds27ZNly9fVnh4uL2tVq1aqlixomJjY+1te/bs0aRJkzRv3jy5uPC2+6vCHPe/S0lJUenSpQsu+CIiMzNT27ZtcxgvFxcXhYeH5zpesbGxDv0lKSIiwt7/8OHDSkxMdOjj4+Oj0NDQ6/4M7iaFMe45SUlJkcViUalSpQok7jtBYY19VlaW+vTpo+eff15169YtnOCBIob8yXnIoQofOZRzkEM5B/mTc/DXDXaJiYkqV66cQ1uxYsVUunRpJSYm5nqOu7t7tv+R+fv728/JyMhQr169NGXKFFWsWLFQYi/KCmvc/27z5s1avHixnnrqqQKJuyg5c+aMbDab/P39HdqvN16JiYnX7X/tv/m55t2mMMb97y5duqQXXnhBvXr1kre3d8EEfgcorLF/4403VKxYMQ0fPrzggwaKKPIn5yGHKnzkUM5BDuUc5E/OQVHqLvDiiy/KYrFcd9u3b1+hvf6YMWNUu3ZtPfHEE4X2GrcjZ4/7X/3+++/q3Lmzxo8frwcffNCU1wQK2+XLl9W9e3cZhqEZM2Y4O5w73rZt2/Tee+8pOjpaFovF2eEAhc7Zf8fv1vxJcv7Y/xU5FO5E5FDmIX+6sWLODgCFb9SoUerXr991+1SpUkUBAQE6deqUQ/uVK1d07tw5BQQE5HheQECAMjMzlZyc7PCJU1JSkv2c77//Xrt27dLSpUslXX3ahiSVLVtWY8eO1cSJE2/yzm5vzh73a/bs2aO2bdvqqaee0ksvvXRT91LUlS1bVq6urtmeapTTeF0TEBBw3f7X/puUlKTy5cs79GnYsGEBRl90Fca4X3MtmYqPj9f333/PJ3x/Uxhjv3HjRp06dcphxobNZtOoUaM0depUHTlypGBvAnAyZ/8dv1vzJ8n5Y38NORQ5lLOQQzkH+ZOTOHdJK9xOri0WuXXrVnvb6tWr87RY5NKlS+1t+/btc1gs8uDBg8auXbvs25w5cwxJxubNm3N9isHdpLDG3TAM4/fffzfKlStnPP/884V3A0VEs2bNjKFDh9r3bTabcc8991x30cKHHnrIoS0sLCzbIp1vvfWW/XhKSgqLdP5NQY+7YRhGZmam0aVLF6Nu3brGqVOnCifwO0BBj/2ZM2cc/l++a9cuIzAw0HjhhReMffv2Fd6NALc58ifnIYcyBzmUc5BDOQf5k/koSsFB+/btjUaNGhm//PKL8dNPPxnVq1d3eKzu8ePHjZo1axq//PKLvW3w4MFGxYoVje+//97YunWrERYWZoSFheX6Gj/88ANPj/mbwhj3Xbt2GX5+fsYTTzxhJCQk2Le79Q/QokWLDKvVakRHRxt79uwxnnrqKaNUqVJGYmKiYRiG0adPH+PFF1+099+0aZNRrFgx46233jL27t1rjB8/PsfHGZcqVcpYsWKFsXPnTqNz5848zvhvCnrcMzMzjYcfftioUKGCERcX5/DezsjIcMo93q4K4z3/dzw9BriK/Ml5yKEKHzmUc5BDOQf5k/koSsHB2bNnjV69ehklSpQwvL29jf79+xsXLlywHz98+LAhyfjhhx/sbRcvXjSeeeYZw9fX1/D09DS6du1qJCQk5PoaJFXZFca4jx8/3pCUbQsODjbxzm4v06ZNMypWrGi4u7sbzZo1M37++Wf7sVatWhlRUVEO/b/44gujRo0ahru7u1G3bl1j5cqVDsezsrKMl19+2fD39zesVqvRtm1bY//+/WbcSpFSkON+7Xchp+2vvx+4qqDf839HUgVcRf7kPORQ5iCHcg5yKOcgfzKXxTD+/xfUAQAAAAAAAJPw9D0AAAAAAACYjqIUAAAAAAAATEdRCgAAAAAAAKajKAUAAAAAAADTUZQCAAAAAACA6ShKAQAAAAAAwHQUpQAAAAAAAGA6ilIAAAAAAAAwHUUpAChgFotFy5cvd3YYAAAARQb5E3B3oigF4I7Sr18/WSyWbFv79u2dHRoAAMBtifwJgLMUc3YAAFDQ2rdvr7lz5zq0Wa1WJ0UDAABw+yN/AuAMzJQCcMexWq0KCAhw2Hx9fSVdnRo+Y8YMRUZGqnjx4qpSpYqWLl3qcP6uXbv0j3/8Q8WLF1eZMmX01FNPKS0tzaHPnDlzVLduXVmtVpUvX15Dhw51OH7mzBl17dpVnp6eql69ur7++uvCvWkAAIBbQP4EwBkoSgG467z88svq1q2bduzYod69e6tnz57au3evJCk9PV0RERHy9fXVr7/+qiVLlmjdunUOSdOMGTM0ZMgQPfXUU9q1a5e+/vprVatWzeE1Jk6cqO7du2vnzp3q0KGDevfurXPnzpl6nwAAAAWF/AlAoTAA4A4SFRVluLq6Gl5eXg7bf/7zH8MwDEOSMXjwYIdzQkNDjaefftowDMP46KOPDF9fXyMtLc1+fOXKlYaLi4uRmJhoGIZhBAYGGmPHjs01BknGSy+9ZN9PS0szJBnfffddgd0nAABAQSF/AuAsrCkF4I7Tpk0bzZgxw6GtdOnS9n+HhYU5HAsLC1NcXJwkae/evQoJCZGXl5f9+H333aesrCzt379fFotFJ0+eVNu2ba8bQ4MGDez/9vLykre3t06dOnWztwQAAFCoyJ8AOANFKQB3HC8vr2zTwQtK8eLF89TPzc3NYd9isSgrK6swQgIAALhl5E8AnIE1pQDcdX7++eds+7Vr15Yk1a5dWzt27FB6err9+KZNm+Ti4qKaNWuqZMmSqlSpkmJiYkyNGQAAwJnInwAUBmZKAbjjZGRkKDEx0aGtWLFiKlu2rCRpyZIlatKkie6//359/vnn2rJli2bPni1J6t27t8aPH6+oqChNmDBBp0+f1rBhw9SnTx/5+/tLkiZMmKDBgwerXLlyioyM1IULF7Rp0yYNGzbM3BsFAAAoIORPAJyBohSAO86qVatUvnx5h7aaNWtq3759kq4+2WXRokV65plnVL58eS1cuFB16tSRJHl6emr16tV69tln1bRpU3l6eqpbt25655137NeKiorSpUuX9O6772r06NEqW7asHn30UfNuEAAAoICRPwFwBothGIazgwAAs1gsFn311Vfq0qWLs0MBAAAoEsifABQW1pQCAAAAAACA6ShKAQAAAAAAwHR8fQ8AAAAAAACmY6YUAAAAAAAATEdRCgAAAAAAAKajKAUAAAAAAADTUZQCAAAAAACA6ShKAQAAAAAAwHQUpQAAAAAAAGA6ilIAAAAAAAAwHUUpAAAAAAAAmI6iFAAAAAAAAEz3/wC6slLAET6RwAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import spacy\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import shutil\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from captum.attr import LayerIntegratedGradients\n",
        "\n",
        "# Initialize device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Initialize models\n",
        "nlp = spacy.load('en_core_web_sm', disable=['ner', 'parser', 'lemmatizer'])\n",
        "\n",
        "# Use a BERT model fine-tuned on Amazon reviews\n",
        "model_name = 'nlptown/bert-base-multilingual-uncased-sentiment'\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "bert_model = BertModel.from_pretrained(model_name).to(device)\n",
        "\n",
        "class RegularizedBERT(nn.Module):\n",
        "    def __init__(self, num_labels, feature_dim, hyperparams):\n",
        "        super().__init__()\n",
        "        self.bert = bert_model\n",
        "        self.dropout = nn.Dropout(hyperparams[\"Dropout\"])\n",
        "        self.feature_dim = feature_dim\n",
        "        self.bert_projection = nn.Linear(768, 384)\n",
        "        self.feature_projection = nn.Linear(feature_dim, 384) if feature_dim > 0 else None\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(384, 384),\n",
        "            nn.LayerNorm(384),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(hyperparams[\"Dropout\"]),\n",
        "            nn.Linear(384, num_labels)\n",
        "        )\n",
        "        self.all_preds = []\n",
        "        self.all_labels = []\n",
        "        self.all_texts = []\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, features=None):\n",
        "        bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = bert_output.last_hidden_state[:, 0, :]\n",
        "        bert_projected = self.bert_projection(pooled_output)\n",
        "\n",
        "        if features is not None and self.feature_dim > 0:\n",
        "            feature_projected = self.feature_projection(features)\n",
        "            combined_features = bert_projected + feature_projected\n",
        "        else:\n",
        "            combined_features = bert_projected\n",
        "\n",
        "        output = self.classifier(combined_features)\n",
        "        return output\n",
        "\n",
        "class GPUOptimizedTrainer:\n",
        "    def __init__(self, df, text_column, labels, hyperparams, embedding_dir=\"embeddings\"):\n",
        "        # Validate hyperparameters\n",
        "        required_params = [\"Epochs\", \"Batch Size\", \"Learning Rate\", \"Dropout\", \"Weight Decay\",\n",
        "                         \"Label Smoothing\", \"Early Stopping Patience\", \"Gradient Accumulation Steps\"]\n",
        "        for param in required_params:\n",
        "            if param not in hyperparams:\n",
        "                raise ValueError(f\"Missing required hyperparameter: {param}\")\n",
        "\n",
        "        if hyperparams[\"Batch Size\"] <= 0:\n",
        "            raise ValueError(\"Batch Size must be positive\")\n",
        "        if not 0 <= hyperparams[\"Dropout\"] <= 1:\n",
        "            raise ValueError(f\"Dropout must be between 0 and 1\")\n",
        "\n",
        "        self.device = device\n",
        "        self.hyperparams = hyperparams\n",
        "        self.batch_size = hyperparams[\"Batch Size\"]\n",
        "        self.embedding_dir = embedding_dir\n",
        "        self.text_column = text_column\n",
        "\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "        torch.backends.cuda.matmul.allow_tf32 = True\n",
        "        torch.backends.cudnn.allow_tf32 = True\n",
        "\n",
        "        self.model = RegularizedBERT(\n",
        "            num_labels=5,\n",
        "            feature_dim=0,\n",
        "            hyperparams=hyperparams\n",
        "        ).to(self.device)\n",
        "\n",
        "        self.scaler = GradScaler()\n",
        "        self.prepare_data(df, labels)\n",
        "        self.setup_training()\n",
        "\n",
        "    def extract_features(self, texts):\n",
        "        print(\"Extracting features...\")\n",
        "        os.makedirs(self.embedding_dir, exist_ok=True)  # Ensure embedding directory exists\n",
        "\n",
        "        bert_embedding_file = os.path.join(self.embedding_dir, \"bert_embeddings.npy\")\n",
        "        syntactic_feature_file = os.path.join(self.embedding_dir, \"syntactic_features.npy\")\n",
        "\n",
        "        if os.path.exists(bert_embedding_file) and os.path.exists(syntactic_feature_file):\n",
        "            print(\"Loading embeddings from disk...\")\n",
        "            contextual_features = np.load(bert_embedding_file)\n",
        "            syntactic_features = np.load(syntactic_feature_file)\n",
        "            print(\"Embeddings loaded.\")\n",
        "            return np.hstack([contextual_features, syntactic_features])\n",
        "        else:\n",
        "            print(\"Calculating and saving embeddings...\")\n",
        "\n",
        "            def extract_contextual(texts, batch_size=128):\n",
        "                features = []\n",
        "                for i in range(0, len(texts), batch_size):\n",
        "                    batch = [str(text).strip() for text in texts[i:i + batch_size] if pd.notna(text) and str(text).strip()]\n",
        "                    inputs = tokenizer(batch, padding=True, truncation=True, return_tensors=\"pt\").to(self.device)\n",
        "                    with torch.no_grad():\n",
        "                        outputs = bert_model(**inputs)\n",
        "                        embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
        "                    features.extend(embeddings)\n",
        "                return np.array(features)\n",
        "\n",
        "            def extract_syntactic(texts):\n",
        "                features = []\n",
        "                for text in texts:\n",
        "                    text = str(text).strip()\n",
        "                    if not text:\n",
        "                        features.append([0, 0, 0, 0])  # Handle empty strings\n",
        "                        continue\n",
        "                    doc = nlp(text)\n",
        "                    pos_tags = [token.pos_ for token in doc]\n",
        "                    features.append([\n",
        "                        len(doc),\n",
        "                        len(set(pos_tags)) / max(len(pos_tags), 1),\n",
        "                        pos_tags.count('NOUN') / max(len(pos_tags), 1),\n",
        "                        pos_tags.count('VERB') / max(len(pos_tags), 1),\n",
        "                    ])\n",
        "                return np.array(features)\n",
        "\n",
        "            contextual_features = extract_contextual(texts)\n",
        "            syntactic_features = extract_syntactic(texts)\n",
        "\n",
        "            np.save(bert_embedding_file, contextual_features)  # Save BERT embeddings\n",
        "            np.save(syntactic_feature_file, syntactic_features)  # Save syntactic features\n",
        "            print(\"Embeddings calculated and saved.\")\n",
        "            return np.array(np.hstack([contextual_features, syntactic_features]))\n",
        "\n",
        "    def prepare_data(self, df, labels, val_split=0.2):\n",
        "        print(\"Preparing data...\")\n",
        "\n",
        "        # Extract the data\n",
        "        texts = df[self.text_column].tolist()\n",
        "        valid_labels = []\n",
        "        valid_texts = []\n",
        "        valid_indices = []\n",
        "        for i, text in enumerate(texts):\n",
        "            text = str(text).strip()\n",
        "            if pd.notna(text) and text:\n",
        "                valid_texts.append(text)\n",
        "                valid_labels.append(labels[i])\n",
        "                valid_indices.append(i)\n",
        "\n",
        "        if len(valid_texts) < 2:\n",
        "            raise ValueError(\"Insufficient data for training. At least two valid texts are required.\")\n",
        "\n",
        "        encodings = tokenizer(\n",
        "            valid_texts,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=512,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        input_ids = encodings['input_ids']\n",
        "        attention_mask = encodings['attention_mask']\n",
        "\n",
        "        # Extract features\n",
        "        features = self.extract_features(valid_texts)  # Get all features\n",
        "\n",
        "        # Check if features array is empty or has insufficient rows\n",
        "        if features.shape[0] != len(valid_texts):\n",
        "            raise ValueError(f\"Feature extraction failed: Expected {len(valid_texts)} rows, but got {features.shape[0]} rows.\")\n",
        "        if features.shape[0] < 2:\n",
        "            raise ValueError(\"Insufficient data for training. At least two valid texts are required.\")\n",
        "\n",
        "        # Split data\n",
        "        split_idx = int(len(input_ids) * (1 - val_split))\n",
        "        indices = np.random.permutation(len(input_ids))\n",
        "        train_idx = indices[:split_idx]\n",
        "        val_idx = indices[split_idx:]\n",
        "\n",
        "        # Scale features (fit only on training data)\n",
        "        scaler = StandardScaler()\n",
        "        train_features = scaler.fit_transform(features[train_idx])\n",
        "        val_features = scaler.transform(features[val_idx])\n",
        "\n",
        "        self.train_input_ids = input_ids[train_idx]\n",
        "        self.train_attention_mask = attention_mask[train_idx]\n",
        "        self.train_features = torch.tensor(train_features, dtype=torch.float32)\n",
        "        self.train_labels = torch.tensor([valid_labels[i] for i in train_idx], dtype=torch.long)\n",
        "        self.train_texts = [valid_texts[i] for i in train_idx]\n",
        "\n",
        "        self.val_input_ids = input_ids[val_idx]\n",
        "        self.val_attention_mask = attention_mask[val_idx]\n",
        "        self.val_features = torch.tensor(val_features, dtype=torch.float32)\n",
        "        self.val_labels = torch.tensor([valid_labels[i] for i in val_idx], dtype=torch.long)\n",
        "        self.val_texts = [valid_texts[i] for i in val_idx]\n",
        "\n",
        "        self.create_dataloaders()\n",
        "\n",
        "    def create_dataloaders(self):\n",
        "        train_dataset = TensorDataset(self.train_input_ids, self.train_attention_mask, self.train_features, self.train_labels)\n",
        "        val_dataset = TensorDataset(self.val_input_ids, self.val_attention_mask, self.val_features, self.val_labels)\n",
        "\n",
        "        self.train_loader = DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=True,\n",
        "            pin_memory=True,\n",
        "            num_workers=4,\n",
        "            prefetch_factor=3,\n",
        "            persistent_workers=True\n",
        "        )\n",
        "\n",
        "        val_batch_size = min(self.batch_size * 2, len(val_dataset))\n",
        "        self.val_loader = DataLoader(\n",
        "            val_dataset,\n",
        "            batch_size=val_batch_size,\n",
        "            pin_memory=True,\n",
        "            num_workers=4,\n",
        "            persistent_workers=True\n",
        "        )\n",
        "\n",
        "    def setup_training(self):\n",
        "        self.optimizer = torch.optim.AdamW(\n",
        "            self.model.parameters(),\n",
        "            lr=self.hyperparams[\"Learning Rate\"],\n",
        "            weight_decay=self.hyperparams[\"Weight Decay\"],\n",
        "            betas=(0.9, 0.999)\n",
        "        )\n",
        "\n",
        "        total_steps = (len(self.train_loader) // self.hyperparams[\"Gradient Accumulation Steps\"]) * self.hyperparams[\"Epochs\"]\n",
        "\n",
        "        self.scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "            self.optimizer,\n",
        "            max_lr=self.hyperparams[\"Learning Rate\"] * 10,\n",
        "            steps_per_epoch=len(self.train_loader) // self.hyperparams[\"Gradient Accumulation Steps\"],\n",
        "            epochs=self.hyperparams[\"Epochs\"],\n",
        "            pct_start=0.1\n",
        "        )\n",
        "\n",
        "        self.early_stopping = EarlyStopping(patience=self.hyperparams[\"Early Stopping Patience\"])\n",
        "\n",
        "    def train(self):\n",
        "        epochs = self.hyperparams[\"Epochs\"]\n",
        "        accumulation_steps = self.hyperparams[\"Gradient Accumulation Steps\"]\n",
        "\n",
        "        # Clear previous predictions\n",
        "        self.model.all_preds = []\n",
        "        self.model.all_labels = []\n",
        "        self.model.all_texts = []\n",
        "\n",
        "        best_val_loss = float('inf')\n",
        "        train_losses, val_losses = [], []\n",
        "        train_accs, val_accs = [], []\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            train_metrics = self.train_epoch(accumulation_steps)\n",
        "            val_metrics = self.validate()\n",
        "\n",
        "            train_losses.append(train_metrics['loss'])\n",
        "            val_losses.append(val_metrics['loss'])\n",
        "            train_accs.append(train_metrics['acc'])\n",
        "            val_accs.append(val_metrics['acc'])\n",
        "\n",
        "            print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "            print(f\"Train Loss: {train_metrics['loss']:.4f}, Acc: {train_metrics['acc']:.4f}\")\n",
        "            print(f\"Val Loss: {val_metrics['loss']:.4f}, Acc: {val_metrics['acc']:.4f}\")\n",
        "\n",
        "            if val_metrics['loss'] < best_val_loss:\n",
        "                best_val_loss = val_metrics['loss']\n",
        "                torch.save(self.model.state_dict(), 'best_model.pt')\n",
        "\n",
        "            if self.early_stopping(val_metrics['loss']):\n",
        "                print(\"Early stopping triggered\")\n",
        "                break\n",
        "\n",
        "        self.perform_error_analysis()\n",
        "        return {\n",
        "            'train_loss': train_losses,\n",
        "            'val_loss': val_losses,\n",
        "            'train_acc': train_accs,\n",
        "            'val_acc': val_accs\n",
        "        }\n",
        "\n",
        "    def train_epoch(self, accumulation_steps):\n",
        "        torch.cuda.empty_cache()\n",
        "        self.model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for batch_idx, (input_ids, attention_mask, features, target) in enumerate(tqdm(self.train_loader, desc=\"Training\", leave=False)):\n",
        "            torch.cuda.empty_cache() # Empty cache after every batch\n",
        "            input_ids = input_ids.to(self.device, non_blocking=True)\n",
        "            attention_mask = attention_mask.to(self.device, non_blocking=True)\n",
        "            features = features.to(self.device, non_blocking=True)\n",
        "            target = target.to(self.device, non_blocking=True)\n",
        "\n",
        "            with autocast():\n",
        "                output = self.model(input_ids=input_ids, attention_mask=attention_mask, features=features)\n",
        "                loss = F.cross_entropy(output, target, label_smoothing=self.hyperparams[\"Label Smoothing\"])\n",
        "                loss = loss / accumulation_steps\n",
        "\n",
        "            self.scaler.scale(loss).backward()\n",
        "\n",
        "            if (batch_idx + 1) % accumulation_steps == 0 or (batch_idx + 1) == len(self.train_loader):\n",
        "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
        "                self.scaler.step(self.optimizer)\n",
        "                self.scaler.update()\n",
        "                self.optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "            total_loss += loss.item() * accumulation_steps\n",
        "            pred = output.argmax(dim=1)\n",
        "            correct += pred.eq(target).sum().item()\n",
        "            total += target.size(0)\n",
        "\n",
        "        self.scheduler.step()\n",
        "        return {'loss': total_loss / len(self.train_loader), 'acc': correct / total}\n",
        "\n",
        "    def validate(self):\n",
        "        torch.cuda.empty_cache()\n",
        "        self.model.eval()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (input_ids, attention_mask, features, target) in enumerate(tqdm(self.val_loader, desc=\"Validating\", leave=False)):\n",
        "                torch.cuda.empty_cache() # Empty cache after every batch\n",
        "                input_ids = input_ids.to(self.device, non_blocking=True)\n",
        "                attention_mask = attention_mask.to(self.device, non_blocking=True)\n",
        "                features = features.to(self.device, non_blocking=True)\n",
        "                target = target.to(self.device, non_blocking=True)\n",
        "\n",
        "                with autocast():\n",
        "                    output = self.model(input_ids=input_ids, attention_mask=attention_mask, features=features)\n",
        "                    loss = F.cross_entropy(output, target)\n",
        "\n",
        "                total_loss += loss.item()\n",
        "                pred = output.argmax(dim=1)\n",
        "                correct += pred.eq(target).sum().item()\n",
        "                total += target.size(0)\n",
        "\n",
        "            #Moved the start idx before as it was causing memory errors:\n",
        "            start_index = 0 #batch_idx * self.val_loader.batch_size\n",
        "            batch_size = self.val_loader.batch_size\n",
        "\n",
        "            end_index = len(self.val_texts)\n",
        "                # Get the text for the current batch\n",
        "\n",
        "            self.model.all_preds.extend(pred[:batch_size].cpu().numpy())\n",
        "            self.model.all_labels.extend(target[:batch_size].cpu().numpy())\n",
        "            self.model.all_texts.extend(self.val_texts[start_index:min(end_index, start_index + batch_size)])\n",
        "\n",
        "        return {'loss': total_loss / len(self.val_loader), 'acc': correct / total}\n",
        "\n",
        "    def perform_error_analysis(self):\n",
        "        # Generate classification report\n",
        "        report = classification_report(self.model.all_labels, self.model.all_preds, digits=4)\n",
        "        print(\"Classification Report:\\n\", report)\n",
        "\n",
        "        # Generate confusion matrix\n",
        "        cm = confusion_matrix(self.model.all_labels, self.model.all_preds)\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "        plt.xlabel('Predicted Labels')\n",
        "        plt.ylabel('True Labels')\n",
        "        plt.title('Confusion Matrix')\n",
        "        plt.show()\n",
        "\n",
        "        # Find misclassified texts\n",
        "        misclassified_indices = np.where(np.array(self.model.all_preds) != np.array(self.model.all_labels))[0]\n",
        "\n",
        "        print(\"\\nMisclassified Text Examples:\")\n",
        "        for idx in misclassified_indices[:5]:\n",
        "            print(f\"True Label: {self.model.all_labels[idx]}, Predicted Label: {self.model.all_preds[idx]}\")\n",
        "            print(f\"Text: {self.model.all_texts[idx]}\\n\")\n",
        "\n",
        "        # Explain the predictions using Captum\n",
        "\n",
        "\n",
        "    def explain_instance(self, text, true_label):\n",
        "        model = self.model  # Access the model via self\n",
        "        model.bert.eval()\n",
        "        model.bert.zero_grad()\n",
        "\n",
        "        encoding = tokenizer(text, add_special_tokens=True, return_tensors='pt')\n",
        "        input_ids = encoding.input_ids.to(self.device)\n",
        "        attention_mask = encoding.attention_mask.to(self.device)\n",
        "\n",
        "        def forward_func(input_ids, attention_mask):\n",
        "            with torch.no_grad():  # Very important: no gradients needed for attributions\n",
        "                bert_output = model.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "                pooled_output = bert_output.last_hidden_state[:, 0, :]\n",
        "                bert_projected = model.bert_projection(pooled_output)\n",
        "                return model.classifier(bert_projected)\n",
        "\n",
        "        lig = LayerIntegratedGradients(forward_func, model.bert.embeddings) #Very Important\n",
        "        try:\n",
        "            attributions, delta = lig.attribute(input_ids, #Input Ids instead of encoded tensors!\n",
        "                additional_forward_args=(attention_mask,),\n",
        "                target=int(true_label),#Target labels are of type tensor, not integer!\n",
        "                return_convergence_delta=True\n",
        "            )\n",
        "            attributions = attributions.sum(dim=-1).squeeze(0)\n",
        "            attributions = attributions / torch.norm(attributions)\n",
        "            attributions = attributions.cpu().detach().numpy()\n",
        "\n",
        "            tokens = tokenizer.convert_ids_to_tokens(input_ids[0].cpu().numpy())\n",
        "\n",
        "            print(f\"\\nText: {text}\")\n",
        "            print(f\"True Label: {true_label}\")\n",
        "            print(\"\\nToken Attribution Scores:\")\n",
        "            for token, attribution in zip(tokens, attributions):\n",
        "                if attribution != 0:\n",
        "                    print(f\"{token}: {attribution:.4f}\")\n",
        "            print(\"-\" * 80)\n",
        "        except Exception as e:\n",
        "            print(f\"Captum Explanations error{e}. Check model setup with dimensions. Skipping explanation!\")\n",
        "        return {\"tokens\": tokens, \"attributions\": attributions} #Captum now returns to here!\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=3, min_delta=0):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.best_loss = None\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, val_loss):\n",
        "        epsilon = 1e-6\n",
        "        if self.best_loss is None:\n",
        "            self.best_loss = val_loss\n",
        "        elif val_loss > self.best_loss - self.min_delta + epsilon:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                return True\n",
        "        else:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n",
        "        return False\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Load your DataFrame\n",
        "    df = pd.read_csv(\"/content/modified_df_11.csv\")\n",
        "\n",
        "    # Ensure 'text' column is string\n",
        "    df['text'] = df['text'].astype(str)\n",
        "\n",
        "    # Set name of text column\n",
        "    text_column = 'text'\n",
        "\n",
        "    # Extract labels\n",
        "    labels = np.array(df[\"rating\"].tolist()) - 1  # Adjust as needed\n",
        "\n",
        "    # Define hyperparameters\n",
        "    hyperparams = {\n",
        "        \"Epochs\": 1,  # Reduced for faster example\n",
        "        \"Batch Size\": 20,  # Reduced for faster example\n",
        "        \"Learning Rate\": 1e-5,\n",
        "        \"Dropout\": 0.3,\n",
        "        \"Weight Decay\": 0.1,\n",
        "        \"Label Smoothing\": 0.1,\n",
        "        \"Early Stopping Patience\": 3,\n",
        "        \"Gradient Accumulation Steps\": 4,\n",
        "        \"Optimizer\": \"AdamW\",\n",
        "        \"Scheduler\": \"OneCycleLR\",\n",
        "        \"Feature Dimension\": 0,\n",
        "        \"Model\": \"BERT with Multiple Embeddings\"\n",
        "    }\n",
        "\n",
        "    embedding_dir = \"my_embeddings\"\n",
        "\n",
        "    # Clear embedding directory\n",
        "    #if os.path.exists(embedding_dir):\n",
        "    #    shutil.rmtree(embedding_dir)\n",
        "\n",
        "    # Instantiate Trainer\n",
        "    trainer = GPUOptimizedTrainer(df, text_column, labels, hyperparams, embedding_dir=embedding_dir)\n",
        "    metrics = trainer.train()\n",
        "\n",
        "    # Print DataFrame\n",
        "\n",
        "    # Plot results\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(metrics['train_loss'], label='Train Loss')\n",
        "    plt.plot(metrics['val_loss'], label='Val Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(metrics['train_acc'], label='Train Acc')\n",
        "    plt.plot(metrics['val_acc'], label='Val Acc')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fL9mTak0uIbx"
      },
      "outputs": [],
      "source": [
        "!pip install captum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOK1dLXQuIdx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc3a1347-e9d1-41f2-e9be-9cc5bf352894"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "  warnings.warn(Warnings.W111)\n",
            "<ipython-input-7-53e2d621382a>:102: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = GradScaler()\n",
            "Training:   0%|          | 0/609 [00:00<?, ?it/s]<ipython-input-7-53e2d621382a>:383: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Validating:   0%|          | 0/77 [00:00<?, ?it/s]<ipython-input-7-53e2d621382a>:422: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Generating explanations: 100%|██████████| 500/500 [08:50<00:00,  1.06s/it]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import spacy\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import shutil\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from captum.attr import LayerIntegratedGradients\n",
        "import logging\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "    handlers=[logging.FileHandler('training.log'), logging.StreamHandler()]\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Initialize device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Initialize models\n",
        "nlp = spacy.load('en_core_web_sm', disable=['ner', 'parser', 'lemmatizer'])\n",
        "\n",
        "# Use a BERT model fine-tuned on Amazon reviews\n",
        "model_name = 'nlptown/bert-base-multilingual-uncased-sentiment'\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "bert_model = BertModel.from_pretrained(model_name).to(device)\n",
        "\n",
        "class RegularizedBERT(nn.Module):\n",
        "    def __init__(self, num_labels, feature_dim, hyperparams):\n",
        "        super().__init__()\n",
        "        self.bert = bert_model\n",
        "        self.dropout = nn.Dropout(hyperparams[\"Dropout\"])\n",
        "        self.feature_dim = feature_dim\n",
        "        self.bert_projection = nn.Linear(768, 384)\n",
        "        self.feature_projection = nn.Linear(feature_dim, 384) if feature_dim > 0 else None\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(384, 384),\n",
        "            nn.LayerNorm(384),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(hyperparams[\"Dropout\"]),\n",
        "            nn.Linear(384, num_labels)\n",
        "        )\n",
        "        self.all_preds = []\n",
        "        self.all_labels = []\n",
        "        self.all_texts = []\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, features=None):\n",
        "        bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = bert_output.last_hidden_state[:, 0, :]\n",
        "        bert_projected = self.bert_projection(pooled_output)\n",
        "\n",
        "        if features is not None and self.feature_dim > 0:\n",
        "            feature_projected = self.feature_projection(features)\n",
        "            combined_features = bert_projected + feature_projected\n",
        "        else:\n",
        "            combined_features = bert_projected\n",
        "\n",
        "        output = self.classifier(combined_features)\n",
        "        return output\n",
        "\n",
        "class GPUOptimizedTrainer:\n",
        "    def __init__(self, df, text_column, labels, hyperparams, embedding_dir=\"embeddings\"):\n",
        "        required_params = [\"Epochs\", \"Batch Size\", \"Learning Rate\", \"Dropout\", \"Weight Decay\",\n",
        "                         \"Label Smoothing\", \"Early Stopping Patience\", \"Gradient Accumulation Steps\"]\n",
        "        for param in required_params:\n",
        "            if param not in hyperparams:\n",
        "                raise ValueError(f\"Missing required hyperparameter: {param}\")\n",
        "\n",
        "        if hyperparams[\"Batch Size\"] <= 0:\n",
        "            raise ValueError(\"Batch Size must be positive\")\n",
        "        if not 0 <= hyperparams[\"Dropout\"] <= 1:\n",
        "            raise ValueError(f\"Dropout must be between 0 and 1\")\n",
        "\n",
        "        self.device = device\n",
        "        self.hyperparams = hyperparams\n",
        "        self.batch_size = hyperparams[\"Batch Size\"]\n",
        "        self.embedding_dir = embedding_dir\n",
        "        self.text_column = text_column\n",
        "\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "        torch.backends.cuda.matmul.allow_tf32 = True\n",
        "        torch.backends.cudnn.allow_tf32 = True\n",
        "\n",
        "        self.model = RegularizedBERT(\n",
        "            num_labels=5,\n",
        "            feature_dim=0,\n",
        "            hyperparams=hyperparams\n",
        "        ).to(self.device)\n",
        "\n",
        "        self.scaler = GradScaler()\n",
        "\n",
        "        # Initialize metrics\n",
        "        self.train_metrics = {\n",
        "            'loss': [],\n",
        "            'accuracy': [],\n",
        "            'grad_norm': [],\n",
        "            'layer_stats': []\n",
        "        }\n",
        "        self.val_metrics = {\n",
        "            'loss': [],\n",
        "            'accuracy': []\n",
        "        }\n",
        "\n",
        "        self.prepare_data(df, labels)\n",
        "        self.setup_training()\n",
        "\n",
        "    def extract_features(self, texts):\n",
        "        logger.info(\"Extracting features...\")\n",
        "        os.makedirs(self.embedding_dir, exist_ok=True)\n",
        "\n",
        "        bert_embedding_file = os.path.join(self.embedding_dir, \"bert_embeddings.npy\")\n",
        "        syntactic_feature_file = os.path.join(self.embedding_dir, \"syntactic_features.npy\")\n",
        "\n",
        "        if os.path.exists(bert_embedding_file) and os.path.exists(syntactic_feature_file):\n",
        "            logger.info(\"Loading embeddings from disk...\")\n",
        "            contextual_features = np.load(bert_embedding_file)\n",
        "            syntactic_features = np.load(syntactic_feature_file)\n",
        "            return np.hstack([contextual_features, syntactic_features])\n",
        "        else:\n",
        "            logger.info(\"Calculating and saving embeddings...\")\n",
        "\n",
        "            def extract_contextual(texts, batch_size=128):\n",
        "                features = []\n",
        "                for i in range(0, len(texts), batch_size):\n",
        "                    batch = [str(text).strip() for text in texts[i:i + batch_size] if pd.notna(text) and str(text).strip()]\n",
        "                    inputs = tokenizer(batch, padding=True, truncation=True, return_tensors=\"pt\").to(self.device)\n",
        "                    with torch.no_grad():\n",
        "                        outputs = bert_model(**inputs)\n",
        "                        embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
        "                    features.extend(embeddings)\n",
        "                return np.array(features)\n",
        "\n",
        "            def extract_syntactic(texts):\n",
        "                features = []\n",
        "                for text in texts:\n",
        "                    text = str(text).strip()\n",
        "                    if not text:\n",
        "                        features.append([0, 0, 0, 0])\n",
        "                        continue\n",
        "                    doc = nlp(text)\n",
        "                    pos_tags = [token.pos_ for token in doc]\n",
        "                    features.append([\n",
        "                        len(doc),\n",
        "                        len(set(pos_tags)) / max(len(pos_tags), 1),\n",
        "                        pos_tags.count('NOUN') / max(len(pos_tags), 1),\n",
        "                        pos_tags.count('VERB') / max(len(pos_tags), 1),\n",
        "                    ])\n",
        "                return np.array(features)\n",
        "\n",
        "            contextual_features = extract_contextual(texts)\n",
        "            syntactic_features = extract_syntactic(texts)\n",
        "\n",
        "            np.save(bert_embedding_file, contextual_features)\n",
        "            np.save(syntactic_feature_file, syntactic_features)\n",
        "            logger.info(\"Embeddings calculated and saved.\")\n",
        "            return np.array(np.hstack([contextual_features, syntactic_features]))\n",
        "\n",
        "    def prepare_data(self, df, labels, val_split=0.2):\n",
        "        logger.info(\"Preparing data...\")\n",
        "\n",
        "        texts = df[self.text_column].tolist()\n",
        "        valid_labels = []\n",
        "        valid_texts = []\n",
        "        valid_indices = []\n",
        "        for i, text in enumerate(texts):\n",
        "            text = str(text).strip()\n",
        "            if pd.notna(text) and text:\n",
        "                valid_texts.append(text)\n",
        "                valid_labels.append(labels[i])\n",
        "                valid_indices.append(i)\n",
        "\n",
        "        if len(valid_texts) < 2:\n",
        "            raise ValueError(\"Insufficient data for training. At least two valid texts are required.\")\n",
        "\n",
        "        # Truncate and pad sequences to max length\n",
        "        max_length = 512  # BERT's maximum sequence length\n",
        "        all_input_ids = []\n",
        "        all_attention_masks = []\n",
        "        all_labels = []\n",
        "        all_texts = []\n",
        "\n",
        "        logger.info(\"Processing texts into chunks...\")\n",
        "        for idx, text in enumerate(valid_texts):\n",
        "            # Tokenize with overflow handling\n",
        "            encoding = tokenizer(\n",
        "                text,\n",
        "                truncation=True,\n",
        "                padding='max_length',\n",
        "                max_length=max_length,\n",
        "                return_tensors='pt',\n",
        "                return_overflowing_tokens=True,\n",
        "                stride=128  # Use stride for overlapping chunks\n",
        "            )\n",
        "\n",
        "            # Handle multiple chunks if text is too long\n",
        "            num_chunks = encoding['input_ids'].size(0)\n",
        "            all_input_ids.append(encoding['input_ids'])\n",
        "            all_attention_masks.append(encoding['attention_mask'])\n",
        "            # Repeat label and text for each chunk\n",
        "            all_labels.extend([valid_labels[idx]] * num_chunks)\n",
        "            all_texts.extend([text] * num_chunks)\n",
        "\n",
        "        # Concatenate all tensors\n",
        "        input_ids = torch.cat(all_input_ids, dim=0)\n",
        "        attention_mask = torch.cat(all_attention_masks, dim=0)\n",
        "        logger.info(f\"Processed {len(valid_texts)} texts into {len(all_labels)} chunks\")\n",
        "\n",
        "        # Extract features for each chunk\n",
        "        features = self.extract_features(valid_texts)\n",
        "        # Repeat features for each chunk of the corresponding text\n",
        "        expanded_features = []\n",
        "        feature_idx = 0\n",
        "        for text_chunks in all_input_ids:\n",
        "            num_chunks = text_chunks.size(0)\n",
        "            expanded_features.extend([features[feature_idx]] * num_chunks)\n",
        "            feature_idx += 1\n",
        "        features = np.array(expanded_features)\n",
        "\n",
        "        if features.shape[0] != len(all_labels):\n",
        "            raise ValueError(f\"Feature extraction failed: Expected {len(all_labels)} rows, but got {features.shape[0]} rows.\")\n",
        "        if features.shape[0] < 2:\n",
        "            raise ValueError(\"Insufficient data for training. At least two valid chunks are required.\")\n",
        "\n",
        "        # Use stratified split on the chunked data\n",
        "        split_idx = int(len(all_labels) * (1 - val_split))\n",
        "        indices = np.random.permutation(len(all_labels))\n",
        "        train_idx = indices[:split_idx]\n",
        "        val_idx = indices[split_idx:]\n",
        "\n",
        "        scaler = StandardScaler()\n",
        "        train_features = scaler.fit_transform(features[train_idx])\n",
        "        val_features = scaler.transform(features[val_idx])\n",
        "\n",
        "        self.train_input_ids = input_ids[train_idx]\n",
        "        self.train_attention_mask = attention_mask[train_idx]\n",
        "        self.train_features = torch.tensor(train_features, dtype=torch.float32)\n",
        "        self.train_labels = torch.tensor(all_labels)[train_idx]\n",
        "        self.train_texts = [all_texts[i] for i in train_idx]\n",
        "\n",
        "        self.val_input_ids = input_ids[val_idx]\n",
        "        self.val_attention_mask = attention_mask[val_idx]\n",
        "        self.val_features = torch.tensor(val_features, dtype=torch.float32)\n",
        "        self.val_labels = torch.tensor(all_labels)[val_idx]\n",
        "        self.val_texts = [all_texts[i] for i in val_idx]\n",
        "\n",
        "        self.create_dataloaders()\n",
        "\n",
        "    def create_dataloaders(self):\n",
        "        train_dataset = TensorDataset(self.train_input_ids, self.train_attention_mask, self.train_features, self.train_labels)\n",
        "        val_dataset = TensorDataset(self.val_input_ids, self.val_attention_mask, self.val_features, self.val_labels)\n",
        "\n",
        "        self.train_loader = DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=True,\n",
        "            pin_memory=True,\n",
        "            num_workers=4,\n",
        "            prefetch_factor=3,\n",
        "            persistent_workers=True\n",
        "        )\n",
        "\n",
        "        val_batch_size = min(self.batch_size * 2, len(val_dataset))\n",
        "        self.val_loader = DataLoader(\n",
        "            val_dataset,\n",
        "            batch_size=val_batch_size,\n",
        "            pin_memory=True,\n",
        "            num_workers=4,\n",
        "            persistent_workers=True\n",
        "        )\n",
        "\n",
        "    def setup_training(self):\n",
        "        self.optimizer = torch.optim.AdamW(\n",
        "            self.model.parameters(),\n",
        "            lr=self.hyperparams[\"Learning Rate\"],\n",
        "            weight_decay=self.hyperparams[\"Weight Decay\"],\n",
        "            betas=(0.9, 0.999)\n",
        "        )\n",
        "\n",
        "        total_steps = (len(self.train_loader) // self.hyperparams[\"Gradient Accumulation Steps\"]) * self.hyperparams[\"Epochs\"]\n",
        "\n",
        "        self.scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "            self.optimizer,\n",
        "            max_lr=self.hyperparams[\"Learning Rate\"] * 10,\n",
        "            steps_per_epoch=len(self.train_loader) // self.hyperparams[\"Gradient Accumulation Steps\"],\n",
        "            epochs=self.hyperparams[\"Epochs\"],\n",
        "            pct_start=0.1\n",
        "        )\n",
        "\n",
        "        self.early_stopping = EarlyStopping(patience=self.hyperparams[\"Early Stopping Patience\"])\n",
        "\n",
        "    def train(self):\n",
        "        epochs = self.hyperparams[\"Epochs\"]\n",
        "        accumulation_steps = self.hyperparams[\"Gradient Accumulation Steps\"]\n",
        "\n",
        "        self.model.all_preds = []\n",
        "        self.model.all_labels = []\n",
        "        self.model.all_texts = []\n",
        "\n",
        "        best_val_loss = float('inf')\n",
        "        train_losses, val_losses = [], []\n",
        "        train_accs, val_accs = [], []\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            train_metrics = self.train_epoch(accumulation_steps)\n",
        "            val_metrics = self.validate()\n",
        "\n",
        "            train_losses.append(train_metrics['loss'])\n",
        "            val_losses.append(val_metrics['loss'])\n",
        "            train_accs.append(train_metrics['acc'])\n",
        "            val_accs.append(val_metrics['acc'])\n",
        "\n",
        "            logger.info(f\"Epoch {epoch+1}/{epochs}\")\n",
        "            logger.info(f\"Train Loss: {train_metrics['loss']:.4f}, Acc: {train_metrics['acc']:.4f}\")\n",
        "            logger.info(f\"Val Loss: {val_metrics['loss']:.4f}, Acc: {val_metrics['acc']:.4f}\")\n",
        "\n",
        "            if val_metrics['loss'] < best_val_loss:\n",
        "                best_val_loss = val_metrics['loss']\n",
        "                torch.save(self.model.state_dict(), 'best_model.pt')\n",
        "\n",
        "            if self.early_stopping(val_metrics['loss']):\n",
        "                logger.info(\"Early stopping triggered\")\n",
        "                break\n",
        "\n",
        "        # Plot final training curves\n",
        "        plt.figure(figsize=(15, 5))\n",
        "\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(train_losses, label='Train Loss')\n",
        "        plt.plot(val_losses, label='Val Loss')\n",
        "        plt.title('Training and Validation Loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(train_accs, label='Train Acc')\n",
        "        plt.plot(val_accs, label='Val Acc')\n",
        "        plt.title('Training and Validation Accuracy')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('training_curves.png')\n",
        "        plt.close()\n",
        "\n",
        "        self.perform_error_analysis()\n",
        "        return {\n",
        "            'train_loss': train_losses,\n",
        "            'val_loss': val_losses,\n",
        "            'train_acc': train_accs,\n",
        "            'val_acc': val_accs\n",
        "        }\n",
        "\n",
        "    def train_epoch(self, accumulation_steps):\n",
        "        torch.cuda.empty_cache()\n",
        "        self.model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for batch_idx, (input_ids, attention_mask, features, target) in enumerate(tqdm(self.train_loader, desc=\"Training\", leave=False)):\n",
        "            torch.cuda.empty_cache()\n",
        "            input_ids = input_ids.to(self.device, non_blocking=True)\n",
        "            attention_mask = attention_mask.to(self.device, non_blocking=True)\n",
        "            features = features.to(self.device, non_blocking=True)\n",
        "            target = target.to(self.device, non_blocking=True)\n",
        "\n",
        "            with autocast():\n",
        "                output = self.model(input_ids=input_ids, attention_mask=attention_mask, features=features)\n",
        "                loss = F.cross_entropy(output, target, label_smoothing=self.hyperparams[\"Label Smoothing\"])\n",
        "                loss = loss / accumulation_steps\n",
        "\n",
        "            self.scaler.scale(loss).backward()\n",
        "\n",
        "            if (batch_idx + 1) % accumulation_steps == 0 or (batch_idx + 1) == len(self.train_loader):\n",
        "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
        "                self.scaler.step(self.optimizer)\n",
        "                self.scaler.update()\n",
        "                self.optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "            total_loss += loss.item() * accumulation_steps\n",
        "            pred = output.argmax(dim=1)\n",
        "            correct += pred.eq(target).sum().item()\n",
        "            total += target.size(0)\n",
        "\n",
        "        self.scheduler.step()\n",
        "        return {'loss': total_loss / len(self.train_loader), 'acc': correct / total}\n",
        "\n",
        "    def validate(self):\n",
        "        torch.cuda.empty_cache()\n",
        "        self.model.eval()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "        all_texts = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (input_ids, attention_mask, features, target) in enumerate(tqdm(self.val_loader, desc=\"Validating\", leave=False)):\n",
        "                torch.cuda.empty_cache()\n",
        "                input_ids = input_ids.to(self.device, non_blocking=True)\n",
        "                attention_mask = attention_mask.to(self.device, non_blocking=True)\n",
        "                features = features.to(self.device, non_blocking=True)\n",
        "                target = target.to(self.device, non_blocking=True)\n",
        "\n",
        "                with autocast():\n",
        "                    output = self.model(input_ids=input_ids, attention_mask=attention_mask, features=features)\n",
        "                    loss = F.cross_entropy(output, target)\n",
        "\n",
        "                total_loss += loss.item()\n",
        "                pred = output.argmax(dim=1)\n",
        "                correct += pred.eq(target).sum().item()\n",
        "                total += target.size(0)\n",
        "\n",
        "                all_preds.extend(pred.cpu().numpy())\n",
        "                all_labels.extend(target.cpu().numpy())\n",
        "                start_idx = batch_idx * self.val_loader.batch_size\n",
        "                end_idx = min((batch_idx + 1) * self.val_loader.batch_size, len(self.val_texts))\n",
        "                all_texts.extend(self.val_texts[start_idx:end_idx])\n",
        "\n",
        "        self.model.all_preds = all_preds\n",
        "        self.model.all_labels = all_labels\n",
        "        self.model.all_texts = all_texts\n",
        "\n",
        "        return {'loss': total_loss / len(self.val_loader), 'acc': correct / total}\n",
        "\n",
        "    def perform_error_analysis(self):\n",
        "        report = classification_report(self.model.all_labels, self.model.all_preds, digits=4)\n",
        "        with open('classification_report.txt', 'w') as f:\n",
        "            f.write(report)\n",
        "        logger.info(\"Classification report saved to classification_report.txt\")\n",
        "\n",
        "        cm = confusion_matrix(self.model.all_labels, self.model.all_preds)\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                   xticklabels=['0', '1', '2', '3', '4'],\n",
        "                   yticklabels=['0', '1', '2', '3', '4'])\n",
        "        plt.xlabel('Predicted Labels')\n",
        "        plt.ylabel('True Labels')\n",
        "        plt.title('Confusion Matrix')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('confusion_matrix.png')\n",
        "        plt.close()\n",
        "\n",
        "        misclassified_indices = np.where(np.array(self.model.all_preds) != np.array(self.model.all_labels))[0]\n",
        "        misclassified_df = pd.DataFrame({\n",
        "            'text': [self.model.all_texts[i] for i in misclassified_indices],\n",
        "            'true_label': [self.model.all_labels[i] for i in misclassified_indices],\n",
        "            'predicted_label': [self.model.all_preds[i] for i in misclassified_indices]\n",
        "        })\n",
        "        misclassified_df.to_csv('misclassified_examples.csv', index=False)\n",
        "\n",
        "        self.output_classifications_to_csv()\n",
        "\n",
        "    def output_classifications_to_csv(self):\n",
        "        results = []\n",
        "\n",
        "        # Group examples by true label\n",
        "        label_indices = {}\n",
        "        for idx in range(len(self.model.all_texts)):\n",
        "            true_label = self.model.all_labels[idx]\n",
        "            if true_label not in label_indices:\n",
        "                label_indices[true_label] = []\n",
        "            label_indices[true_label].append(idx)\n",
        "\n",
        "        # Sample up to 100 examples per rating\n",
        "        selected_indices = []\n",
        "        for label in label_indices:\n",
        "            indices = label_indices[label]\n",
        "            if len(indices) > 100:\n",
        "                selected_indices.extend(np.random.choice(indices, 100, replace=False))\n",
        "            else:\n",
        "                selected_indices.extend(indices)\n",
        "\n",
        "        logger.info(f\"Processing {len(selected_indices)} examples for Captum analysis\")\n",
        "\n",
        "        # Process selected examples\n",
        "        for idx in tqdm(selected_indices, desc=\"Generating explanations\"):\n",
        "            text = self.model.all_texts[idx]\n",
        "            true_label = self.model.all_labels[idx]\n",
        "            pred_label = self.model.all_preds[idx]\n",
        "\n",
        "            try:\n",
        "                explanation = self.explain_instance(text, true_label)\n",
        "\n",
        "                result = {\n",
        "                    'text': text,\n",
        "                    'true_label': true_label,\n",
        "                    'predicted_label': pred_label,\n",
        "                    'correct_classification': true_label == pred_label,\n",
        "                    'captum_success': len(explanation['tokens']) > 0\n",
        "                }\n",
        "\n",
        "                if result['captum_success']:\n",
        "                    for token, attribution in zip(explanation['tokens'], explanation['attributions']):\n",
        "                        result[f'token_{token}'] = attribution\n",
        "                else:\n",
        "                    result['explanation_error'] = 'Captum attribution failed'\n",
        "\n",
        "                results.append(result)\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error processing instance {idx}: {e}\")\n",
        "                results.append({\n",
        "                    'text': text,\n",
        "                    'true_label': true_label,\n",
        "                    'predicted_label': pred_label,\n",
        "                    'correct_classification': true_label == pred_label,\n",
        "                    'captum_success': False,\n",
        "                    'explanation_error': str(e)\n",
        "                })\n",
        "\n",
        "        df = pd.DataFrame(results)\n",
        "        df.to_csv('classification_analysis.csv', index=False)\n",
        "\n",
        "        misclassified_df = df[df['correct_classification'] == False]\n",
        "        if not misclassified_df.empty:\n",
        "            misclassified_df.to_csv('misclassified_analysis.csv', index=False)\n",
        "\n",
        "        logger.info(\"Analysis saved to classification_analysis.csv and misclassified_analysis.csv\")\n",
        "\n",
        "    def explain_instance(self, text, true_label):\n",
        "        self.model.eval()\n",
        "        self.model.zero_grad()\n",
        "\n",
        "        # Tokenize text with truncation and move to device without requiring gradients\n",
        "        encoding = tokenizer(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            truncation=True,\n",
        "            max_length=512,  # BERT's maximum sequence length\n",
        "            padding='max_length',\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        input_ids = encoding.input_ids.to(self.device)\n",
        "        attention_mask = encoding.attention_mask.to(self.device)\n",
        "\n",
        "        # Define forward function without modifying input gradients\n",
        "        def forward_func(inputs, attention_mask):\n",
        "            bert_output = self.model.bert(input_ids=inputs, attention_mask=attention_mask)\n",
        "            pooled_output = bert_output.last_hidden_state[:, 0, :]\n",
        "            bert_projected = self.model.bert_projection(pooled_output)\n",
        "            logits = self.model.classifier(bert_projected)\n",
        "            return logits\n",
        "\n",
        "        # Initialize LayerIntegratedGradients with embeddings layer\n",
        "        lig = LayerIntegratedGradients(forward_func, self.model.bert.embeddings.word_embeddings)\n",
        "\n",
        "        try:\n",
        "            # Compute attributions\n",
        "            attributions, delta = lig.attribute(\n",
        "                inputs=input_ids,\n",
        "                additional_forward_args=(attention_mask,),\n",
        "                target=int(true_label),\n",
        "                return_convergence_delta=True,\n",
        "                n_steps=50,\n",
        "                internal_batch_size=1\n",
        "            )\n",
        "\n",
        "            # Process attributions\n",
        "            attributions = attributions.sum(dim=-1).squeeze(0)\n",
        "            attributions = attributions / torch.norm(attributions)\n",
        "            attributions = attributions.cpu().detach().numpy()\n",
        "            tokens = tokenizer.convert_ids_to_tokens(input_ids[0].cpu().numpy())\n",
        "            return {\"tokens\": tokens, \"attributions\": attributions}\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Captum Explanations error: {e}\")\n",
        "            return {\"tokens\": [], \"attributions\": []}\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=3, min_delta=0):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.best_loss = None\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, val_loss):\n",
        "        epsilon = 1e-6\n",
        "        if self.best_loss is None:\n",
        "            self.best_loss = val_loss\n",
        "        elif val_loss > self.best_loss - self.min_delta + epsilon:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                return True\n",
        "        else:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n",
        "        return False\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    df = pd.read_csv(\"sample.csv\")\n",
        "    df['text'] = df['text'].astype(str)\n",
        "    text_column = 'text'\n",
        "    labels = np.array(df[\"rating\"].tolist()) - 1\n",
        "\n",
        "    hyperparams = {\n",
        "        \"Epochs\": 1,\n",
        "        \"Batch Size\": 20,\n",
        "        \"Learning Rate\": 1e-5,\n",
        "        \"Dropout\": 0.3,\n",
        "        \"Weight Decay\": 0.1,\n",
        "        \"Label Smoothing\": 0.1,\n",
        "        \"Early Stopping Patience\": 3,\n",
        "        \"Gradient Accumulation Steps\": 4,\n",
        "        \"Optimizer\": \"AdamW\",\n",
        "        \"Scheduler\": \"OneCycleLR\",\n",
        "        \"Feature Dimension\": 0,\n",
        "        \"Model\": \"BERT with Multiple Embeddings\"\n",
        "    }\n",
        "\n",
        "    embedding_dir = \"embeddings\"\n",
        "    trainer = GPUOptimizedTrainer(df, text_column, labels, hyperparams, embedding_dir=embedding_dir)\n",
        "    metrics = trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "En5nT2kAuIfa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5T7ZoqN7uIhS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8401f29-2a06-43cb-840e-15ebf29e0bfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "  warnings.warn(Warnings.W111)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing rating 0...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-b47b4e680da0>:102: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = GradScaler()\n",
            "Rating 0: 100%|██████████| 100/100 [01:45<00:00,  1.05s/it]\n",
            "<ipython-input-8-b47b4e680da0>:102: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = GradScaler()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing rating 1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Rating 1: 100%|██████████| 100/100 [01:44<00:00,  1.04s/it]\n",
            "<ipython-input-8-b47b4e680da0>:102: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = GradScaler()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing rating 2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Rating 2: 100%|██████████| 100/100 [01:44<00:00,  1.05s/it]\n",
            "<ipython-input-8-b47b4e680da0>:102: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = GradScaler()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing rating 3...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Rating 3: 100%|██████████| 100/100 [01:44<00:00,  1.04s/it]\n",
            "<ipython-input-8-b47b4e680da0>:102: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = GradScaler()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing rating 4...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Rating 4: 100%|██████████| 100/100 [01:44<00:00,  1.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Analysis saved to word_weights_analysis.csv\n",
            "Total examples analyzed: 500\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import spacy\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import shutil\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from captum.attr import LayerIntegratedGradients\n",
        "import logging\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "    handlers=[logging.FileHandler('training.log'), logging.StreamHandler()]\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Initialize device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Initialize models\n",
        "nlp = spacy.load('en_core_web_sm', disable=['ner', 'parser', 'lemmatizer'])\n",
        "\n",
        "# Use a BERT model fine-tuned on Amazon reviews\n",
        "model_name = 'nlptown/bert-base-multilingual-uncased-sentiment'\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "bert_model = BertModel.from_pretrained(model_name).to(device)\n",
        "\n",
        "class RegularizedBERT(nn.Module):\n",
        "    def __init__(self, num_labels, feature_dim, hyperparams):\n",
        "        super().__init__()\n",
        "        self.bert = bert_model\n",
        "        self.dropout = nn.Dropout(hyperparams[\"Dropout\"])\n",
        "        self.feature_dim = feature_dim\n",
        "        self.bert_projection = nn.Linear(768, 384)\n",
        "        self.feature_projection = nn.Linear(feature_dim, 384) if feature_dim > 0 else None\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(384, 384),\n",
        "            nn.LayerNorm(384),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(hyperparams[\"Dropout\"]),\n",
        "            nn.Linear(384, num_labels)\n",
        "        )\n",
        "        self.all_preds = []\n",
        "        self.all_labels = []\n",
        "        self.all_texts = []\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, features=None):\n",
        "        bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = bert_output.last_hidden_state[:, 0, :]\n",
        "        bert_projected = self.bert_projection(pooled_output)\n",
        "\n",
        "        if features is not None and self.feature_dim > 0:\n",
        "            feature_projected = self.feature_projection(features)\n",
        "            combined_features = bert_projected + feature_projected\n",
        "        else:\n",
        "            combined_features = bert_projected\n",
        "\n",
        "        output = self.classifier(combined_features)\n",
        "        return output\n",
        "\n",
        "class GPUOptimizedTrainer:\n",
        "    def __init__(self, df, text_column, labels, hyperparams, embedding_dir=\"embeddings\"):\n",
        "        required_params = [\"Epochs\", \"Batch Size\", \"Learning Rate\", \"Dropout\", \"Weight Decay\",\n",
        "                         \"Label Smoothing\", \"Early Stopping Patience\", \"Gradient Accumulation Steps\"]\n",
        "        for param in required_params:\n",
        "            if param not in hyperparams:\n",
        "                raise ValueError(f\"Missing required hyperparameter: {param}\")\n",
        "\n",
        "        if hyperparams[\"Batch Size\"] <= 0:\n",
        "            raise ValueError(\"Batch Size must be positive\")\n",
        "        if not 0 <= hyperparams[\"Dropout\"] <= 1:\n",
        "            raise ValueError(f\"Dropout must be between 0 and 1\")\n",
        "\n",
        "        self.device = device\n",
        "        self.hyperparams = hyperparams\n",
        "        self.batch_size = hyperparams[\"Batch Size\"]\n",
        "        self.embedding_dir = embedding_dir\n",
        "        self.text_column = text_column\n",
        "\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "        torch.backends.cuda.matmul.allow_tf32 = True\n",
        "        torch.backends.cudnn.allow_tf32 = True\n",
        "\n",
        "        self.model = RegularizedBERT(\n",
        "            num_labels=5,\n",
        "            feature_dim=0,\n",
        "            hyperparams=hyperparams\n",
        "        ).to(self.device)\n",
        "\n",
        "        self.scaler = GradScaler()\n",
        "\n",
        "        # Initialize metrics\n",
        "        self.train_metrics = {\n",
        "            'loss': [],\n",
        "            'accuracy': [],\n",
        "            'grad_norm': [],\n",
        "            'layer_stats': []\n",
        "        }\n",
        "        self.val_metrics = {\n",
        "            'loss': [],\n",
        "            'accuracy': []\n",
        "        }\n",
        "\n",
        "        self.prepare_data(df, labels)\n",
        "        self.setup_training()\n",
        "\n",
        "    def extract_features(self, texts):\n",
        "        logger.info(\"Extracting features...\")\n",
        "        os.makedirs(self.embedding_dir, exist_ok=True)\n",
        "\n",
        "        bert_embedding_file = os.path.join(self.embedding_dir, \"bert_embeddings.npy\")\n",
        "        syntactic_feature_file = os.path.join(self.embedding_dir, \"syntactic_features.npy\")\n",
        "\n",
        "        if os.path.exists(bert_embedding_file) and os.path.exists(syntactic_feature_file):\n",
        "            logger.info(\"Loading embeddings from disk...\")\n",
        "            contextual_features = np.load(bert_embedding_file)\n",
        "            syntactic_features = np.load(syntactic_feature_file)\n",
        "            return np.hstack([contextual_features, syntactic_features])\n",
        "        else:\n",
        "            logger.info(\"Calculating and saving embeddings...\")\n",
        "\n",
        "            def extract_contextual(texts, batch_size=128):\n",
        "                features = []\n",
        "                for i in range(0, len(texts), batch_size):\n",
        "                    batch = [str(text).strip() for text in texts[i:i + batch_size] if pd.notna(text) and str(text).strip()]\n",
        "                    inputs = tokenizer(batch, padding=True, truncation=True, return_tensors=\"pt\").to(self.device)\n",
        "                    with torch.no_grad():\n",
        "                        outputs = bert_model(**inputs)\n",
        "                        embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
        "                    features.extend(embeddings)\n",
        "                return np.array(features)\n",
        "\n",
        "            def extract_syntactic(texts):\n",
        "                features = []\n",
        "                for text in texts:\n",
        "                    text = str(text).strip()\n",
        "                    if not text:\n",
        "                        features.append([0, 0, 0, 0])\n",
        "                        continue\n",
        "                    doc = nlp(text)\n",
        "                    pos_tags = [token.pos_ for token in doc]\n",
        "                    features.append([\n",
        "                        len(doc),\n",
        "                        len(set(pos_tags)) / max(len(pos_tags), 1),\n",
        "                        pos_tags.count('NOUN') / max(len(pos_tags), 1),\n",
        "                        pos_tags.count('VERB') / max(len(pos_tags), 1),\n",
        "                    ])\n",
        "                return np.array(features)\n",
        "\n",
        "            contextual_features = extract_contextual(texts)\n",
        "            syntactic_features = extract_syntactic(texts)\n",
        "\n",
        "            np.save(bert_embedding_file, contextual_features)\n",
        "            np.save(syntactic_feature_file, syntactic_features)\n",
        "            logger.info(\"Embeddings calculated and saved.\")\n",
        "            return np.array(np.hstack([contextual_features, syntactic_features]))\n",
        "\n",
        "    def prepare_data(self, df, labels, val_split=0.2):\n",
        "        logger.info(\"Preparing data...\")\n",
        "\n",
        "        texts = df[self.text_column].tolist()\n",
        "        valid_labels = []\n",
        "        valid_texts = []\n",
        "        valid_indices = []\n",
        "        for i, text in enumerate(texts):\n",
        "            text = str(text).strip()\n",
        "            if pd.notna(text) and text:\n",
        "                valid_texts.append(text)\n",
        "                valid_labels.append(labels[i])\n",
        "                valid_indices.append(i)\n",
        "\n",
        "        if len(valid_texts) < 2:\n",
        "            raise ValueError(\"Insufficient data for training. At least two valid texts are required.\")\n",
        "\n",
        "        # Truncate and pad sequences to max length\n",
        "        max_length = 512  # BERT's maximum sequence length\n",
        "        all_input_ids = []\n",
        "        all_attention_masks = []\n",
        "        all_labels = []\n",
        "        all_texts = []\n",
        "\n",
        "        logger.info(\"Processing texts into chunks...\")\n",
        "        for idx, text in enumerate(valid_texts):\n",
        "            # Tokenize with overflow handling\n",
        "            encoding = tokenizer(\n",
        "                text,\n",
        "                truncation=True,\n",
        "                padding='max_length',\n",
        "                max_length=max_length,\n",
        "                return_tensors='pt',\n",
        "                return_overflowing_tokens=True,\n",
        "                stride=128  # Use stride for overlapping chunks\n",
        "            )\n",
        "\n",
        "            # Handle multiple chunks if text is too long\n",
        "            num_chunks = encoding['input_ids'].size(0)\n",
        "            all_input_ids.append(encoding['input_ids'])\n",
        "            all_attention_masks.append(encoding['attention_mask'])\n",
        "            # Repeat label and text for each chunk\n",
        "            all_labels.extend([valid_labels[idx]] * num_chunks)\n",
        "            all_texts.extend([text] * num_chunks)\n",
        "\n",
        "        # Concatenate all tensors\n",
        "        input_ids = torch.cat(all_input_ids, dim=0)\n",
        "        attention_mask = torch.cat(all_attention_masks, dim=0)\n",
        "        logger.info(f\"Processed {len(valid_texts)} texts into {len(all_labels)} chunks\")\n",
        "\n",
        "        # Extract features for each chunk\n",
        "        features = self.extract_features(valid_texts)\n",
        "        # Repeat features for each chunk of the corresponding text\n",
        "        expanded_features = []\n",
        "        feature_idx = 0\n",
        "        for text_chunks in all_input_ids:\n",
        "            num_chunks = text_chunks.size(0)\n",
        "            expanded_features.extend([features[feature_idx]] * num_chunks)\n",
        "            feature_idx += 1\n",
        "        features = np.array(expanded_features)\n",
        "\n",
        "        if features.shape[0] != len(all_labels):\n",
        "            raise ValueError(f\"Feature extraction failed: Expected {len(all_labels)} rows, but got {features.shape[0]} rows.\")\n",
        "        if features.shape[0] < 2:\n",
        "            raise ValueError(\"Insufficient data for training. At least two valid chunks are required.\")\n",
        "\n",
        "        # Use stratified split on the chunked data\n",
        "        split_idx = int(len(all_labels) * (1 - val_split))\n",
        "        indices = np.random.permutation(len(all_labels))\n",
        "        train_idx = indices[:split_idx]\n",
        "        val_idx = indices[split_idx:]\n",
        "\n",
        "        scaler = StandardScaler()\n",
        "        train_features = scaler.fit_transform(features[train_idx])\n",
        "        val_features = scaler.transform(features[val_idx])\n",
        "\n",
        "        self.train_input_ids = input_ids[train_idx]\n",
        "        self.train_attention_mask = attention_mask[train_idx]\n",
        "        self.train_features = torch.tensor(train_features, dtype=torch.float32)\n",
        "        self.train_labels = torch.tensor(all_labels)[train_idx]\n",
        "        self.train_texts = [all_texts[i] for i in train_idx]\n",
        "\n",
        "        self.val_input_ids = input_ids[val_idx]\n",
        "        self.val_attention_mask = attention_mask[val_idx]\n",
        "        self.val_features = torch.tensor(val_features, dtype=torch.float32)\n",
        "        self.val_labels = torch.tensor(all_labels)[val_idx]\n",
        "        self.val_texts = [all_texts[i] for i in val_idx]\n",
        "\n",
        "        self.create_dataloaders()\n",
        "\n",
        "    def create_dataloaders(self):\n",
        "        train_dataset = TensorDataset(self.train_input_ids, self.train_attention_mask, self.train_features, self.train_labels)\n",
        "        val_dataset = TensorDataset(self.val_input_ids, self.val_attention_mask, self.val_features, self.val_labels)\n",
        "\n",
        "        self.train_loader = DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=True,\n",
        "            pin_memory=True,\n",
        "            num_workers=4,\n",
        "            prefetch_factor=3,\n",
        "            persistent_workers=True\n",
        "        )\n",
        "\n",
        "        val_batch_size = min(self.batch_size * 2, len(val_dataset))\n",
        "        self.val_loader = DataLoader(\n",
        "            val_dataset,\n",
        "            batch_size=val_batch_size,\n",
        "            pin_memory=True,\n",
        "            num_workers=4,\n",
        "            persistent_workers=True\n",
        "        )\n",
        "\n",
        "    def setup_training(self):\n",
        "        self.optimizer = torch.optim.AdamW(\n",
        "            self.model.parameters(),\n",
        "            lr=self.hyperparams[\"Learning Rate\"],\n",
        "            weight_decay=self.hyperparams[\"Weight Decay\"],\n",
        "            betas=(0.9, 0.999)\n",
        "        )\n",
        "\n",
        "        total_steps = (len(self.train_loader) // self.hyperparams[\"Gradient Accumulation Steps\"]) * self.hyperparams[\"Epochs\"]\n",
        "\n",
        "        self.scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "            self.optimizer,\n",
        "            max_lr=self.hyperparams[\"Learning Rate\"] * 10,\n",
        "            steps_per_epoch=len(self.train_loader) // self.hyperparams[\"Gradient Accumulation Steps\"],\n",
        "            epochs=self.hyperparams[\"Epochs\"],\n",
        "            pct_start=0.1\n",
        "        )\n",
        "\n",
        "        self.early_stopping = EarlyStopping(patience=self.hyperparams[\"Early Stopping Patience\"])\n",
        "\n",
        "    def train(self):\n",
        "        epochs = self.hyperparams[\"Epochs\"]\n",
        "        accumulation_steps = self.hyperparams[\"Gradient Accumulation Steps\"]\n",
        "\n",
        "        self.model.all_preds = []\n",
        "        self.model.all_labels = []\n",
        "        self.model.all_texts = []\n",
        "\n",
        "        best_val_loss = float('inf')\n",
        "        train_losses, val_losses = [], []\n",
        "        train_accs, val_accs = [], []\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            train_metrics = self.train_epoch(accumulation_steps)\n",
        "            val_metrics = self.validate()\n",
        "\n",
        "            train_losses.append(train_metrics['loss'])\n",
        "            val_losses.append(val_metrics['loss'])\n",
        "            train_accs.append(train_metrics['acc'])\n",
        "            val_accs.append(val_metrics['acc'])\n",
        "\n",
        "            logger.info(f\"Epoch {epoch+1}/{epochs}\")\n",
        "            logger.info(f\"Train Loss: {train_metrics['loss']:.4f}, Acc: {train_metrics['acc']:.4f}\")\n",
        "            logger.info(f\"Val Loss: {val_metrics['loss']:.4f}, Acc: {val_metrics['acc']:.4f}\")\n",
        "\n",
        "            if val_metrics['loss'] < best_val_loss:\n",
        "                best_val_loss = val_metrics['loss']\n",
        "                torch.save(self.model.state_dict(), 'best_model.pt')\n",
        "\n",
        "            if self.early_stopping(val_metrics['loss']):\n",
        "                logger.info(\"Early stopping triggered\")\n",
        "                break\n",
        "\n",
        "        # Plot final training curves\n",
        "        plt.figure(figsize=(15, 5))\n",
        "\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(train_losses, label='Train Loss')\n",
        "        plt.plot(val_losses, label='Val Loss')\n",
        "        plt.title('Training and Validation Loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(train_accs, label='Train Acc')\n",
        "        plt.plot(val_accs, label='Val Acc')\n",
        "        plt.title('Training and Validation Accuracy')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('training_curves.png')\n",
        "        plt.close()\n",
        "\n",
        "        self.perform_error_analysis()\n",
        "        return {\n",
        "            'train_loss': train_losses,\n",
        "            'val_loss': val_losses,\n",
        "            'train_acc': train_accs,\n",
        "            'val_acc': val_accs\n",
        "        }\n",
        "\n",
        "    def train_epoch(self, accumulation_steps):\n",
        "        torch.cuda.empty_cache()\n",
        "        self.model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for batch_idx, (input_ids, attention_mask, features, target) in enumerate(tqdm(self.train_loader, desc=\"Training\", leave=False)):\n",
        "            torch.cuda.empty_cache()\n",
        "            input_ids = input_ids.to(self.device, non_blocking=True)\n",
        "            attention_mask = attention_mask.to(self.device, non_blocking=True)\n",
        "            features = features.to(self.device, non_blocking=True)\n",
        "            target = target.to(self.device, non_blocking=True)\n",
        "\n",
        "            with autocast():\n",
        "                output = self.model(input_ids=input_ids, attention_mask=attention_mask, features=features)\n",
        "                loss = F.cross_entropy(output, target, label_smoothing=self.hyperparams[\"Label Smoothing\"])\n",
        "                loss = loss / accumulation_steps\n",
        "\n",
        "            self.scaler.scale(loss).backward()\n",
        "\n",
        "            if (batch_idx + 1) % accumulation_steps == 0 or (batch_idx + 1) == len(self.train_loader):\n",
        "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
        "                self.scaler.step(self.optimizer)\n",
        "                self.scaler.update()\n",
        "                self.optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "            total_loss += loss.item() * accumulation_steps\n",
        "            pred = output.argmax(dim=1)\n",
        "            correct += pred.eq(target).sum().item()\n",
        "            total += target.size(0)\n",
        "\n",
        "        self.scheduler.step()\n",
        "        return {'loss': total_loss / len(self.train_loader), 'acc': correct / total}\n",
        "\n",
        "    def validate(self):\n",
        "        torch.cuda.empty_cache()\n",
        "        self.model.eval()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "        all_texts = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (input_ids, attention_mask, features, target) in enumerate(tqdm(self.val_loader, desc=\"Validating\", leave=False)):\n",
        "                torch.cuda.empty_cache()\n",
        "                input_ids = input_ids.to(self.device, non_blocking=True)\n",
        "                attention_mask = attention_mask.to(self.device, non_blocking=True)\n",
        "                features = features.to(self.device, non_blocking=True)\n",
        "                target = target.to(self.device, non_blocking=True)\n",
        "\n",
        "                with autocast():\n",
        "                    output = self.model(input_ids=input_ids, attention_mask=attention_mask, features=features)\n",
        "                    loss = F.cross_entropy(output, target)\n",
        "\n",
        "                total_loss += loss.item()\n",
        "                pred = output.argmax(dim=1)\n",
        "                correct += pred.eq(target).sum().item()\n",
        "                total += target.size(0)\n",
        "\n",
        "                all_preds.extend(pred.cpu().numpy())\n",
        "                all_labels.extend(target.cpu().numpy())\n",
        "                start_idx = batch_idx * self.val_loader.batch_size\n",
        "                end_idx = min((batch_idx + 1) * self.val_loader.batch_size, len(self.val_texts))\n",
        "                all_texts.extend(self.val_texts[start_idx:end_idx])\n",
        "\n",
        "        self.model.all_preds = all_preds\n",
        "        self.model.all_labels = all_labels\n",
        "        self.model.all_texts = all_texts\n",
        "\n",
        "        return {'loss': total_loss / len(self.val_loader), 'acc': correct / total}\n",
        "\n",
        "    def perform_error_analysis(self):\n",
        "        report = classification_report(self.model.all_labels, self.model.all_preds, digits=4)\n",
        "        with open('classification_report.txt', 'w') as f:\n",
        "            f.write(report)\n",
        "        logger.info(\"Classification report saved to classification_report.txt\")\n",
        "\n",
        "        cm = confusion_matrix(self.model.all_labels, self.model.all_preds)\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                   xticklabels=['0', '1', '2', '3', '4'],\n",
        "                   yticklabels=['0', '1', '2', '3', '4'])\n",
        "        plt.xlabel('Predicted Labels')\n",
        "        plt.ylabel('True Labels')\n",
        "        plt.title('Confusion Matrix')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('confusion_matrix.png')\n",
        "        plt.close()\n",
        "\n",
        "        misclassified_indices = np.where(np.array(self.model.all_preds) != np.array(self.model.all_labels))[0]\n",
        "        misclassified_df = pd.DataFrame({\n",
        "            'text': [self.model.all_texts[i] for i in misclassified_indices],\n",
        "            'true_label': [self.model.all_labels[i] for i in misclassified_indices],\n",
        "            'predicted_label': [self.model.all_preds[i] for i in misclassified_indices]\n",
        "        })\n",
        "        misclassified_df.to_csv('misclassified_examples.csv', index=False)\n",
        "\n",
        "        self.output_classifications_to_csv()\n",
        "\n",
        "    def output_classifications_to_csv(self):\n",
        "        results = []\n",
        "\n",
        "        # Group examples by true label\n",
        "        label_indices = {}\n",
        "        for idx in range(len(self.model.all_texts)):\n",
        "            true_label = self.model.all_labels[idx]\n",
        "            if true_label not in label_indices:\n",
        "                label_indices[true_label] = []\n",
        "            label_indices[true_label].append(idx)\n",
        "\n",
        "        # Sample up to 100 examples per rating\n",
        "        selected_indices = []\n",
        "        for label in label_indices:\n",
        "            indices = label_indices[label]\n",
        "            if len(indices) > 100:\n",
        "                selected_indices.extend(np.random.choice(indices, 100, replace=False))\n",
        "            else:\n",
        "                selected_indices.extend(indices)\n",
        "\n",
        "        logger.info(f\"Processing {len(selected_indices)} examples for Captum analysis\")\n",
        "\n",
        "        # Process selected examples\n",
        "        for idx in tqdm(selected_indices, desc=\"Generating explanations\"):\n",
        "            text = self.model.all_texts[idx]\n",
        "            true_label = self.model.all_labels[idx]\n",
        "            pred_label = self.model.all_preds[idx]\n",
        "\n",
        "            try:\n",
        "                explanation = self.explain_instance(text, true_label)\n",
        "\n",
        "                result = {\n",
        "                    'text': text,\n",
        "                    'true_label': true_label,\n",
        "                    'predicted_label': pred_label,\n",
        "                    'correct_classification': true_label == pred_label,\n",
        "                    'captum_success': len(explanation['tokens']) > 0\n",
        "                }\n",
        "\n",
        "                if result['captum_success']:\n",
        "                    for token, attribution in zip(explanation['tokens'], explanation['attributions']):\n",
        "                        result[f'token_{token}'] = attribution\n",
        "                else:\n",
        "                    result['explanation_error'] = 'Captum attribution failed'\n",
        "\n",
        "                results.append(result)\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error processing instance {idx}: {e}\")\n",
        "                results.append({\n",
        "                    'text': text,\n",
        "                    'true_label': true_label,\n",
        "                    'predicted_label': pred_label,\n",
        "                    'correct_classification': true_label == pred_label,\n",
        "                    'captum_success': False,\n",
        "                    'explanation_error': str(e)\n",
        "                })\n",
        "\n",
        "        df = pd.DataFrame(results)\n",
        "        df.to_csv('classification_analysis.csv', index=False)\n",
        "\n",
        "        misclassified_df = df[df['correct_classification'] == False]\n",
        "        if not misclassified_df.empty:\n",
        "            misclassified_df.to_csv('misclassified_analysis.csv', index=False)\n",
        "\n",
        "        logger.info(\"Analysis saved to classification_analysis.csv and misclassified_analysis.csv\")\n",
        "\n",
        "    def explain_instance(self, text, true_label, print_weights=False):\n",
        "        self.model.eval()\n",
        "        self.model.zero_grad()\n",
        "\n",
        "        # Tokenize text with truncation and move to device without requiring gradients\n",
        "        encoding = tokenizer(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            truncation=True,\n",
        "            max_length=512,  # BERT's maximum sequence length\n",
        "            padding='max_length',\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        input_ids = encoding.input_ids.to(self.device)\n",
        "        attention_mask = encoding.attention_mask.to(self.device)\n",
        "\n",
        "        # Define forward function without modifying input gradients\n",
        "        def forward_func(inputs, attention_mask):\n",
        "            bert_output = self.model.bert(input_ids=inputs, attention_mask=attention_mask)\n",
        "            pooled_output = bert_output.last_hidden_state[:, 0, :]\n",
        "            bert_projected = self.model.bert_projection(pooled_output)\n",
        "            logits = self.model.classifier(bert_projected)\n",
        "            return logits\n",
        "\n",
        "        # Initialize LayerIntegratedGradients with embeddings layer\n",
        "        lig = LayerIntegratedGradients(forward_func, self.model.bert.embeddings.word_embeddings)\n",
        "\n",
        "        try:\n",
        "            # Compute attributions\n",
        "            attributions, delta = lig.attribute(\n",
        "                inputs=input_ids,\n",
        "                additional_forward_args=(attention_mask,),\n",
        "                target=int(true_label),\n",
        "                return_convergence_delta=True,\n",
        "                n_steps=50,\n",
        "                internal_batch_size=1\n",
        "            )\n",
        "\n",
        "            # Process attributions\n",
        "            attributions = attributions.sum(dim=-1).squeeze(0)\n",
        "            attributions = attributions / torch.norm(attributions)\n",
        "            attributions = attributions.cpu().detach().numpy()\n",
        "            tokens = tokenizer.convert_ids_to_tokens(input_ids[0].cpu().numpy())\n",
        "\n",
        "            # Only include tokens that are part of the actual text (not padding)\n",
        "            mask = attention_mask[0].cpu().numpy()\n",
        "            tokens = [t for t, m in zip(tokens, mask) if m == 1]\n",
        "            attributions = attributions[mask == 1]\n",
        "\n",
        "            if print_weights:\n",
        "                # Print word weights in a readable format\n",
        "                print(\"\\nWord Weights from Captum Analysis:\")\n",
        "                print(\"-\" * 50)\n",
        "                for token, weight in zip(tokens, attributions):\n",
        "                    print(f\"{token:15} : {weight:+.4f}\")\n",
        "                print(\"-\" * 50)\n",
        "\n",
        "            return {\"tokens\": tokens, \"attributions\": attributions}\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Captum Explanations error: {e}\")\n",
        "            return {\"tokens\": [], \"attributions\": []}\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=3, min_delta=0):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.best_loss = None\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, val_loss):\n",
        "        epsilon = 1e-6\n",
        "        if self.best_loss is None:\n",
        "            self.best_loss = val_loss\n",
        "        elif val_loss > self.best_loss - self.min_delta + epsilon:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                return True\n",
        "        else:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n",
        "        return False\n",
        "\n",
        "def analyze_text_weights(text, label, model_path='best_model.pt'):\n",
        "    \"\"\"Analyze word weights for a given text using Captum.\"\"\"\n",
        "    hyperparams = {\n",
        "        \"Epochs\": 1,\n",
        "        \"Batch Size\": 1,\n",
        "        \"Learning Rate\": 1e-5,\n",
        "        \"Dropout\": 0.3,\n",
        "        \"Weight Decay\": 0.1,\n",
        "        \"Label Smoothing\": 0.1,\n",
        "        \"Early Stopping Patience\": 3,\n",
        "        \"Gradient Accumulation Steps\": 1,\n",
        "        \"Optimizer\": \"AdamW\",\n",
        "        \"Scheduler\": \"OneCycleLR\",\n",
        "        \"Feature Dimension\": 0,\n",
        "        \"Model\": \"BERT with Multiple Embeddings\"\n",
        "    }\n",
        "\n",
        "    # Create a minimal dataset with just the input text\n",
        "    df = pd.DataFrame({'text': [text]})\n",
        "    labels = np.array([label])\n",
        "\n",
        "    # Initialize trainer\n",
        "    trainer = GPUOptimizedTrainer(df, 'text', labels, hyperparams)\n",
        "\n",
        "    # Load the trained model if available\n",
        "    if os.path.exists(model_path):\n",
        "        trainer.model.load_state_dict(torch.load(model_path))\n",
        "        print(f\"Loaded model from {model_path}\")\n",
        "\n",
        "    # Get word weights\n",
        "    explanation = trainer.explain_instance(text, label, print_weights=True)\n",
        "    return explanation\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Read the dataset\n",
        "    df = pd.read_csv(\"sample.csv\")\n",
        "    df['rating'] = df['rating'] - 1  # Convert to 0-4 scale\n",
        "    text_column = 'text'\n",
        "\n",
        "    # Initialize results list for word weights\n",
        "    results = []\n",
        "\n",
        "    # Setup trainer with minimal hyperparameters for inference\n",
        "    hyperparams = {\n",
        "        \"Epochs\": 1,\n",
        "        \"Batch Size\": 1,\n",
        "        \"Learning Rate\": 1e-5,\n",
        "        \"Dropout\": 0.3,\n",
        "        \"Weight Decay\": 0.1,\n",
        "        \"Label Smoothing\": 0.1,\n",
        "        \"Early Stopping Patience\": 3,\n",
        "        \"Gradient Accumulation Steps\": 1,\n",
        "        \"Optimizer\": \"AdamW\",\n",
        "        \"Scheduler\": \"OneCycleLR\",\n",
        "        \"Feature Dimension\": 0,\n",
        "        \"Model\": \"BERT with Multiple Embeddings\"\n",
        "    }\n",
        "\n",
        "    # Process 100 examples for each rating\n",
        "    for rating in range(5):\n",
        "        print(f\"\\nProcessing rating {rating}...\")\n",
        "        # Get texts for this rating\n",
        "        rating_texts = df[df['rating'] == rating][text_column].tolist()\n",
        "\n",
        "        # Sample 100 texts (or all if less than 100)\n",
        "        if len(rating_texts) > 100:\n",
        "            rating_texts = np.random.choice(rating_texts, 100, replace=False)\n",
        "\n",
        "        # Create trainer for this batch\n",
        "        batch_df = pd.DataFrame({text_column: rating_texts})\n",
        "        batch_labels = np.array([rating] * len(rating_texts))\n",
        "        trainer = GPUOptimizedTrainer(batch_df, text_column, batch_labels, hyperparams)\n",
        "\n",
        "        # Process each text\n",
        "        for text in tqdm(rating_texts, desc=f\"Rating {rating}\"):\n",
        "            explanation = trainer.explain_instance(text, rating, print_weights=False)\n",
        "\n",
        "            if explanation['tokens']:\n",
        "                # Create base result dictionary\n",
        "                result = {\n",
        "                    'text': text,\n",
        "                    'rating': rating\n",
        "                }\n",
        "\n",
        "                # Add token weights\n",
        "                for token, weight in zip(explanation['tokens'], explanation['attributions']):\n",
        "                    result[f'token_{token}'] = weight\n",
        "\n",
        "                results.append(result)\n",
        "\n",
        "    # Convert to DataFrame and save to CSV\n",
        "    results_df = pd.DataFrame(results)\n",
        "    results_df.to_csv('word_weights_analysis.csv', index=False)\n",
        "    print(f\"\\nAnalysis saved to word_weights_analysis.csv\")\n",
        "    print(f\"Total examples analyzed: {len(results_df)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ygvAeAaQjiWO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}