{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_title</th>\n",
       "      <th>cust_name</th>\n",
       "      <th>cust_rating</th>\n",
       "      <th>cust_review_text</th>\n",
       "      <th>date_experience</th>\n",
       "      <th>company</th>\n",
       "      <th>comment_length</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/10 would recommend</td>\n",
       "      <td>David Silva</td>\n",
       "      <td>5</td>\n",
       "      <td>shop need buck cheaper stock guy</td>\n",
       "      <td>2025-01-14T01:18:40.000Z</td>\n",
       "      <td>esilencers.com</td>\n",
       "      <td>97</td>\n",
       "      <td>-0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I had a question they got back to…</td>\n",
       "      <td>Riley Brown</td>\n",
       "      <td>5</td>\n",
       "      <td>question get back right away make sure everyth...</td>\n",
       "      <td>2025-01-14T11:32:00.000Z</td>\n",
       "      <td>esilencers.com</td>\n",
       "      <td>89</td>\n",
       "      <td>0.261905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eSilencers has the best pricing</td>\n",
       "      <td>William Harding</td>\n",
       "      <td>5</td>\n",
       "      <td>esilencers best price service company always c...</td>\n",
       "      <td>2025-01-10T06:52:30.000Z</td>\n",
       "      <td>esilencers.com</td>\n",
       "      <td>107</td>\n",
       "      <td>0.386667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AEM5 MUZZLE DEVICE AND COLLAR KIT 5.56 (LONG C...</td>\n",
       "      <td>Cesar Marroquin</td>\n",
       "      <td>5</td>\n",
       "      <td>aem muzzle device collar kit long collar perfe...</td>\n",
       "      <td>2024-12-26T07:39:39.000Z</td>\n",
       "      <td>esilencers.com</td>\n",
       "      <td>485</td>\n",
       "      <td>0.300595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great range of in stock items and awesome cust...</td>\n",
       "      <td>CHRISTOPHER SMITH</td>\n",
       "      <td>5</td>\n",
       "      <td>great range stock item last two item need fini...</td>\n",
       "      <td>2025-01-04T15:55:03.000Z</td>\n",
       "      <td>esilencers.com</td>\n",
       "      <td>121</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>They were efficient in all phases</td>\n",
       "      <td>Danny Neal Huffines</td>\n",
       "      <td>5</td>\n",
       "      <td>efficient phase take time explain area entire ...</td>\n",
       "      <td>2024-12-29T14:56:15.000Z</td>\n",
       "      <td>esilencers.com</td>\n",
       "      <td>139</td>\n",
       "      <td>0.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Great dealer!</td>\n",
       "      <td>B.W.</td>\n",
       "      <td>5</td>\n",
       "      <td>order bt tp factory sbr form submit next day f...</td>\n",
       "      <td>2024-12-24T13:37:28.000Z</td>\n",
       "      <td>esilencers.com</td>\n",
       "      <td>229</td>\n",
       "      <td>0.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Esilencers is always fast and easy</td>\n",
       "      <td>Weston C</td>\n",
       "      <td>5</td>\n",
       "      <td>esilencers always fast easy didnt call always ...</td>\n",
       "      <td>2024-12-29T01:22:41.000Z</td>\n",
       "      <td>esilencers.com</td>\n",
       "      <td>133</td>\n",
       "      <td>0.277778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HIGHLY RECOMMEND A++</td>\n",
       "      <td>gho3st</td>\n",
       "      <td>5</td>\n",
       "      <td>great customer service answer phone right away</td>\n",
       "      <td>2025-01-08T23:25:18.000Z</td>\n",
       "      <td>esilencers.com</td>\n",
       "      <td>52</td>\n",
       "      <td>0.542857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Follow up email after not submitting…</td>\n",
       "      <td>Patrick A</td>\n",
       "      <td>5</td>\n",
       "      <td>follow email submit order ask small discount g...</td>\n",
       "      <td>2024-12-16T22:10:22.000Z</td>\n",
       "      <td>esilencers.com</td>\n",
       "      <td>176</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        review_title            cust_name  \\\n",
       "0                             10/10 would recommend           David Silva   \n",
       "1            When I had a question they got back to…          Riley Brown   \n",
       "2                    eSilencers has the best pricing      William Harding   \n",
       "3  AEM5 MUZZLE DEVICE AND COLLAR KIT 5.56 (LONG C...      Cesar Marroquin   \n",
       "4  Great range of in stock items and awesome cust...    CHRISTOPHER SMITH   \n",
       "5                  They were efficient in all phases  Danny Neal Huffines   \n",
       "6                                      Great dealer!                 B.W.   \n",
       "7                 Esilencers is always fast and easy             Weston C   \n",
       "8                               HIGHLY RECOMMEND A++               gho3st   \n",
       "9              Follow up email after not submitting…            Patrick A   \n",
       "\n",
       "  cust_rating                                   cust_review_text  \\\n",
       "0           5                   shop need buck cheaper stock guy   \n",
       "1           5  question get back right away make sure everyth...   \n",
       "2           5  esilencers best price service company always c...   \n",
       "3           5  aem muzzle device collar kit long collar perfe...   \n",
       "4           5  great range stock item last two item need fini...   \n",
       "5           5  efficient phase take time explain area entire ...   \n",
       "6           5  order bt tp factory sbr form submit next day f...   \n",
       "7           5  esilencers always fast easy didnt call always ...   \n",
       "8           5     great customer service answer phone right away   \n",
       "9           5  follow email submit order ask small discount g...   \n",
       "\n",
       "            date_experience         company  comment_length  sentiment  \n",
       "0  2025-01-14T01:18:40.000Z  esilencers.com              97  -0.100000  \n",
       "1  2025-01-14T11:32:00.000Z  esilencers.com              89   0.261905  \n",
       "2  2025-01-10T06:52:30.000Z  esilencers.com             107   0.386667  \n",
       "3  2024-12-26T07:39:39.000Z  esilencers.com             485   0.300595  \n",
       "4  2025-01-04T15:55:03.000Z  esilencers.com             121   0.500000  \n",
       "5  2024-12-29T14:56:15.000Z  esilencers.com             139   0.080000  \n",
       "6  2024-12-24T13:37:28.000Z  esilencers.com             229   0.040000  \n",
       "7  2024-12-29T01:22:41.000Z  esilencers.com             133   0.277778  \n",
       "8  2025-01-08T23:25:18.000Z  esilencers.com              52   0.542857  \n",
       "9  2024-12-16T22:10:22.000Z  esilencers.com             176   0.375000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "\n",
    "#Preprocessing\n",
    "df_categories = pd.read_csv(\"trustpilot_categories.csv\")\n",
    "df_companies = pd.read_csv(\"trustpilot_companies.csv\")\n",
    "df_reviews_sports = pd.read_csv(\"trustpilot_reviews_1000.csv\")\n",
    "df_reviews_sports['comment_length'] = df_reviews_sports['cust_review_text'].fillna('').apply(lambda x: len(str(x)))\n",
    "df_reviews_sports['cust_review_text'] = df_reviews_sports['cust_review_text'].fillna('')\n",
    "df_reviews_sports['sentiment'] = df_reviews_sports['cust_review_text'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "\n",
    "#convert to small letters\n",
    "df_reviews_sports['cust_review_text'] = df_reviews_sports['cust_review_text'].str.lower()\n",
    "\n",
    "#delete special characters, numbers and html-tags\n",
    "df_reviews_sports['cust_review_text'] = df_reviews_sports['cust_review_text'].apply(lambda x: re.sub(r'[^a-zA-Z\\s]', '', str(x)))\n",
    "\n",
    "#delete stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "df_reviews_sports['cust_review_text'] = df_reviews_sports['cust_review_text'].apply(\n",
    "    lambda x: ' '.join([word for word in x.split() if word not in stop_words])\n",
    ")\n",
    "\n",
    "#stemming (i.e. running --> run)\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "df_reviews_sports['cust_review_text'] = df_reviews_sports['cust_review_text'].apply(\n",
    "    lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split()])\n",
    ")\n",
    "def lemmatize_with_pos(text):\n",
    "    return ' '.join([lemmatizer.lemmatize(word, pos=wordnet.VERB) for word in text.split()])\n",
    "\n",
    "df_reviews_sports['cust_review_text'] = df_reviews_sports['cust_review_text'].apply(lemmatize_with_pos)\n",
    "df_reviews_sports.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97      6380\n",
      "           1       0.98      0.96      0.97      6563\n",
      "           2       0.96      0.99      0.98      6559\n",
      "           3       0.83      0.85      0.84      6471\n",
      "           4       0.86      0.81      0.83      6352\n",
      "\n",
      "    accuracy                           0.92     32325\n",
      "   macro avg       0.92      0.92      0.92     32325\n",
      "weighted avg       0.92      0.92      0.92     32325\n",
      "\n",
      "Confusion Matrix:\n",
      "[[6268   28   22   49   13]\n",
      " [  16 6303   12  230    2]\n",
      " [  43    0 6479    3   34]\n",
      " [  53   30   82 5516  790]\n",
      " [ 110   98  136  877 5131]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "#tuning the review column\n",
    "\n",
    "#string to numeric\n",
    "df_reviews_sports['cust_rating'] = pd.to_numeric(df_reviews_sports['cust_rating'], errors='coerce')\n",
    "\n",
    "# deleting NaN\n",
    "df_reviews_sports = df_reviews_sports.dropna(subset=['cust_rating', 'cust_review_text'])\n",
    "\n",
    "#TF-IDF-vectorizing (converting text to numeric format)\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "X = tfidf.fit_transform(df_reviews_sports['cust_review_text'])\n",
    "\n",
    "#target variable (Ratings)\n",
    "y = df_reviews_sports['cust_rating']\n",
    "\n",
    "#SMOTE (balancing of the Ratings)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "#test and training data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "#Logistic Regression\n",
    "\n",
    "#training the model (Logistic Regression)\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#prediction and evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.99      1.00      1.00      6380\n",
      "         2.0       1.00      1.00      1.00      6563\n",
      "         3.0       1.00      1.00      1.00      6559\n",
      "         4.0       0.98      0.99      0.98      6471\n",
      "         5.0       0.98      0.98      0.98      6352\n",
      "\n",
      "    accuracy                           0.99     32325\n",
      "   macro avg       0.99      0.99      0.99     32325\n",
      "weighted avg       0.99      0.99      0.99     32325\n",
      "\n",
      "Random Forest Confusion Matrix:\n",
      "[[6373    0    0    0    7]\n",
      " [   2 6546    0    9    6]\n",
      " [   1    0 6546    0   12]\n",
      " [   1    0    0 6388   82]\n",
      " [  29    2    2  110 6209]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# prediction\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# evaluation\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(\"Random Forest Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.97      1.00      0.98      6380\n",
      "         2.0       0.98      0.94      0.96      6563\n",
      "         3.0       0.98      0.99      0.99      6559\n",
      "         4.0       0.82      0.89      0.85      6471\n",
      "         5.0       0.89      0.81      0.85      6352\n",
      "\n",
      "    accuracy                           0.93     32325\n",
      "   macro avg       0.93      0.93      0.93     32325\n",
      "weighted avg       0.93      0.93      0.93     32325\n",
      "\n",
      "SVM Confusion Matrix:\n",
      "[[6353   12    0   10    5]\n",
      " [  27 6162    0  374    0]\n",
      " [  21    0 6520    0   18]\n",
      " [  27    2   36 5763  643]\n",
      " [  97   97  107  892 5159]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "#from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# prediction\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# evaluation\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "print(\"SVM Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Trust_pilot/trustpilot_env/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [14:30:45] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.98      0.98      0.98      6380\n",
      "         2.0       0.99      0.98      0.98      6563\n",
      "         3.0       0.99      0.99      0.99      6559\n",
      "         4.0       0.91      0.82      0.86      6471\n",
      "         5.0       0.82      0.91      0.86      6352\n",
      "\n",
      "    accuracy                           0.94     32325\n",
      "   macro avg       0.94      0.94      0.94     32325\n",
      "weighted avg       0.94      0.94      0.94     32325\n",
      "\n",
      "XGBoost Confusion Matrix:\n",
      "[[6259   35   10   26   50]\n",
      " [  28 6423    0   65   47]\n",
      " [  17    4 6472   23   43]\n",
      " [  24   21    3 5336 1087]\n",
      " [  70   32   59  427 5764]]\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Zielvariable umwandeln: Werte auf ganze Zahlen und bei 0 beginnend verschieben\n",
    "y_train_int = y_train.astype(int) - 1\n",
    "y_test_int = y_test.astype(int) - 1\n",
    "\n",
    "# Gradient Boosting Classifier (XGBoost)\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "xgb_model.fit(X_train, y_train_int)\n",
    "\n",
    "# Vorhersage\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Vorhersagen zurückverschieben, um originalen Bereich (1-5) wiederherzustellen\n",
    "y_pred_xgb_original = y_pred_xgb + 1\n",
    "\n",
    "# Bewertung\n",
    "print(\"XGBoost Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_xgb_original))\n",
    "print(\"XGBoost Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_xgb_original))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Einzigartige Labels in y_train: {0, 1}\n",
      "Einzigartige Labels in y_test: {0, 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ubuntu/Trust_pilot/trustpilot_env/lib/python3.12/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Prüfen, ob CPU verwendet wird\n",
    "device = torch.device('cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Schritt 1: Daten vorbereiten\n",
    "# Zielvariable filtern: Nur Werte zwischen 1 und 5 zulassen\n",
    "df_reviews_sports['cust_rating'] = pd.to_numeric(df_reviews_sports['cust_rating'], errors='coerce')\n",
    "df_reviews_sports = df_reviews_sports.dropna(subset=['cust_rating', 'cust_review_text'])\n",
    "df_reviews_sports = df_reviews_sports[df_reviews_sports['cust_rating'].between(1, 5)]\n",
    "\n",
    "# Zielwerte in den Bereich [0, 4] umwandeln\n",
    "df_reviews_sports['cust_rating'] = df_reviews_sports['cust_rating'].astype(int) - 1\n",
    "\n",
    "# Aufteilen in Training und Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_reviews_sports['cust_review_text'],\n",
    "    df_reviews_sports['cust_rating'],\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Debugging: Überprüfen der Labels\n",
    "print(\"Einzigartige Labels in y_train:\", set(y_train))\n",
    "print(\"Einzigartige Labels in y_test:\", set(y_test))\n",
    "\n",
    "# Schritt 2: Tokenizer laden\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenizer-Funktion\n",
    "def tokenize_data(texts, labels, tokenizer, max_len=64):  # Kürzere maximale Länge für Effizienz\n",
    "    tokens = tokenizer(\n",
    "        list(texts),  # Sicherstellen, dass Texte als Liste vorliegen\n",
    "        max_length=max_len,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    return tokens, torch.tensor(labels, dtype=torch.long)  # Labels als Long-Tensors zurückgeben\n",
    "\n",
    "# Training-Daten tokenisieren\n",
    "train_tokens, train_labels = tokenize_data(X_train, y_train.tolist(), tokenizer)\n",
    "test_tokens, test_labels = tokenize_data(X_test, y_test.tolist(), tokenizer)\n",
    "\n",
    "# Schritt 3: Dataset und DataLoader\n",
    "class ReviewsDataset(Dataset):\n",
    "    def __init__(self, tokens, labels):\n",
    "        self.tokens = tokens\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.tokens['input_ids'][idx],\n",
    "            'attention_mask': self.tokens['attention_mask'][idx],\n",
    "            'labels': self.labels[idx]\n",
    "        }\n",
    "\n",
    "train_dataset = ReviewsDataset(train_tokens, train_labels)\n",
    "test_dataset = ReviewsDataset(test_tokens, test_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)  # Kleinere Batch-Größe für CPU\n",
    "test_loader = DataLoader(test_dataset, batch_size=8)\n",
    "\n",
    "# Schritt 4: BERT-Modell laden\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=5)  # 5 Klassen\n",
    "model.to(device)\n",
    "\n",
    "# Schritt 5: Optimizer und Loss-Funktion\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Schritt 6: Training\n",
    "epochs = 2  # Reduzierte Anzahl der Epochen für Effizienz\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss}\")\n",
    "\n",
    "# Schritt 7: Evaluation\n",
    "model.eval()\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "        predictions.extend(preds.cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Schritt 8: Bericht und Metriken\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_labels, predictions, target_names=['1', '2', '3', '4', '5']))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trustpilot_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
